{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [threading.Thread]启动与停止线程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`threading` 库可以在单独的线程中执行任何的在 `Python` 中可以调用的对象。你可以创建一个 `Thread` 对象并将你要执行的对象以 `target` 参数的形式提供给该对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T08:14:03.080682Z",
     "start_time": "2019-09-24T08:14:03.072835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 10\n"
     ]
    }
   ],
   "source": [
    "# Code to execute in an independent thread\n",
    "import time\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        print('T-minus', n)\n",
    "        n -= 1\n",
    "        time.sleep(5)\n",
    "\n",
    "# Create and launch a thread\n",
    "from threading import Thread\n",
    "t = Thread(target=countdown, args=(10,))\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当你创建好一个线程对象后，该对象并不会立即执行，除非你调用它的 `start()` 方法（当你调用 `start()` 方法时，它会调用你传递进来的函数，并把你传递进来的参数传递给该函数）。\n",
    "\n",
    "`Python` 中的线程会在一个单独的系统级线程中执行（比如说一个 `POSIX` 线程或者一个 `Windows` 线程），这些线程将由操作系统来全权管理。\n",
    "\n",
    "线程一旦启动，将独立执行直到目标函数返回。你可以查询一个线程对象的状态，看它是否还在执行：\n",
    "\n",
    "```py\n",
    "if t.is_alive():\n",
    "    print('Still running')\n",
    "else:\n",
    "    print('Completed')\n",
    "\n",
    "```\n",
    "\n",
    "你也可以将一个线程加入到当前线程，并等待它终止：\n",
    "\n",
    "```py\n",
    "t.join()\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后台线程无法等待，不过，这些线程会在主线程终止时自动销毁。 \n",
    "\n",
    "除了如上所示的两个操作，并没有太多可以对线程做的事情。\n",
    "\n",
    "你无法结束一个线程，无法给它发送信号，无法调整它的调度，也无法执行其他高级操作。\n",
    "\n",
    "如果需要这些特性，你需要自己添加。\n",
    "\n",
    "比如说，如果你需要终止线程，那么这个线程必须通过编程在某个特定点轮询来退出。\n",
    "\n",
    "你可以像下边这样把线程放入一个类中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T16:19:36.245785Z",
     "start_time": "2019-09-24T16:19:36.234817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ThreadTest.py\n"
     ]
    }
   ],
   "source": [
    "%%file ThreadTest.py\n",
    "import time\n",
    "class CountdownTask:\n",
    "    def __init__(self):\n",
    "        self._running = True\n",
    "\n",
    "    def terminate(self):\n",
    "        self._running = False\n",
    "\n",
    "    def run(self, n):\n",
    "        while self._running and n > 0:\n",
    "            print('T-minus', n)\n",
    "            n -= 1\n",
    "            time.sleep(5)\n",
    "\n",
    "c = CountdownTask()\n",
    "\n",
    "from threading import Thread\n",
    "t = Thread(target=c.run, args=(10,))\n",
    "t.start()\n",
    "c.terminate() # Signal termination 信號終止\n",
    "t.join()      # Wait for actual termination (if needed) 實際停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T16:18:08.371769Z",
     "start_time": "2019-09-24T16:18:08.352819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python \"D:\\CODE\\GitHub\\py\\資料結構\\py3-cookbook\\并发编程\\ThreadTest.py\"\n",
      "D:\\CODE\\GitHub\\py\\資料結構\\py3-cookbook\\并发编程\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x179f62f3d68>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============ 開新 CONSOLE ============\n",
    "# ------------ Run the server ------------\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "# os.path.abspath {本黨位置}: D:\\Google 雲端硬碟\\learn\\線程調用\\TestOS.py\n",
    "# os.path.dirname {目錄} : D:\\Google 雲端硬碟\\learn\\線程調用\n",
    "BASE_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "# 透過 cmd 呼叫\n",
    "DIR = os.path.join(BASE_DIR, 'ThreadTest.py')\n",
    "cmd = \"python \" + f'\"{DIR}\"'\n",
    "print(cmd,BASE_DIR,sep='\\n')\n",
    "#  CONSOLE混雜\n",
    "#os.system(cmd)\n",
    "#subprocess.call(cmd)\n",
    "\n",
    "#  NEW 一個 CONSOLE\n",
    "subprocess.Popen(cmd, creationflags=subprocess.CREATE_NEW_CONSOLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果线程执行一些像 `I/O` 这样的阻塞操作，那么通过轮询来终止线程将使得线程之间的协调变得非常棘手。\n",
    "\n",
    "比如，如果一个线程一直阻塞在一个 `I/O` 操作上，它就永远无法返回，也就无法检查自己是否已经被结束了。\n",
    "\n",
    "要正确处理这些问题，你需要利用超时循环来小心操作线程。 例子如下：\n",
    "\n",
    "```py\n",
    "class IOTask:\n",
    "    def terminate(self):\n",
    "        self._running = False\n",
    "\n",
    "    def run(self, sock):\n",
    "        # sock is a socket\n",
    "        sock.settimeout(5)        # Set timeout period\n",
    "        while self._running:\n",
    "            # Perform a blocking I/O operation w/ timeout\n",
    "            try:\n",
    "                data = sock.recv(8192)\n",
    "                break\n",
    "            except socket.timeout:\n",
    "                continue\n",
    "            # Continued processing\n",
    "            ...\n",
    "        # Terminated\n",
    "        return\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [multiprocessing]讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于全局解释锁 `（GIL）` 的原因， `Python` 的线程被限制到同一时刻只允许一个线程执行这样一个执行模型。\n",
    "\n",
    "所以， `Python` 的线程更适用于处理 `I/O` 和其他需要并发执行的阻塞操作（比如等待 `I/O` 、等待从数据库获取数据等等），而**不是需要多处理器并行的计算密集型任务**\n",
    "\n",
    "你可以通过 `multiprocessing` 模块在一个单独的进程中执行你的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T14:24:13.100921Z",
     "start_time": "2019-09-24T14:24:08.086293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 5\n",
      "T-minus 4\n",
      "T-minus 3\n",
      "T-minus 2\n",
      "T-minus 1\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "class CountdownTask:\n",
    "    def __init__(self):\n",
    "        self._running = True\n",
    "\n",
    "    def terminate(self):\n",
    "        self._running = False\n",
    "\n",
    "    def run(self, n):\n",
    "        while self._running and n > 0:\n",
    "            print('T-minus', n)\n",
    "            n -= 1\n",
    "            time.sleep(1)\n",
    "\n",
    "c = CountdownTask()\n",
    "p = multiprocessing.Process(\n",
    "    target=c.run(n=5)\n",
    ")\n",
    "p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [threading.Event()]判断线程是否已经启动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线程的一个关键特性是每个线程都是独立运行且状态不可预测。\n",
    "\n",
    "如果程序中的其他线程需要通过判断某个线程的状态来确定自己下一步的操作，这时线程同步问题就会变得非常棘手。\n",
    "\n",
    "为了解决这些问题，我们需要使用 `threading` 库中的 `Event` 对象。 \n",
    "\n",
    "`Event` 对象包含一个可由线程设置的信号标志，它允许线程等待某些事件的发生。\n",
    "\n",
    "在初始情况下， `event` 对象中的信号标志被设置为假。\n",
    "\n",
    "如果有线程等待一个 `event` 对象，而这个 `event` 对象的标志为假，那么这个线程将会被一直阻塞直至该标志为真。\n",
    "\n",
    "一个线程如果将一个 `event` 对象的信号标志设置为真，它将唤醒所有等待这个 `event` 对象的线程。\n",
    "\n",
    "如果一个线程等待一个已经被设置为真的 `event` 对象，那么它将忽略这个事件，继续执行。 \n",
    "\n",
    "下边的代码展示了如何使用 `Event` 来协调线程的启动："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T15:11:15.138582Z",
     "start_time": "2019-09-24T15:11:15.127598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching countdown\n",
      "countdown starting\n",
      "T-minus 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countdown is running\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Event\n",
    "import time\n",
    "\n",
    "# Code to execute in an independent thread\n",
    "def countdown(n, started_evt):\n",
    "    print('countdown starting')\n",
    "    # Event().set()\n",
    "    started_evt.set()\n",
    "    while n > 0:\n",
    "        print('T-minus', n)\n",
    "        n -= 1\n",
    "        time.sleep(5)\n",
    "\n",
    "# Create the event object that will be used to signal startup\n",
    "started_evt = Event()\n",
    "\n",
    "# Launch the thread and pass the startup event\n",
    "print('Launching countdown')\n",
    "t = Thread(target=countdown, args=(10,started_evt))\n",
    "t.start()\n",
    "\n",
    "# Wait for the thread to start\n",
    "started_evt.wait()\n",
    "print('countdown is running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [threading.Condition()]讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`event` 对象最好单次使用，就是说，你创建一个 `event` 对象，让某个线程等待这个对象，一旦这个对象被设置为真，你就应该丢弃它。\n",
    "\n",
    "尽管可以通过 `clear()` 方法来重置 `event` 对象，但是很难确保安全地清理 `event` 对象并对它重新赋值。\n",
    "\n",
    "很可能会发生错过事件、死锁或者其他问题（特别是，你无法保证重置 `event` 对象的代码会在线程再次等待这个 `event` 对象之前执行）。\n",
    "\n",
    "如果一个线程需要不停地重复使用 `event` 对象，你最好使用 `Condition` 对象来代替。\n",
    "\n",
    "下面的代码使用 `Condition` 对象实现了一个周期定时器，每当定时器超时的时候，其他线程都可以监测到："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T16:20:46.457723Z",
     "start_time": "2019-09-24T16:20:46.445767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MultiThreadTest.py\n"
     ]
    }
   ],
   "source": [
    "%%file MultiThreadTest.py\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# ======= Timer =======\n",
    "\n",
    "class PeriodicTimer:\n",
    "    def __init__(self, interval):\n",
    "        self._interval = interval\n",
    "        self._flag = 0\n",
    "        self._cv = threading.Condition()\n",
    "\n",
    "    def start(self):\n",
    "        t = threading.Thread(target=self.run)\n",
    "        t.daemon = True\n",
    "\n",
    "        t.start()\n",
    "\n",
    "    def run(self):\n",
    "        '''\n",
    "        Run the timer and notify waiting threads after each interval\n",
    "        '''\n",
    "        while True:\n",
    "            time.sleep(self._interval)\n",
    "            with self._cv:\n",
    "                # 二進制 異位(XOR)\n",
    "                self._flag ^= 1\n",
    "                self._cv.notify_all()\n",
    "\n",
    "    def wait_for_tick(self):\n",
    "        '''\n",
    "        Wait for the next tick of the timer\n",
    "        '''\n",
    "        with self._cv:\n",
    "            last_flag = self._flag\n",
    "            while last_flag == self._flag:\n",
    "                self._cv.wait()\n",
    "\n",
    "# Example use of the timer\n",
    "ptimer = PeriodicTimer(1)\n",
    "ptimer.start()\n",
    "\n",
    "# Two threads that synchronize on the timer\n",
    "def countdown(nticks):\n",
    "    while nticks > 0:\n",
    "        ptimer.wait_for_tick()\n",
    "        print('T-minus', nticks)\n",
    "        nticks -= 1\n",
    "\n",
    "def countup(last):\n",
    "    n = 0\n",
    "    while n < last:\n",
    "        ptimer.wait_for_tick()\n",
    "        print('Counting', n)\n",
    "        n += 1\n",
    "\n",
    "threading.Thread(target=countdown, args=(10,)).start()\n",
    "threading.Thread(target=countup, args=(5,)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T16:20:48.126977Z",
     "start_time": "2019-09-24T16:20:48.115007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python \"D:\\CODE\\GitHub\\py\\資料結構\\py3-cookbook\\并发编程\\MultiThreadTest.py\"\n",
      "D:\\CODE\\GitHub\\py\\資料結構\\py3-cookbook\\并发编程\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x179f62f3c50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============ 開新 CONSOLE ============\n",
    "# ------------ Run the server ------------\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "# os.path.abspath {本黨位置}: D:\\Google 雲端硬碟\\learn\\線程調用\\TestOS.py\n",
    "# os.path.dirname {目錄} : D:\\Google 雲端硬碟\\learn\\線程調用\n",
    "BASE_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "# 透過 cmd 呼叫\n",
    "DIR = os.path.join(BASE_DIR, 'MultiThreadTest.py')\n",
    "cmd = \"python \" + f'\"{DIR}\"'\n",
    "print(cmd,BASE_DIR,sep='\\n')\n",
    "#  CONSOLE混雜\n",
    "#os.system(cmd)\n",
    "#subprocess.call(cmd)\n",
    "\n",
    "#  NEW 一個 CONSOLE\n",
    "subprocess.Popen(cmd, creationflags=subprocess.CREATE_NEW_CONSOLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`event` 对象的一个重要特点是当它被设置为真时会唤醒所有等待它的线程。\n",
    "\n",
    "如果你只想唤醒单个线程，最好是使用 **信号量** 或者 `Condition` 对象来替代。考虑一下这段使用信号量实现的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T09:34:39.278949Z",
     "start_time": "2019-09-25T09:34:39.270151Z"
    }
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "# Worker thread\n",
    "def worker(n, sema):\n",
    "    # Wait to be signaled\n",
    "    sema.acquire()\n",
    "\n",
    "    # Do some work\n",
    "    print('Working', n)\n",
    "\n",
    "# Create some threads\n",
    "sema = threading.Semaphore(0)\n",
    "nworkers = 10\n",
    "for n in range(nworkers):\n",
    "    t = threading.Thread(target=worker, args=(n, sema,))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次信号量被释放，只有一个线程会被唤醒并执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T09:34:45.266688Z",
     "start_time": "2019-09-25T09:34:45.257904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working 0\n",
      "Working 1\n"
     ]
    }
   ],
   "source": [
    "sema.release()\n",
    "\n",
    "sema.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {情境及應用不瞭解}线程间通信"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从一个线程向另一个线程发送数据最安全的方式可能就是使用 `queue` 库中的队列了。\n",
    "\n",
    "创建一个被多个线程共享的 `Queue` 对象，这些线程通过使用 `put()` 和 `get()` 操作来向队列中添加或者删除元素。 例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:51:11.674954Z",
     "start_time": "2019-09-25T12:51:11.650554Z"
    }
   },
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "# A thread that produces data\n",
    "def producer(out_q):\n",
    "    while True:\n",
    "        # Produce some data\n",
    "        ...\n",
    "        out_q.put(data)\n",
    "\n",
    "# A thread that consumes data\n",
    "def consumer(in_q):\n",
    "    while True:\n",
    "        # Get some data\n",
    "        data = in_q.get()\n",
    "        # Process the data\n",
    "        ...\n",
    "\n",
    "# Create the shared queue and launch both threads\n",
    "q = Queue()\n",
    "t1 = Thread(target=consumer, args=(q,))\n",
    "t2 = Thread(target=producer, args=(q,))\n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Queue` 对象已经包含了必要的锁，所以你可以通过它在多个线程间多安全地共享数据。 \n",
    "\n",
    "当使用队列时，协调生产者和消费者的关闭问题可能会有一些麻烦。\n",
    "\n",
    "一个通用的解决方法是在队列中放置一个特殊的值，当消费者读到这个值的时候，终止执行。例如：\n",
    "\n",
    "```py\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "# Object that signals shutdown\n",
    "_sentinel = object()\n",
    "\n",
    "# A thread that produces data\n",
    "def producer(out_q):\n",
    "    while running:\n",
    "        # Produce some data\n",
    "        ...\n",
    "        out_q.put(data)\n",
    "\n",
    "    # Put the sentinel on the queue to indicate completion\n",
    "    out_q.put(_sentinel)\n",
    "\n",
    "# A thread that consumes data\n",
    "def consumer(in_q):\n",
    "    while True:\n",
    "        # Get some data\n",
    "        data = in_q.get()\n",
    "\n",
    "        # Check for termination\n",
    "        if data is _sentinel:\n",
    "            in_q.put(_sentinel)\n",
    "            break\n",
    "\n",
    "        # Process the data\n",
    "        ...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本例中有一个特殊的地方：消费者在读到这个特殊值之后立即又把它放回到队列中，将之传递下去。\n",
    "\n",
    "这样，所有监听这个队列的消费者线程就可以全部关闭了。 \n",
    "\n",
    "尽管队列是最常见的线程间通信机制，但是仍然可以自己通过创建自己的数据结构并添加所需的锁和同步机制来实现线程间通信。\n",
    "\n",
    "最常见的方法是使用 `Condition` 变量来包装你的数据结构。\n",
    "\n",
    "下边这个例子演示了如何创建一个线程安全的优先级队列\n",
    "\n",
    "```py\n",
    "import heapq\n",
    "import threading\n",
    "\n",
    "class PriorityQueue:\n",
    "    def __init__(self):\n",
    "        self._queue = []\n",
    "        self._count = 0\n",
    "        self._cv = threading.Condition()\n",
    "        \n",
    "    def put(self, item, priority):\n",
    "        with self._cv:\n",
    "            heapq.heappush(self._queue, (-priority, self._count, item))\n",
    "            self._count += 1\n",
    "            self._cv.notify()\n",
    "\n",
    "    def get(self):\n",
    "        with self._cv:\n",
    "            while len(self._queue) == 0:\n",
    "                self._cv.wait()\n",
    "            return heapq.heappop(self._queue)[-1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用队列来进行线程间通信是一个单向、不确定的过程。通常情况下，你没有办法知道接收数据的线程是什么时候接收到的数据并开始工作的。\n",
    "\n",
    "不过队列对象提供一些基本完成的特性，比如下边这个例子中的 `task_done()` 和 `join()` ：\n",
    "\n",
    "```py\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "# A thread that produces data\n",
    "def producer(out_q):\n",
    "    while running:\n",
    "        # Produce some data\n",
    "        ...\n",
    "        out_q.put(data)\n",
    "\n",
    "# A thread that consumes data\n",
    "def consumer(in_q):\n",
    "    while True:\n",
    "        # Get some data\n",
    "        data = in_q.get()\n",
    "\n",
    "        # Process the data\n",
    "        ...\n",
    "        # Indicate completion\n",
    "        in_q.task_done()\n",
    "\n",
    "# Create the shared queue and launch both threads\n",
    "q = Queue()\n",
    "t1 = Thread(target=consumer, args=(q,))\n",
    "t2 = Thread(target=producer, args=(q,))\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Wait for all produced items to be consumed\n",
    "q.join()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果一个线程需要在一个 **“消费者”** 线程处理完特定的数据项时立即得到通知，你可以把要发送的数据和一个 `Event` 放到一起使用，这样 **“生产者”** 就可以通过这个 `Event` 对象来监测处理的过程了。示例如下：\n",
    "\n",
    "```py\n",
    "from queue import Queue\n",
    "from threading import Thread, Event\n",
    "\n",
    "# A thread that produces data\n",
    "def producer(out_q):\n",
    "    while running:\n",
    "        # Produce some data\n",
    "        ...\n",
    "        # Make an (data, event) pair and hand it to the consumer\n",
    "        evt = Event()\n",
    "        out_q.put((data, evt))\n",
    "        ...\n",
    "        # Wait for the consumer to process the item\n",
    "        evt.wait()\n",
    "\n",
    "# A thread that consumes data\n",
    "def consumer(in_q):\n",
    "    while True:\n",
    "        # Get some data\n",
    "        data, evt = in_q.get()\n",
    "        # Process the data\n",
    "        ...\n",
    "        # Indicate completion\n",
    "        evt.set()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [列隊判斷與線程]讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用队列这种基于消息的通信机制可以被扩展到更大的应用范畴，比如，你可以把你的程序放入 **多个进程** 甚至是 **分布式系统** 而无需改变底层的队列结构。 \n",
    "\n",
    "使用线程队列有一个要注意的问题是，向队列中 **添加数据项** 时并不会复制此数据项，线程间通信实际上是在线程间传递对象引用。\n",
    "\n",
    "如果你担心对象的 **共享状态** ，那你最好只传递不可修改的数据结构（如：整型、字符串或者元组）或者一个对象的 **深拷贝** 。\n",
    "\n",
    "```py\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import copy\n",
    "\n",
    "# A thread that produces data\n",
    "def producer(out_q):\n",
    "    while True:\n",
    "        # Produce some data\n",
    "        ...\n",
    "        out_q.put(copy.deepcopy(data))\n",
    "\n",
    "# A thread that consumes data\n",
    "def consumer(in_q):\n",
    "    while True:\n",
    "        # Get some data\n",
    "        data = in_q.get()\n",
    "        # Process the data\n",
    "        ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Queue` 对象提供一些在当前上下文很有用的附加特性。\n",
    "\n",
    "比如在创建 `Queue` 对象时提供可选的 `size` 参数来限制可以添加到队列中的元素数量。\n",
    "\n",
    "对于 **“生产者”** 与 **“消费者”** 速度有差异的情况，为队列中的元素数量添加上限是有意义的。\n",
    "\n",
    "比如，一个 **“生产者”** 产生项目的速度比 **“消费者”** **“消费”** 的速度快，那么使用固定大小的队列就可以在队列已满的时候阻塞队列，以免未预期的连锁效应扩散整个程序造成死锁或者程序运行失常。\n",
    "\n",
    "在通信的线程之间进行“流量控制”是一个看起来容易实现起来困难的问题。\n",
    "\n",
    "如果你发现自己曾经试图通过摆弄队列大小来解决一个问题，这也许就标志着你的程序可能存在脆弱设计或者固有的可伸缩问题。 **get()** 和 **put()** 方法都 **支持非阻塞方式和设定超时** ，例如：\n",
    "\n",
    "```py\n",
    "import queue\n",
    "q = queue.Queue()\n",
    "\n",
    "try:\n",
    "    data = q.get(block=False)\n",
    "except queue.Empty:\n",
    "    ...\n",
    "\n",
    "try:\n",
    "    q.put(item, block=False)\n",
    "except queue.Full:\n",
    "    ...\n",
    "\n",
    "try:\n",
    "    data = q.get(timeout=5.0)\n",
    "except queue.Empty:\n",
    "    ...\n",
    "```\n",
    "\n",
    "这些操作都可以用来避免当执行某些特定队列操作时发生无限阻塞的情况，比如，一个非阻塞的 `put()` 方法和 **一个固定大小的队列** 一起使用，这样当队列已满时就可以执行不同的代码。\n",
    "\n",
    "比如输出一条日志信息并丢弃。\n",
    "\n",
    "```py\n",
    "def producer(q):\n",
    "    ...\n",
    "    try:\n",
    "        q.put(item, block=False)\n",
    "    except queue.Full:\n",
    "        log.warning('queued item %r discarded!', item)\n",
    "```\n",
    "\n",
    "如果你试图让消费者线程在执行像 `q.get()` 这样的操作时，超时自动终止以便检查终止标志，你应该使用 `q.get()` 的可选参数 `timeout` ，如下：\n",
    "\n",
    "```py\n",
    "_running = True\n",
    "\n",
    "def consumer(q):\n",
    "    while _running:\n",
    "        try:\n",
    "            item = q.get(timeout=5.0)\n",
    "            # Process item\n",
    "            ...\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "```\n",
    "\n",
    "最后，有 `q.qsize()` ， `q.full()` ， `q.empty()` 等实用方法可以获取一个队列的当前大小和状态。但要注意，这些方法都不是线程安全的。\n",
    "\n",
    "可能你对一个队列使用 `empty()` 判断出这个队列为空，但同时另外一个线程可能已经向这个队列中插入一个数据项。\n",
    "\n",
    "所以，你最好不要在你的代码中使用这些方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [threading; with]给关键部分加锁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要在多线程程序中安全使用可变对象，你需要使用 `threading` 库中的 `Lock` 对象，就像下边这个例子这样：\n",
    "\n",
    "```py\n",
    "import threading\n",
    "\n",
    "class SharedCounter:\n",
    "    '''\n",
    "    A counter object that can be shared by multiple threads.\n",
    "    '''\n",
    "    def __init__(self, initial_value = 0):\n",
    "        self._value = initial_value\n",
    "        self._value_lock = threading.Lock()\n",
    "\n",
    "    def incr(self,delta=1):\n",
    "        '''\n",
    "        Increment the counter with locking\n",
    "        '''\n",
    "        with self._value_lock:\n",
    "             self._value += delta\n",
    "\n",
    "    def decr(self,delta=1):\n",
    "        '''\n",
    "        Decrement the counter with locking\n",
    "        '''\n",
    "        with self._value_lock:\n",
    "             self._value -= delta\n",
    "```\n",
    "\n",
    "`Lock` 对象和 `with` 语句块一起使用可以保证互斥执行，就是每次只有一个线程可以执行 `with` 语句包含的代码块。\n",
    "\n",
    "`with` 语句会在这个代码块执行前自动获取锁，在执行结束后自动释放锁。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [無明確應用，難以理解，未完]讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线程调度本质上是不确定的，因此，在多线程程序中错误地使用锁机制可能会导致随机数据损坏或者其他的异常行为，我们称之为竞争条件。\n",
    "\n",
    "为了避免竞争条件，最好只在临界区（对临界资源进行操作的那部分代码）使用锁。\n",
    "\n",
    "显式获取和释放锁是很常见的。下边是一个上一个例子的变种：\n",
    "\n",
    "\n",
    "```py\n",
    "import threading\n",
    "\n",
    "class SharedCounter:\n",
    "    '''\n",
    "    A counter object that can be shared by multiple threads.\n",
    "    '''\n",
    "    def __init__(self, initial_value = 0):\n",
    "        self._value = initial_value\n",
    "        self._value_lock = threading.Lock()\n",
    "\n",
    "    def incr(self,delta=1):\n",
    "        '''\n",
    "        Increment the counter with locking\n",
    "        '''\n",
    "        # 上 锁\n",
    "        self._value_lock.acquire()\n",
    "        self._value += delta\n",
    "        # 释放锁\n",
    "        self._value_lock.release()\n",
    "\n",
    "    def decr(self,delta=1):\n",
    "        '''\n",
    "        Decrement the counter with locking\n",
    "        '''\n",
    "        # 上 锁\n",
    "        self._value_lock.acquire()\n",
    "        self._value -= delta\n",
    "        # 释放锁\n",
    "        self._value_lock.release()\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比于这种显式调用的方法， `with` 语句更加优雅，也更不容易出错，\n",
    "\n",
    "特别是程序员可能会忘记调用 `release()` 方法或者程序在获得锁之后产生异常这两种情况（使用 `with` 语句可以保证在这两种情况下仍能正确释放锁）。 \n",
    "\n",
    "为了避免出现死锁的情况，使用锁机制的程序应该设定为每个线程一次只允许获取一个锁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**未完**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 防止死锁的加锁机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在多线程程序中，死锁问题很大一部分是由于线程同时获取多个锁造成的。\n",
    "\n",
    "举个例子：一个线程获取了第一个锁，然后在获取第二个锁的 时候发生阻塞，那么这个线程就可能阻塞其他线程的执行，从而导致整个程序假死。 \n",
    "\n",
    "解决死锁问题的一种方案是为程序中的每一个锁分配一个唯一的`id`，然后只允许按照升序规则来使用多个锁，这个规则使用上下文管理器 是非常容易实现的，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T15:02:56.640693Z",
     "start_time": "2019-10-01T15:02:56.238964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-1"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Thread-local state to stored information on locks already acquired\n",
    "_local = threading.local()\n",
    "\n",
    "@contextmanager\n",
    "def acquire(*locks):\n",
    "    # Sort locks by object identifier\n",
    "    locks = sorted(locks, key=lambda x: id(x))\n",
    "\n",
    "    # Make sure lock order of previously acquired locks is not violated\n",
    "    acquired = getattr(_local,'acquired',[])\n",
    "    if acquired and max(id(lock) for lock in acquired) >= id(locks[0]):\n",
    "        raise RuntimeError('Lock Order Violation')\n",
    "\n",
    "    # Acquire all of the locks\n",
    "    acquired.extend(locks)\n",
    "    _local.acquired = acquired\n",
    "\n",
    "    try:\n",
    "        for lock in locks:\n",
    "            lock.acquire()\n",
    "        yield\n",
    "    finally:\n",
    "        # Release locks in reverse order of acquisition\n",
    "        for lock in reversed(locks):\n",
    "            lock.release()\n",
    "        del acquired[-len(locks):]\n",
    "\n",
    "# ======= 使用 ========\n",
    "# 如何使用这个上下文管理器\n",
    "# 不论是单个锁还是多个锁中都使用 acquire() 函数来申请锁        \n",
    "import threading\n",
    "x_lock = threading.Lock()\n",
    "y_lock = threading.Lock()\n",
    "\n",
    "def thread_1():\n",
    "    while True:\n",
    "        with acquire(x_lock, y_lock):\n",
    "            print('Thread-1')\n",
    "\n",
    "def thread_2():\n",
    "    while True:\n",
    "        with acquire(y_lock, x_lock):\n",
    "            print('Thread-2')\n",
    "\n",
    "t1 = threading.Thread(target=thread_1)\n",
    "t1.daemon = True\n",
    "t1.start()\n",
    "\n",
    "t2 = threading.Thread(target=thread_2)\n",
    "t2.daemon = True\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你执行这段代码，你会发现它即使在不同的函数中以不同的顺序获取锁也没有发生死锁。 \n",
    "\n",
    "其关键在于，在第一段代码中，我们对这些锁进行了排序。\n",
    "\n",
    "通过排序，使得不管用户以什么样的顺序来请求锁，这些锁都会按照固定的顺序被获取。 \n",
    "\n",
    "如果有多个 `acquire()` 操作被**嵌套**调用，可以通过线程本地存储 `（TLS）` 来检测潜在的死锁问题。 \n",
    "\n",
    "假设你的代码是这样写的: \n",
    "```py\n",
    "import threading\n",
    "x_lock = threading.Lock()\n",
    "y_lock = threading.Lock()\n",
    "\n",
    "def thread_1():\n",
    "\n",
    "    while True:\n",
    "        with acquire(x_lock):\n",
    "            with acquire(y_lock):\n",
    "                print('Thread-1')\n",
    "\n",
    "def thread_2():\n",
    "    while True:\n",
    "        with acquire(y_lock):\n",
    "            with acquire(x_lock):\n",
    "                print('Thread-2')\n",
    "\n",
    "t1 = threading.Thread(target=thread_1)\n",
    "t1.daemon = True\n",
    "t1.start()\n",
    "\n",
    "t2 = threading.Thread(target=thread_2)\n",
    "t2.daemon = True\n",
    "t2.start()\n",
    "```\n",
    "\n",
    "必定会有一个线程发生崩溃\n",
    "\n",
    "```py\n",
    "Exception in thread Thread-45:\n",
    "Traceback (most recent call last):\n",
    "  File \"D:\\anaconda\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
    "    self.run()\n",
    "  File \"D:\\anaconda\\lib\\threading.py\", line 864, in run\n",
    "    self._target(*self._args, **self._kwargs)\n",
    "  File \"<ipython-input-49-bb2fb04bd3bb>\", line 15, in thread_2\n",
    "    with acquire(x_lock):\n",
    "  File \"D:\\anaconda\\lib\\contextlib.py\", line 81, in __enter__\n",
    "    return next(self.gen)\n",
    "  File \"<ipython-input-47-57757de4db3d>\", line 15, in acquire\n",
    "    raise RuntimeError('Lock Order Violation')\n",
    "RuntimeError: Lock Order Violation\n",
    "```\n",
    "\n",
    "发生崩溃的原因在于，每个线程都记录着自己已经获取到的锁。\n",
    "\n",
    "`acquire()` 函数会检查之前已经获取的锁列表， 由于锁是按照升序排列获取的，所以函数会认为之前已获取的锁的 `id` 必定小于新申请到的锁，这时就会触发异常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "下面以一个关于线程死锁的经典问题：“哲学家就餐问题”，作为本节最后一个例子。\n",
    "\n",
    "题目是这样的：\n",
    "\n",
    "五位哲学家围坐在一张桌子前，每个人 面前有一碗饭和一只筷子。\n",
    "\n",
    "在这里每个哲学家可以看做是一个独立的线程，而每只筷子可以看做是一个锁。\n",
    "\n",
    "每个哲学家可以处在静坐、 思考、吃饭三种状态中的一个。\n",
    "\n",
    "需要注意的是，每个哲学家吃饭是需要两只筷子的，这样问题就来了：如果每个哲学家都拿起自己左边的筷子， 那么他们五个都只能拿着一只筷子坐在那儿，直到饿死。\n",
    "\n",
    "此时他们就进入了死锁状态。 \n",
    "\n",
    "下面是一个简单的使用死锁避免机制解决“哲学家就餐问题”的实现：\n",
    "\n",
    "\n",
    "```py\n",
    "import threading\n",
    "\n",
    "# The philosopher thread\n",
    "def philosopher(left, right):\n",
    "    while True:\n",
    "        with acquire(left,right):\n",
    "             print(threading.currentThread(), 'eating')\n",
    "\n",
    "# The chopsticks (represented by locks)\n",
    "NSTICKS = 5\n",
    "chopsticks = [threading.Lock() for n in range(NSTICKS)]\n",
    "\n",
    "# Create all of the philosophers\n",
    "for n in range(NSTICKS):\n",
    "    t = threading.Thread(\n",
    "        target=philosopher,\n",
    "        args=(chopsticks[n],chopsticks[(n+1) % NSTICKS])\n",
    "    )\n",
    "    t.start()\n",
    "```\n",
    "    \n",
    "最后，要特别注意到，为了避免死锁，所有的加锁操作必须使用 `acquire()` 函数。如果代码中的某部分绕过 `acquire` 函数直接申请锁，那么整个死锁避免机制就不起作用了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存线程的状态信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时在多线程编程中，你需要只保存当前运行线程的状态。 \n",
    "\n",
    "要这么做，可使用 `thread.local()` 创建一个本地线程存储对象。 \n",
    "\n",
    "对这个对象的属性的保存和读取操作都只会对执行线程可见，而其他线程并不可见。\n",
    "\n",
    "作为使用本地存储的一个有趣的实际例子， 考虑在 `8.3小节` 定义过的 `LazyConnection` 上下文管理器类。 \n",
    "\n",
    "下面我们对它进行一些小的修改使得它可以适用于多线程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:10:33.541659Z",
     "start_time": "2019-10-02T16:10:33.523156Z"
    }
   },
   "outputs": [],
   "source": [
    "from socket import socket, AF_INET, SOCK_STREAM\n",
    "import threading\n",
    "\n",
    "class LazyConnection:\n",
    "    def __init__(self, address, family=AF_INET, type=SOCK_STREAM):\n",
    "        self.address = address\n",
    "        self.family = AF_INET\n",
    "        self.type = SOCK_STREAM\n",
    "        self.local = threading.local()\n",
    "\n",
    "    def __enter__(self):\n",
    "        if hasattr(self.local, 'sock'):\n",
    "            raise RuntimeError('Already connected')\n",
    "        self.local.sock = socket(self.family, self.type)\n",
    "        self.local.sock.connect(self.address)\n",
    "        return self.local.sock\n",
    "\n",
    "    def __exit__(self, exc_ty, exc_val, tb):\n",
    "        self.local.sock.close()\n",
    "        del self.local.sock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码中，自己观察对于 `self.local` 属性的使用。\n",
    "\n",
    "它被初始化为一个 `threading.local()` 实例。 \n",
    "\n",
    "其他方法操作被存储为 `self.local.sock` 的套接字对象。 \n",
    "\n",
    "有了这些就可以在多线程中安全的使用 `LazyConnection` 实例了。\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:10:34.880236Z",
     "start_time": "2019-10-02T16:10:34.591558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 392 bytes\n",
      "Got 392 bytes\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "def test(conn):\n",
    "    with conn as s:\n",
    "        s.send(b'GET /index.html HTTP/1.0\\r\\n')\n",
    "        s.send(b'Host: www.python.org\\r\\n')\n",
    "\n",
    "        s.send(b'\\r\\n')\n",
    "        resp = b''.join(iter(partial(s.recv, 8192), b''))\n",
    "\n",
    "    print('Got {} bytes'.format(len(resp)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conn = LazyConnection(('www.python.org', 80))\n",
    "\n",
    "    t1 = threading.Thread(target=test, args=(conn,))\n",
    "    t2 = threading.Thread(target=test, args=(conn,))\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t1.join()\n",
    "    t2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它之所以行得通的原因是每个线程会创建一个自己专属的套接字连接（存储为 `self.local.sock` ）。 \n",
    "\n",
    "因此，当不同的线程执行套接字操作时，由于操作的是不同的套接字，因此它们不会相互影响。\n",
    "\n",
    "## 讨论\n",
    "\n",
    "当出了问题的时候，通常是因为某个对象被多个线程使用到，用来操作一些专用的系统资源， 比如一个套接字或文件。\n",
    "\n",
    "你不能让所有线程共享一个单独对象， 因为多个线程同时读和写的时候会产生混乱。\n",
    "\n",
    "本地线程存储通过让这些资源只能在被使用的线程中可见来解决这个问题。\n",
    "\n",
    "本节中，使用 `thread.local()` 可以让 `LazyConnection` 类支持一个线程一个连接， 而不是对于所有的进程都只有一个连接。\n",
    "\n",
    "其原理是，每个 `threading.local()` 实例为每个线程维护着一个单独的实例字典。\n",
    "\n",
    "所有普通实例操作比如获取、修改和删除值仅仅操作这个字典。 \n",
    "\n",
    "每个线程使用一个独立的字典就可以保证数据的隔离了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建一个线程池"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`concurrent.futures` 函数库有一个 `ThreadPoolExecutor` 类可以被用来完成这个任务。 下面是一个简单的 `TCP` 服务器，使用了一个线程池来响应客户端："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-02T16:27:51.246Z"
    }
   },
   "outputs": [],
   "source": [
    "from socket import AF_INET, SOCK_STREAM, socket\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def echo_client(sock, client_addr):\n",
    "    '''\n",
    "    Handle a client connection\n",
    "    '''\n",
    "    print('Got connection from', client_addr)\n",
    "    while True:\n",
    "        msg = sock.recv(65536)\n",
    "        if not msg:\n",
    "            break\n",
    "        sock.sendall(msg)\n",
    "    print('Client closed connection')\n",
    "    sock.close()\n",
    "\n",
    "def echo_server(addr):\n",
    "    pool = ThreadPoolExecutor(128)\n",
    "    sock = socket(AF_INET, SOCK_STREAM)\n",
    "    sock.bind(addr)\n",
    "    sock.listen(5)\n",
    "    while True:\n",
    "        client_sock, client_addr = sock.accept()\n",
    "        pool.submit(echo_client, client_sock, client_addr)\n",
    "\n",
    "echo_server(('',15000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想手动创建你自己的线程池， 通常可以使用一个 `Queue` 来轻松实现。\n",
    "\n",
    "下面是一个稍微不同但是手动实现的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from socket import socket, AF_INET, SOCK_STREAM\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "def echo_client(q):\n",
    "    '''\n",
    "    Handle a client connection\n",
    "    '''\n",
    "    sock, client_addr = q.get()\n",
    "    print('Got connection from', client_addr)\n",
    "    while True:\n",
    "        msg = sock.recv(65536)\n",
    "        if not msg:\n",
    "            break\n",
    "        sock.sendall(msg)\n",
    "    print('Client closed connection')\n",
    "\n",
    "    sock.close()\n",
    "\n",
    "def echo_server(addr, nworkers):\n",
    "    # Launch the client workers\n",
    "    q = Queue()\n",
    "    for n in range(nworkers):\n",
    "        t = Thread(target=echo_client, args=(q,))\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "\n",
    "    # Run the server\n",
    "    sock = socket(AF_INET, SOCK_STREAM)\n",
    "    sock.bind(addr)\n",
    "    sock.listen(5)\n",
    "    while True:\n",
    "        client_sock, client_addr = sock.accept()\n",
    "        q.put((client_sock, client_addr))\n",
    "\n",
    "echo_server(('',15000), 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [資料，例子沒有執行][concurrent.futures.ProcessPoolExecutor]简单的并行编程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`concurrent.futures` 库提供了一个 `ProcessPoolExecutor` 类， 可被用来在一个单独的 `Python` 解释器中执行计算密集型函数。\n",
    "\n",
    "不过，要使用它，你首先要有一些计算密集型的任务。 \n",
    "\n",
    "我们通过一个简单而实际的例子来演示它。假定你有个 `Apache web` 服务器日志目录的 `gzip` 压缩包：\n",
    "\n",
    "```\n",
    "logs/\n",
    "   20120701.log.gz\n",
    "   20120702.log.gz\n",
    "   20120703.log.gz\n",
    "   20120704.log.gz\n",
    "   20120705.log.gz\n",
    "   20120706.log.gz\n",
    "   ...\n",
    "```\n",
    "\n",
    "进一步假设每个日志文件内容类似下面这样：\n",
    "\n",
    "```\n",
    "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
    "210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] \"GET /ply/ ...\" 200 11875\n",
    "210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] \"GET /favicon.ico ...\" 404 369\n",
    "61.135.216.105 - - [10/Jul/2012:00:20:04 -0500] \"GET /blog/atom.xml ...\" 304 -\n",
    "...\n",
    "```\n",
    "\n",
    "下面是一个脚本，在这些日志文件中查找出所有访问过 `robots.txt` 文件的主机：\n",
    "  \n",
    "```py\n",
    "# findrobots.py\n",
    "\n",
    "import gzip\n",
    "import io\n",
    "import glob\n",
    "\n",
    "def find_robots(filename):\n",
    "    '''\n",
    "    Find all of the hosts that access robots.txt in a single log file\n",
    "    '''\n",
    "    robots = set()\n",
    "    with gzip.open(filename) as f:\n",
    "        for line in io.TextIOWrapper(f,encoding='ascii'):\n",
    "            fields = line.split()\n",
    "            if fields[6] == '/robots.txt':\n",
    "                robots.add(fields[0])\n",
    "    return robots\n",
    "\n",
    "def find_all_robots(logdir):\n",
    "    '''\n",
    "    Find all hosts across and entire sequence of files\n",
    "    '''\n",
    "    files = glob.glob(logdir+'/*.log.gz')\n",
    "    all_robots = set()\n",
    "    for robots in map(find_robots, files):\n",
    "        all_robots.update(robots)\n",
    "    return all_robots\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    robots = find_all_robots('logs')\n",
    "    for ipaddr in robots:\n",
    "        print(ipaddr)\n",
    "```\n",
    "\n",
    "前面的程序使用了通常的 `map-reduce` 风格来编写。 \n",
    "\n",
    "函数 `find_robots()` 在一个文件名集合上做map操作，并将结果汇总为一个单独的结果， 也就是 `find_all_robots()` 函数中的 `all_robots` 集合。\n",
    "\n",
    "现在，假设你想要修改这个程序让它使用多核 `CPU` 。 很简单——只需要将 `map()` 操作替换为一个 `concurrent.futures` 库中生成的类似操作即可。 \n",
    "\n",
    "下面是一个简单修改版本：\n",
    "  \n",
    "```py\n",
    "# findrobots.py\n",
    "\n",
    "import gzip\n",
    "import io\n",
    "import glob\n",
    "from concurrent import futures\n",
    "\n",
    "def find_robots(filename):\n",
    "    '''\n",
    "    Find all of the hosts that access robots.txt in a single log file\n",
    "\n",
    "    '''\n",
    "    robots = set()\n",
    "    with gzip.open(filename) as f:\n",
    "        for line in io.TextIOWrapper(f,encoding='ascii'):\n",
    "            fields = line.split()\n",
    "            if fields[6] == '/robots.txt':\n",
    "                robots.add(fields[0])\n",
    "    return robots\n",
    "\n",
    "def find_all_robots(logdir):\n",
    "    '''\n",
    "    Find all hosts across and entire sequence of files\n",
    "    '''\n",
    "    files = glob.glob(logdir+'/*.log.gz')\n",
    "    all_robots = set()\n",
    "    with futures.ProcessPoolExecutor() as pool:\n",
    "        for robots in pool.map(find_robots, files):\n",
    "            all_robots.update(robots)\n",
    "    return all_robots\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    robots = find_all_robots('logs')\n",
    "    for ipaddr in robots:\n",
    "```\n",
    "\n",
    "## 讨论\n",
    "\n",
    "`ProcessPoolExecutor` 的典型用法如下：\n",
    "\n",
    "```py\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "with ProcessPoolExecutor() as pool:\n",
    "    ...\n",
    "    do work in parallel using pool\n",
    "    ...\n",
    "```    \n",
    "    \n",
    "其原理是，一个 `ProcessPoolExecutor` 创建 `N` 个独立的 `Python` 解释器， `N` 是系统上面可用 `CPU` 的个数。你可以通过提供可选参数给 `ProcessPoolExecutor(N)` 来修改 处理器数量。\n",
    "\n",
    "这个处理池会一直运行到 `with` 块中最后一个语句执行完成， 然后处理池被关闭。\n",
    "\n",
    "不过，程序会一直等待直到所有提交的工作被处理完成。\n",
    "\n",
    "---\n",
    "\n",
    "被提交到池中的工作必须被定义为一个函数。有两种方法去提交。 如果你想让一个列表推导或一个 `map()` 操作并行执行的话，可使用 `pool.map()` :\n",
    "\n",
    "```py\n",
    "# A function that performs a lot of work\n",
    "def work(x):\n",
    "    ...\n",
    "    return result\n",
    "\n",
    "# Nonparallel code\n",
    "results = map(work, data)\n",
    "\n",
    "# Parallel implementation\n",
    "with ProcessPoolExecutor() as pool:\n",
    "    results = pool.map(work, data)\n",
    "```    \n",
    "\n",
    "---\n",
    "    \n",
    "另外，你可以使用 `pool.submit()` 来手动的提交单个任务：\n",
    "\n",
    "```py\n",
    "# Some function\n",
    "def work(x):\n",
    "    ...\n",
    "    return result\n",
    "\n",
    "with ProcessPoolExecutor() as pool:\n",
    "    ...\n",
    "    # Example of submitting work to the pool\n",
    "    future_result = pool.submit(work, arg)\n",
    "\n",
    "    # Obtaining the result (blocks until done)\n",
    "    r = future_result.result()\n",
    "    ...\n",
    "```\n",
    "\n",
    "如果你手动提交一个任务，结果是一个 `Future` 实例。 \n",
    "\n",
    "要获取最终结果，你需要调用它的 `result()` 方法。 \n",
    "\n",
    "它会阻塞进程直到结果被返回来。\n",
    "\n",
    "如果不想阻塞，你还可以使用一个回调函数，例如：\n",
    "\n",
    "```py\n",
    "def when_done(r):\n",
    "    print('Got:', r.result())\n",
    "\n",
    "with ProcessPoolExecutor() as pool:\n",
    "     future_result = pool.submit(work, arg)\n",
    "     future_result.add_done_callback(when_done)\n",
    "```\n",
    "\n",
    "回调函数接受一个 `Future` 实例，被用来获取最终的结果（比如通过调用它的 `result()` 方法）。 \n",
    "\n",
    "尽管处理池很容易使用，在设计大程序的时候还是有很多需要注意的地方，如下几点：\n",
    "\n",
    "* 这种并行处理技术只适用于那些可以被分解为互相独立部分的问题。\n",
    "\n",
    "* 被提交的任务必须是简单函数形式。对于方法、闭包和其他类型的并行执行还不支持。\n",
    "\n",
    "* 函数参数和返回值必须兼容 `pickle`，因为要使用到进程间的通信，所有解释器之间的交换数据必须被序列化\n",
    "\n",
    "* 被提交的任务函数不应保留状态或有副作用。除了打印日志之类简单的事情，一旦启动你不能控制子进程的任何行为，因此最好保持简单和纯洁——函数不要去修改环境。\n",
    "\n",
    "在`Unix`上进程池通过调用 `fork()` 系统调用被创建，\n",
    "\n",
    "它会克隆 `Python` 解释器，包括 `fork` 时的所有程序状态。 \n",
    "\n",
    "而在 `Windows` 上，克隆解释器时不会克隆状态。 实际的 `fork` 操作会在第一次调用 `pool.map()` 或 `pool.submit()` 后发生。\n",
    "\n",
    "当你混合使用进程池和多线程的时候要特别小心。\n",
    "\n",
    "你应该在创建任何线程之前先创建并激活进程池（比如在程序启动的 `main` 线程中创建进程池）。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python的全局锁问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在讨论普通的 `GIL` 之前，有一点要强调的是 `GIL` 只会影响到那些严重依赖 `CPU` 的程序（比如计算型的）。\n",
    "\n",
    "如果你的程序大部分只会涉及到 `I/O` ，比如网络交互，那么使用多线程就很合适， 因为它们大部分时间都在等待。\n",
    "\n",
    "实际上，你完全可以放心的创建几千个 `Python` 线程， 现代操作系统运行这么多线程没有任何压力，没啥可担心的。\n",
    "\n",
    "而对于依赖 `CPU` 的程序，你需要弄清楚执行的计算的特点。 \n",
    "\n",
    "例如，优化底层算法要比使用多线程运行快得多。 \n",
    "\n",
    "类似的，由于 `Python` 是解释执行的，如果你将那些性能瓶颈代码移到一个 `C` 语言扩展模块中， 速度也会提升的很快。\n",
    "\n",
    "如果你要操作数组，那么使用 `NumPy` 这样的扩展会非常的高效。\n",
    "\n",
    "---\n",
    "\n",
    "还有一点要注意的是，线程不是专门用来优化性能的。\n",
    "\n",
    "一个 `CPU` 依赖型程序可能会使用线程来管理一个图形用户界面、一个网络连接或其他服务。 这时候， `GIL` 会产生一些问题，因为如果一个线程长期持有 `GIL` 的话会导致其他非 `CPU` 型线程一直等待。 \n",
    "\n",
    "事实上，一个写的不好的 `C` 语言扩展会导致这个问题更加严重， 尽管代码的计算部分会比之前运行的更快些。\n",
    "\n",
    "---\n",
    "\n",
    "**multiprocessing**\n",
    "\n",
    "现在想说的是我们有两种策略来解决 `GIL`  的缺点。 首先，如果你完全工作于 `Python` 环境中，你可以使用 `multiprocessing` 模块来创建一个进程池， 并像协同处理器一样的使用它。\n",
    "\n",
    "例如，假如你有如下的线程代码：\n",
    "\n",
    "```py\n",
    "# Performs a large calculation (CPU bound)\n",
    "def some_work(args):\n",
    "    ...\n",
    "    return result\n",
    "\n",
    "# A thread that calls the above function\n",
    "def some_thread():\n",
    "    while True:\n",
    "        ...\n",
    "        r = some_work(args)\n",
    "    ...\n",
    "```\n",
    "\n",
    "修改代码，使用进程池：\n",
    "\n",
    "```py\n",
    "# Processing pool (see below for initiazation)\n",
    "pool = None\n",
    "\n",
    "# Performs a large calculation (CPU bound)\n",
    "def some_work(args):\n",
    "    ...\n",
    "    return result\n",
    "\n",
    "# A thread that calls the above function\n",
    "def some_thread():\n",
    "    while True:\n",
    "        ...\n",
    "        r = pool.apply(some_work, (args))\n",
    "        ...\n",
    "\n",
    "# Initiaze the pool\n",
    "if __name__ == '__main__':\n",
    "    import multiprocessing\n",
    "    pool = multiprocessing.Pool()\n",
    "```\n",
    "\n",
    "这个通过使用一个技巧利用进程池解决了 `GIL` 的问题。\n",
    "\n",
    "当一个线程想要执行 `CPU` 密集型工作时，会将任务发给进程池。 \n",
    "\n",
    "然后进程池会在另外一个进程中启动一个单独的 `Python` 解释器来工作。 \n",
    "\n",
    "当线程等待结果的时候会释放 `GIL`。 \n",
    "\n",
    "并且，由于计算任务在单独解释器中执行，那么就不会受限于 `GIL` 了。\n",
    "\n",
    "如果你准备使用一个处理器池，注意的是这样做涉及到数据序列化和在不同 `Python` 解释器通信。 \n",
    "\n",
    "被执行的操作需要放在一个通过 `def` 语句定义的 `Python` 函数中，不能是 `lambda` 、闭包可调用实例等， 并且函数参数和返回值必须要兼容 `pickle` 。 \n",
    "\n",
    "同样， **要执行的任务量必须足够大以弥补额外的通信开销。**\n",
    "\n",
    "另外一个难点是当混合使用线程和进程池的时候会让你很头疼。 \n",
    "\n",
    "如果你要同时使用两者，最好在程序启动时， **创建任何线程之前先创建一个单例的进程池** 。 然后线程使用同样的进程池来进行它们的计算密集型工作。\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**C扩展**\n",
    "\n",
    "另外一个解决 `GIL` 的策略是使用 `C` 扩展编程技术。 主要思想是将计算密集型任务转移给 `C` ，跟 `Python` 独立，在工作的时候在 `C` 代码中释放 `GIL` 。 \n",
    "\n",
    "这可以通过在 `C` 代码中插入下面这样的特殊宏来完成：\n",
    "\n",
    "```py\n",
    "#include \"Python.h\"\n",
    "...\n",
    "\n",
    "PyObject *pyfunc(PyObject *self, PyObject *args) {\n",
    "   ...\n",
    "   Py_BEGIN_ALLOW_THREADS\n",
    "   // Threaded C code\n",
    "   ...\n",
    "   Py_END_ALLOW_THREADS\n",
    "   ...\n",
    "}\n",
    "```\n",
    "\n",
    " `C` 扩展最重要的特征是它们和 `Python` 解释器是保持独立的。 \n",
    " \n",
    "也就是说，如果你准备将 `Python` 中的任务分配到 `C` 中去执行， 你需要确保 `C` 代码的操作跟 `Python` 保持独立， 这就意味着不要使用 `Python数据结构` 以及不要调用 `Python的C API` 。 \n",
    "\n",
    "另外一个就是你要确保 `C` 扩展所做的工作是足够的，值得你这样做。 也就是说 `C` 扩展担负起了大量的计算任务，而不是少数几个计算。\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Cython**\n",
    "\n",
    "如果你使用其他工具访问 `C` 语言，比如对于 `Cython` 的 `ctypes` 库，你不需要做任何事。 例如， `ctypes` 在调用 `C` 时会自动释放 `GIL` 。\n",
    "\n",
    "---\n",
    "\n",
    "这些解决 `GIL` 的方案并不能适用于所有问题。 例如，某些类型的应用程序如果被分解为多个进程处理的话并不能很好的工作， 也不能将它的部分代码改成C语言执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义一个Actor任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`actor` 模式是一种最古老的也是最简单的并行和分布式计算解决方案。\n",
    "\n",
    "简单来讲，一个 `actor` 就是一个并发执行的任务，只是简单的执行发送给它的消息任务。 \n",
    "\n",
    "响应这些消息时，它可能还会给其他 `actor` 发送更进一步的消息。 \n",
    "\n",
    "`actor` 之间的通信是单向和异步的。\n",
    "\n",
    "因此，消息发送者不知道消息是什么时候被发送， 也不会接收到一个消息已被处理的回应或通知。\n",
    "\n",
    "结合使用一个线程和一个队列可以很容易的定义 `actor` ，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:16:39.772354Z",
     "start_time": "2019-10-07T15:16:39.092201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: Hello\n",
      "Got: World\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread, Event\n",
    "\n",
    "# Sentinel used for shutdown\n",
    "class ActorExit(Exception):\n",
    "    pass\n",
    "\n",
    "class Actor:\n",
    "    def __init__(self):\n",
    "        self._mailbox = Queue()\n",
    "\n",
    "    def send(self, msg):\n",
    "        '''\n",
    "        Send a message to the actor\n",
    "        '''\n",
    "        self._mailbox.put(msg)\n",
    "\n",
    "    def recv(self):\n",
    "        '''\n",
    "        Receive an incoming message\n",
    "        '''\n",
    "        msg = self._mailbox.get()\n",
    "        if msg is ActorExit:\n",
    "            raise ActorExit()\n",
    "        return msg\n",
    "\n",
    "    def close(self):\n",
    "        '''\n",
    "        Close the actor, thus shutting it down\n",
    "        '''\n",
    "        self.send(ActorExit)\n",
    "\n",
    "    def start(self):\n",
    "        '''\n",
    "        Start concurrent execution\n",
    "        '''\n",
    "        self._terminated = Event()\n",
    "        t = Thread(target=self._bootstrap)\n",
    "\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "\n",
    "    def _bootstrap(self):\n",
    "        try:\n",
    "            self.run()\n",
    "        except ActorExit:\n",
    "            pass\n",
    "        finally:\n",
    "            self._terminated.set()\n",
    "\n",
    "    def join(self):\n",
    "        self._terminated.wait()\n",
    "\n",
    "    def run(self):\n",
    "        '''\n",
    "        Run method to be implemented by the user\n",
    "        '''\n",
    "        while True:\n",
    "            msg = self.recv()\n",
    "\n",
    "# Sample ActorTask\n",
    "class PrintActor(Actor):\n",
    "    def run(self):\n",
    "        while True:\n",
    "            msg = self.recv()\n",
    "            print('Got:', msg)\n",
    "\n",
    "# Sample use\n",
    "p = PrintActor()\n",
    "p.start()\n",
    "p.send('Hello')\n",
    "p.send('World')\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用户可以通过继承 `Actor` 并定义实现自己处理逻辑 `run()` 方法来定义新的 `actor` 。 \n",
    "\n",
    "`ActorExit` 异常的使用就是用户自定义代码可以在需要的时候来捕获终止请求 （异常被 `get()` 方法抛出并传播出去）。\n",
    "\n",
    "如果你放宽对于同步和异步消息发送的要求， 类 `actor` 对象还可以通过生成器来简化定义。\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:28:00.019644Z",
     "start_time": "2019-10-07T15:27:57.222136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: Hello\n",
      "Got: World\n",
      "Actor terminating\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "generator ignored GeneratorExit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5b669dc3f761>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Hello'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'World'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: generator ignored GeneratorExit"
     ]
    }
   ],
   "source": [
    "def print_actor():\n",
    "    while True:\n",
    "        try:\n",
    "            # Get a message\n",
    "            msg = yield      \n",
    "            print('Got:', msg)\n",
    "        except GeneratorExit:\n",
    "            print('Actor terminating')\n",
    "\n",
    "# Sample use\n",
    "p = print_actor()\n",
    "\n",
    "# Advance to the yield (ready to receive)\n",
    "next(p)     \n",
    "\n",
    "p.send('Hello')\n",
    "p.send('World')\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "`actor` 模式的魅力就在于它的简单性。 \n",
    "\n",
    "实际上，这里仅仅只有一个核心操作 `send()` . 甚至，对于在基于 `actor` 系统中的“消息”的泛化概念可以已多种方式被扩展。\n",
    "\n",
    "例如，你可以以元组形式传递标签消息，让 `actor` 执行不同的操作，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:44:47.308438Z",
     "start_time": "2019-10-07T15:44:47.297702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running A 1\n",
      "Running B 2 3\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread, Event\n",
    "\n",
    "# Sentinel used for shutdown\n",
    "class ActorExit(Exception):\n",
    "    pass\n",
    "\n",
    "class Actor:\n",
    "    def __init__(self):\n",
    "        self._mailbox = Queue()\n",
    "\n",
    "    def send(self, msg):\n",
    "        '''\n",
    "        Send a message to the actor\n",
    "        '''\n",
    "        self._mailbox.put(msg)\n",
    "\n",
    "    def recv(self):\n",
    "        '''\n",
    "        Receive an incoming message\n",
    "        '''\n",
    "        msg = self._mailbox.get()\n",
    "        if msg is ActorExit:\n",
    "            raise ActorExit()\n",
    "        return msg\n",
    "\n",
    "    def close(self):\n",
    "        '''\n",
    "        Close the actor, thus shutting it down\n",
    "        '''\n",
    "        self.send(ActorExit)\n",
    "\n",
    "    def start(self):\n",
    "        '''\n",
    "        Start concurrent execution\n",
    "        '''\n",
    "        self._terminated = Event()\n",
    "        t = Thread(target=self._bootstrap)\n",
    "\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "\n",
    "    def _bootstrap(self):\n",
    "        try:\n",
    "            self.run()\n",
    "        except ActorExit:\n",
    "            pass\n",
    "        finally:\n",
    "            self._terminated.set()\n",
    "\n",
    "    def join(self):\n",
    "        self._terminated.wait()\n",
    "\n",
    "    def run(self):\n",
    "        '''\n",
    "        Run method to be implemented by the user\n",
    "        '''\n",
    "        while True:\n",
    "            msg = self.recv()\n",
    "\n",
    "\n",
    "class TaggedActor(Actor):\n",
    "    def run(self):\n",
    "        while True:\n",
    "            tag, *payload = self.recv()\n",
    "            getattr(self,'do_'+tag)(*payload)\n",
    "\n",
    "    # Methods correponding to different message tags\n",
    "    def do_A(self, x):\n",
    "        print('Running A', x)\n",
    "\n",
    "    def do_B(self, x, y):\n",
    "        print('Running B', x, y)\n",
    "\n",
    "# Example\n",
    "a = TaggedActor()\n",
    "a.start()\n",
    "a.send(('A', 1))      # Invokes do_A(1)\n",
    "a.send(('B', 2, 3))   # Invokes do_B(2,3)\n",
    "a.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为另外一个例子，下面的 `actor` 允许在一个工作者中运行任意的函数， 并且通过一个特殊的 `Result` 对象返回结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Event\n",
    "class Result:\n",
    "    def __init__(self):\n",
    "        self._evt = Event()\n",
    "        self._result = None\n",
    "\n",
    "    def set_result(self, value):\n",
    "        self._result = value\n",
    "\n",
    "        self._evt.set()\n",
    "\n",
    "    def result(self):\n",
    "        self._evt.wait()\n",
    "        return self._result\n",
    "\n",
    "class Worker(Actor):\n",
    "    def submit(self, func, *args, **kwargs):\n",
    "        r = Result()\n",
    "        self.send((func, args, kwargs, r))\n",
    "        return r\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            func, args, kwargs, r = self.recv()\n",
    "            r.set_result(func(*args, **kwargs))\n",
    "\n",
    "# Example use\n",
    "worker = Worker()\n",
    "worker.start()\n",
    "r = worker.submit(pow, 2, 3)\n",
    "print(r.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，“发送”一个任务消息的概念可以被扩展到多进程甚至是大型分布式系统中去。\n",
    "\n",
    "例如，一个类 `actor` 对象的 `send()` 方法可以被编程让它能在一个套接字连接上传输数据 或通过某些消息中间件（比如 `AMQP` 、 `ZMQ` 等）来发送。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现消息发布/订阅模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要实现发布/订阅的消息通信模式， 你通常要引入一个单独的“交换机”或“网关”对象作为所有消息的中介。 \n",
    "\n",
    "也就是说，不直接将消息从一个任务发送到另一个，而是将其发送给交换机， 然后由交换机将它发送给一个或多个被关联任务。\n",
    "\n",
    "下面是一个非常简单的交换机实现例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T14:25:57.238228Z",
     "start_time": "2019-10-08T14:25:57.233348Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Exchange:\n",
    "    def __init__(self):\n",
    "        self._subscribers = set()\n",
    "\n",
    "    def attach(self, task):\n",
    "        self._subscribers.add(task)\n",
    "\n",
    "    def detach(self, task):\n",
    "        self._subscribers.remove(task)\n",
    "\n",
    "    def send(self, msg):\n",
    "        for subscriber in self._subscribers:\n",
    "            subscriber.send(msg)\n",
    "\n",
    "# Dictionary of all created exchanges\n",
    "_exchanges = defaultdict(Exchange)\n",
    "\n",
    "# Return the Exchange instance associated with a given name\n",
    "def get_exchange(name):\n",
    "    return _exchanges[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个交换机就是一个普通对象，负责维护一个活跃的订阅者集合，并为绑定、解绑和发送消息提供相应的方法。 \n",
    "\n",
    "每个交换机通过一个名称定位， `get_exchange()` 通过给定一个名称返回相应的 `Exchange` 实例。\n",
    "\n",
    "下面是一个简单例子，演示了如何使用一个交换机："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T14:25:58.571720Z",
     "start_time": "2019-10-08T14:25:58.564889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A msg1\n",
      "B msg1\n",
      "------\n",
      "A msg2\n",
      "B msg2\n"
     ]
    }
   ],
   "source": [
    "# Example of a task.  Any object with a send() method\n",
    "\n",
    "class Task:\n",
    "    def __init__(self,Name):\n",
    "        self.Name = Name\n",
    "    \n",
    "    def send(self, msg):\n",
    "        print(self.Name ,msg)\n",
    "\n",
    "task_a = Task(\"A\")\n",
    "task_b = Task(\"B\")\n",
    "\n",
    "# Example of getting an exchange\n",
    "exc = get_exchange('name')\n",
    "\n",
    "# Examples of subscribing tasks to it\n",
    "exc.attach(task_a)\n",
    "exc.attach(task_b)\n",
    "\n",
    "# Example of sending messages\n",
    "exc.send('msg1')\n",
    "print(\"------\")\n",
    "exc.send('msg2')\n",
    "\n",
    "# Example of unsubscribing\n",
    "exc.detach(task_a)\n",
    "exc.detach(task_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "通过 *队列发送消息的任务* 或 *线程* 的模式很容易被实现并且也非常普遍。 \n",
    "\n",
    "不过，使用 **发布/订阅模式** 的好处更加明显。\n",
    "\n",
    "首先，使用一个交换机可以简化大部分涉及到线程通信的工作。 \n",
    "\n",
    "无需去写通过多进程模块来操作多个线程，你只需要使用这个交换机来连接它们。 \n",
    "\n",
    "某种程度上，这个就跟日志模块的工作原理类似。 实际上，它可以轻松的解耦程序中多个任务。\n",
    "\n",
    "其次，交换机广播消息给多个订阅者的能力带来了一个全新的通信模式。 \n",
    "\n",
    "例如，你可以使用多任务系统、广播或扇出。 你还可以通过以普通订阅者身份绑定来构建调试和诊断工具。 \n",
    "\n",
    "例如，下面是一个简单的诊断类，可以显示被发送的消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T14:32:37.493253Z",
     "start_time": "2019-10-08T14:32:37.486421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg[1]: 'msg1'\n",
      "msg[2]: 'msg11'\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Exchange:\n",
    "    def __init__(self):\n",
    "        self._subscribers = set()\n",
    "\n",
    "    def attach(self, task):\n",
    "        self._subscribers.add(task)\n",
    "\n",
    "    def detach(self, task):\n",
    "        self._subscribers.remove(task)\n",
    "\n",
    "    def send(self, msg):\n",
    "        for subscriber in self._subscribers:\n",
    "            subscriber.send(msg)\n",
    "\n",
    "# Dictionary of all created exchanges\n",
    "_exchanges = defaultdict(Exchange)\n",
    "\n",
    "# Return the Exchange instance associated with a given name\n",
    "def get_exchange(name):\n",
    "    return _exchanges[name]\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "class DisplayMessages:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "    def send(self, msg):\n",
    "        self.count += 1\n",
    "        print('msg[{}]: {!r}'.format(self.count, msg))\n",
    "\n",
    "exc = get_exchange('name')\n",
    "d = DisplayMessages()\n",
    "exc.attach(d)\n",
    "exc.send('msg1')\n",
    "exc.send('msg11')\n",
    "exc.detach(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，该实现的一个重要特点是它能兼容多个 `“task-like”对象` 。 \n",
    "\n",
    "例如，消息接受者可以是 `actor（12.10小节介绍）` 、协程、网络连接或任何实现了正确的 `send()` 方法的东西。\n",
    "\n",
    "关于交换机的一个可能问题是对于订阅者的 `正确绑定和解绑` 。 \n",
    "\n",
    "为了正确的管理资源，每一个绑定的订阅者必须最终要解绑。 在代码中通常会是像下面这样的模式：\n",
    "\n",
    "```py\n",
    "exc = get_exchange('name')\n",
    "exc.attach(some_task)\n",
    "try:\n",
    "    ...\n",
    "finally:\n",
    "    exc.detach(some_task)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "某种意义上，这个和使用文件、锁和类似对象很像。 通常很容易会忘记最后的 detach() 步骤。 为了简化这个，你可以考虑使用上下文管理器协议。 例如，在交换机对象上增加一个 subscribe() 方法，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T14:36:30.922348Z",
     "start_time": "2019-10-08T14:36:30.914514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg[1]: 'msg1'\n",
      "msg[2]: 'msg2'\n"
     ]
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "\n",
    "class Exchange:\n",
    "    def __init__(self):\n",
    "        self._subscribers = set()\n",
    "\n",
    "    def attach(self, task):\n",
    "        self._subscribers.add(task)\n",
    "\n",
    "    def detach(self, task):\n",
    "        self._subscribers.remove(task)\n",
    "\n",
    "    @contextmanager\n",
    "    def subscribe(self, *tasks):\n",
    "        for task in tasks:\n",
    "            self.attach(task)\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            for task in tasks:\n",
    "                self.detach(task)\n",
    "\n",
    "    def send(self, msg):\n",
    "        for subscriber in self._subscribers:\n",
    "            subscriber.send(msg)\n",
    "\n",
    "# Dictionary of all created exchanges\n",
    "_exchanges = defaultdict(Exchange)\n",
    "\n",
    "# Return the Exchange instance associated with a given name\n",
    "def get_exchange(name):\n",
    "    return _exchanges[name]\n",
    "\n",
    "# --------------------------------------------\n",
    "\n",
    "\n",
    "class DisplayMessages:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "    def send(self, msg):\n",
    "        self.count += 1\n",
    "        print('msg[{}]: {!r}'.format(self.count, msg))\n",
    "\n",
    "exc = get_exchange('name')\n",
    "d = DisplayMessages()\n",
    "\n",
    "with exc.subscribe(d):\n",
    "    exc.send('msg1')\n",
    "    exc.send('msg2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后还应该注意的是关于交换机的思想有很多种的扩展实现。 \n",
    "\n",
    "例如，交换机可以实现一整个消息通道集合或提供交换机名称的模式匹配规则。 \n",
    "\n",
    "交换机还可以被扩展到分布式计算程序中（比如，将消息路由到不同机器上面的任务中去）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [yield]使用生成器代替线程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要使用生成器实现自己的并发，你首先要对生成器函数和 `yield` 语句有深刻理解。\n",
    "\n",
    "`yield` 语句会让一个生成器挂起它的执行，这样就可以编写一个调度器， 将生成器当做某种“任务”并使用任务协作切换来替换它们的执行。 \n",
    "\n",
    "要演示这种思想，考虑下面两个使用简单的 `yield` 语句的生成器函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T14:43:50.651597Z",
     "start_time": "2019-10-08T14:43:50.643790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 2\n",
      "T-minus 3\n",
      "Counting up 0\n",
      "T-minus 1\n",
      "T-minus 2\n",
      "Counting up 1\n",
      "Blastoff!\n",
      "T-minus 1\n",
      "Counting up 2\n",
      "Blastoff!\n",
      "Counting up 3\n"
     ]
    }
   ],
   "source": [
    "# Two simple generator functions\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        print('T-minus', n)\n",
    "        yield\n",
    "        n -= 1\n",
    "    print('Blastoff!')\n",
    "\n",
    "def countup(n):\n",
    "    x = 0\n",
    "    while x < n:\n",
    "        print('Counting up', x)\n",
    "        yield\n",
    "        x += 1\n",
    "\n",
    "# =========== 任務調度 ============\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class TaskScheduler:\n",
    "    def __init__(self):\n",
    "        self._task_queue = deque()\n",
    "\n",
    "    def new_task(self, task):\n",
    "        '''\n",
    "        Admit a newly started task to the scheduler\n",
    "\n",
    "        '''\n",
    "        self._task_queue.append(task)\n",
    "\n",
    "    def run(self):\n",
    "        '''\n",
    "        Run until there are no more tasks\n",
    "        '''\n",
    "        while self._task_queue:\n",
    "            task = self._task_queue.popleft()\n",
    "            try:\n",
    "                # Run until the next yield statement\n",
    "                next(task)\n",
    "                self._task_queue.append(task)\n",
    "            except StopIteration:\n",
    "                # Generator is no longer executing\n",
    "                pass\n",
    "\n",
    "# Example use\n",
    "sched = TaskScheduler()\n",
    "sched.new_task(countdown(2))\n",
    "sched.new_task(countdown(3))\n",
    "sched.new_task(countup(4))\n",
    "sched.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成器函数就是认为，而 `yield` 语句是任务挂起的信号。 调度器循环检查任务列表直到没有任务要执行为止。\n",
    "\n",
    "实际上，你可能想要使用生成器来实现简单的并发。 那么，在实现 `actor` 或网络服务器的时候你可以使用生成器来替代线程的使用。\n",
    "\n",
    "下面的代码演示了使用 **生成器** 来实现一个不依赖线程的 `actor` ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T14:46:49.219901Z",
     "start_time": "2019-10-08T14:46:49.212093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 3\n",
      "Got: 2\n",
      "Got: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ActorScheduler:\n",
    "    def __init__(self):\n",
    "        self._actors = { }          # Mapping of names to actors\n",
    "        self._msg_queue = deque()   # Message queue\n",
    "\n",
    "    def new_actor(self, name, actor):\n",
    "        '''\n",
    "        Admit a newly started actor to the scheduler and give it a name\n",
    "        '''\n",
    "        self._msg_queue.append((actor,None))\n",
    "        self._actors[name] = actor\n",
    "\n",
    "    def send(self, name, msg):\n",
    "        '''\n",
    "        Send a message to a named actor\n",
    "        '''\n",
    "        actor = self._actors.get(name)\n",
    "        if actor:\n",
    "            self._msg_queue.append((actor,msg))\n",
    "\n",
    "    def run(self):\n",
    "        '''\n",
    "        Run as long as there are pending messages.\n",
    "        '''\n",
    "        while self._msg_queue:\n",
    "            actor, msg = self._msg_queue.popleft()\n",
    "            try:\n",
    "                 actor.send(msg)\n",
    "            except StopIteration:\n",
    "                 pass\n",
    "\n",
    "# Example use\n",
    "if __name__ == '__main__':\n",
    "    def printer():\n",
    "        while True:\n",
    "            msg = yield\n",
    "            print('Got:', msg)\n",
    "\n",
    "    def counter(sched):\n",
    "        while True:\n",
    "            # Receive the current count\n",
    "            n = yield\n",
    "            if n == 0:\n",
    "                break\n",
    "            # Send to the printer task\n",
    "            sched.send('printer', n)\n",
    "            # Send the next count to the counter task (recursive)\n",
    "\n",
    "            sched.send('counter', n-1)\n",
    "\n",
    "    sched = ActorScheduler()\n",
    "    # Create the initial actors\n",
    "    sched.new_actor('printer', printer())\n",
    "    sched.new_actor('counter', counter(sched))\n",
    "\n",
    "    # Send an initial message to the counter to initiate\n",
    "    sched.send('counter', 3)\n",
    "    sched.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## {情境及應用不瞭解}更加高级的例子\n",
    "\n",
    "下面是一个更加高级的例子，演示了使用生成器来实现一个并发网络应用程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T14:52:21.866702Z",
     "start_time": "2019-10-08T14:52:21.833520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing YieldEvent.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import deque\n",
    "from select import select\n",
    "\n",
    "# This class represents a generic yield event in the scheduler\n",
    "class YieldEvent:\n",
    "    def handle_yield(self, sched, task):\n",
    "        pass\n",
    "    def handle_resume(self, sched, task):\n",
    "        pass\n",
    "\n",
    "# Task Scheduler\n",
    "class Scheduler:\n",
    "    def __init__(self):\n",
    "        self._numtasks = 0       # Total num of tasks\n",
    "        self._ready = deque()    # Tasks ready to run\n",
    "        self._read_waiting = {}  # Tasks waiting to read\n",
    "        self._write_waiting = {} # Tasks waiting to write\n",
    "\n",
    "    # Poll for I/O events and restart waiting tasks\n",
    "    def _iopoll(self):\n",
    "        rset,wset,eset = select(self._read_waiting,\n",
    "                                self._write_waiting,[])\n",
    "        for r in rset:\n",
    "            evt, task = self._read_waiting.pop(r)\n",
    "            evt.handle_resume(self, task)\n",
    "        for w in wset:\n",
    "            evt, task = self._write_waiting.pop(w)\n",
    "            evt.handle_resume(self, task)\n",
    "\n",
    "    def new(self,task):\n",
    "        '''\n",
    "        Add a newly started task to the scheduler\n",
    "        '''\n",
    "\n",
    "        self._ready.append((task, None))\n",
    "        self._numtasks += 1\n",
    "\n",
    "    def add_ready(self, task, msg=None):\n",
    "        '''\n",
    "        Append an already started task to the ready queue.\n",
    "        msg is what to send into the task when it resumes.\n",
    "        '''\n",
    "        self._ready.append((task, msg))\n",
    "\n",
    "    # Add a task to the reading set\n",
    "    def _read_wait(self, fileno, evt, task):\n",
    "        self._read_waiting[fileno] = (evt, task)\n",
    "\n",
    "    # Add a task to the write set\n",
    "    def _write_wait(self, fileno, evt, task):\n",
    "        self._write_waiting[fileno] = (evt, task)\n",
    "\n",
    "    def run(self):\n",
    "        '''\n",
    "        Run the task scheduler until there are no tasks\n",
    "        '''\n",
    "        while self._numtasks:\n",
    "            if not self._ready:\n",
    "                self._iopoll()\n",
    "            task, msg = self._ready.popleft()\n",
    "            try:\n",
    "                # Run the coroutine to the next yield\n",
    "                r = task.send(msg)\n",
    "                if isinstance(r, YieldEvent):\n",
    "                    r.handle_yield(self, task)\n",
    "                else:\n",
    "                    raise RuntimeError('unrecognized yield event')\n",
    "            except StopIteration:\n",
    "                self._numtasks -= 1\n",
    "\n",
    "# Example implementation of coroutine-based socket I/O\n",
    "class ReadSocket(YieldEvent):\n",
    "    def __init__(self, sock, nbytes):\n",
    "        self.sock = sock\n",
    "        self.nbytes = nbytes\n",
    "    def handle_yield(self, sched, task):\n",
    "        sched._read_wait(self.sock.fileno(), self, task)\n",
    "    def handle_resume(self, sched, task):\n",
    "        data = self.sock.recv(self.nbytes)\n",
    "        sched.add_ready(task, data)\n",
    "\n",
    "class WriteSocket(YieldEvent):\n",
    "    def __init__(self, sock, data):\n",
    "        self.sock = sock\n",
    "        self.data = data\n",
    "    def handle_yield(self, sched, task):\n",
    "\n",
    "        sched._write_wait(self.sock.fileno(), self, task)\n",
    "    def handle_resume(self, sched, task):\n",
    "        nsent = self.sock.send(self.data)\n",
    "        sched.add_ready(task, nsent)\n",
    "\n",
    "class AcceptSocket(YieldEvent):\n",
    "    def __init__(self, sock):\n",
    "        self.sock = sock\n",
    "    def handle_yield(self, sched, task):\n",
    "        sched._read_wait(self.sock.fileno(), self, task)\n",
    "    def handle_resume(self, sched, task):\n",
    "        r = self.sock.accept()\n",
    "        sched.add_ready(task, r)\n",
    "\n",
    "# Wrapper around a socket object for use with yield\n",
    "class Socket(object):\n",
    "    def __init__(self, sock):\n",
    "        self._sock = sock\n",
    "    def recv(self, maxbytes):\n",
    "        return ReadSocket(self._sock, maxbytes)\n",
    "    def send(self, data):\n",
    "        return WriteSocket(self._sock, data)\n",
    "    def accept(self):\n",
    "        return AcceptSocket(self._sock)\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._sock, name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from socket import socket, AF_INET, SOCK_STREAM\n",
    "    import time\n",
    "\n",
    "    # Example of a function involving generators.  This should\n",
    "    # be called using line = yield from readline(sock)\n",
    "    def readline(sock):\n",
    "        chars = []\n",
    "        while True:\n",
    "            c = yield sock.recv(1)\n",
    "            if not c:\n",
    "                break\n",
    "            chars.append(c)\n",
    "            if c == b'\\n':\n",
    "                break\n",
    "        return b''.join(chars)\n",
    "\n",
    "    # Echo server using generators\n",
    "    class EchoServer:\n",
    "        def __init__(self,addr,sched):\n",
    "            self.sched = sched\n",
    "            sched.new(self.server_loop(addr))\n",
    "\n",
    "        def server_loop(self,addr):\n",
    "            s = Socket(socket(AF_INET,SOCK_STREAM))\n",
    "\n",
    "            s.bind(addr)\n",
    "            s.listen(5)\n",
    "            while True:\n",
    "                c,a = yield s.accept()\n",
    "                print('Got connection from ', a)\n",
    "                self.sched.new(self.client_handler(Socket(c)))\n",
    "\n",
    "        def client_handler(self,client):\n",
    "            while True:\n",
    "                line = yield from readline(client)\n",
    "                if not line:\n",
    "                    break\n",
    "                line = b'GOT:' + line\n",
    "                while line:\n",
    "                    nsent = yield client.send(line)\n",
    "                    line = line[nsent:]\n",
    "            client.close()\n",
    "            print('Client closed')\n",
    "\n",
    "    sched = Scheduler()\n",
    "    EchoServer(('',16000),sched)\n",
    "    sched.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码有点复杂。不过，它实现了一个小型的操作系统。 \n",
    "\n",
    "有一个就绪的任务队列，并且还有因 `I/O` 休眠的任务等待区域。 \n",
    "\n",
    "还有很多调度器负责在就绪队列和 `I/O` 等待区域之间移动任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "在构建基于生成器的并发框架时，通常会使用更常见的yield形式：\n",
    "\n",
    "```py\n",
    "def some_generator():\n",
    "    ...\n",
    "    result = yield data\n",
    "    ...\n",
    "```    \n",
    "\n",
    "使用这种形式的 `yield` 语句的函数通常被称为“协程”。 \n",
    "\n",
    "通过调度器， `yield` 语句在一个循环中被处理，如下：\n",
    "\n",
    "```py\n",
    "f = some_generator()\n",
    "\n",
    "# Initial result. Is None to start since nothing has been computed\n",
    "result = None\n",
    "while True:\n",
    "    try:\n",
    "        data = f.send(result)\n",
    "        result = ... do some calculation ...\n",
    "    except StopIteration:\n",
    "        break\n",
    "```\n",
    "\n",
    "这里的逻辑稍微有点复杂。\n",
    "\n",
    "不过，被传给 `send()` 的值定义了在 `yield` 语句醒来时的返回值。 \n",
    "\n",
    "因此，如果一个 `yield` 准备在对之前 `yield` 数据的回应中返回结果时，会在下一次 `send()` 操作返回。 \n",
    "\n",
    "---\n",
    "\n",
    "如果一个生成器函数刚开始运行，发送一个 `None` 值会让它排在第一个 `yield` 语句前面。\n",
    "\n",
    "除了发送值外，还可以在一个生成器上面执行一个 `close()` 方法。 \n",
    "\n",
    "它会导致在执行 `yield` 语句时抛出一个 `GeneratorExit` 异常，从而终止执行。 \n",
    "\n",
    "如果进一步设计，一个生成器可以捕获这个异常并执行清理操作。 \n",
    "\n",
    "同样还可以使用生成器的 `throw()` 方法在 `yield` 语句执行时生成一个任意的执行指令。 \n",
    "\n",
    "一个任务调度器可利用它来在运行的生成器中处理错误。\n",
    "\n",
    "---\n",
    "\n",
    "最后一个例子中使用的 `yield from` 语句被用来实现协程，可以被其它生成器作为子程序或过程来调用。 \n",
    "\n",
    "本质上就是将控制权透明的传输给新的函数。 \n",
    "\n",
    "不像普通的生成器，一个使用 `yield from` 被调用的函数可以返回一个作为 `yield from` 语句结果的值。 \n",
    "\n",
    "---\n",
    "\n",
    "最后，如果使用生成器编程，要提醒你的是它还是有很多缺点的。\n",
    "\n",
    "特别是，你得不到任何线程可以提供的好处。\n",
    "\n",
    "例如，如果你执行 `CPU` 依赖或 `I/O` 阻塞程序， 它会将整个任务挂起知道操作完成。\n",
    "\n",
    "为了解决这个问题， 你只能选择将操作委派给另外一个可以独立运行的线程或进程。\n",
    "\n",
    "另外一个限制是大部分 `Python` 库并不能很好的兼容基于生成器的线程。\n",
    "\n",
    "如果你选择这个方案，你会发现你需要自己改写很多标准库函数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多个线程队列轮询"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于轮询问题的一个常见解决方案中有个很少有人知道的技巧，包含了一个隐藏的回路网络连接。 \n",
    "\n",
    "本质上讲其思想就是：对于每个你想要轮询的队列，你创建一对连接的套接字。 \n",
    "\n",
    "然后你在其中一个套接字上面编写代码来标识存在的数据， 另外一个套接字被传给 `select()` 或类似的一个轮询数据到达的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:15:20.368317Z",
     "start_time": "2019-10-11T17:15:20.361486Z"
    }
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "import socket\n",
    "import os\n",
    "\n",
    "class PollableQueue(queue.Queue):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Create a pair of connected sockets\n",
    "        if os.name == 'posix':\n",
    "            self._putsocket, self._getsocket = socket.socketpair()\n",
    "        else:\n",
    "            # Compatibility on non-POSIX systems\n",
    "            server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            server.bind(('127.0.0.1', 0))\n",
    "            server.listen(1)\n",
    "            self._putsocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            self._putsocket.connect(server.getsockname())\n",
    "            self._getsocket, _ = server.accept()\n",
    "            server.close()\n",
    "\n",
    "    def fileno(self):\n",
    "        return self._getsocket.fileno()\n",
    "\n",
    "    def put(self, item):\n",
    "        super().put(item)\n",
    "        self._putsocket.send(b'x')\n",
    "\n",
    "    def get(self):\n",
    "        self._getsocket.recv(1)\n",
    "        return super().get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个代码中，一个新的 `Queue` 实例类型被定义，底层是一个被连接套接字对。\n",
    "\n",
    "在 `Unix` 机器上的 `socketpair()` 函数能轻松的创建这样的套接字。 \n",
    "\n",
    "在 `Windows` 上面，你必须使用类似代码来模拟它。 然后定义普通的 `get()` 和 `put()` 方法在这些套接字上面来执行 `I/O` 操作。 \n",
    "\n",
    "`put()` 方法再将数据放入队列后会写一个单字节到某个套接字中去。 \n",
    "\n",
    "而 `get()` 方法在从队列中移除一个元素时会从另外一个套接字中读取到这个单字节数据。\n",
    "\n",
    "`fileno()` 方法使用一个函数比如 `select()` 来让这个队列可以被轮询。 \n",
    "\n",
    "它仅仅只是暴露了底层被 `get()` 函数使用到的 `socket` 的文件描述符而已。\n",
    "\n",
    "下面是一个例子，定义了一个为到来的元素监控多个队列的消费者：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:15:51.661304Z",
     "start_time": "2019-10-11T17:15:51.651543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 1\n",
      "Got: 10\n",
      "Got: hello\n",
      "Got: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import select\n",
    "import threading\n",
    "\n",
    "class consumer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._running = True\n",
    "\n",
    "    def stop(self):\n",
    "        self._running = False\n",
    "    \n",
    "    def run(self,queues):\n",
    "        '''\n",
    "        Consumer that reads data on multiple queues simultaneously\n",
    "        '''\n",
    "        while self._running:\n",
    "            can_read, _, _ = select.select(queues,[],[])\n",
    "            for r in can_read:\n",
    "                item = r.get()\n",
    "                print('Got:', item)\n",
    "\n",
    "q1 = PollableQueue()\n",
    "q2 = PollableQueue()\n",
    "q3 = PollableQueue()\n",
    "\n",
    "c = consumer()\n",
    "\n",
    "t = threading.Thread(target=c.run, args=([q1,q2,q3],))\n",
    "t.daemon = True\n",
    "t.start()\n",
    "\n",
    "# Feed data to the queues\n",
    "q1.put(1)\n",
    "q2.put(10)\n",
    "q3.put('hello')\n",
    "q2.put(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:15:54.111820Z",
     "start_time": "2019-10-11T17:15:54.107917Z"
    }
   },
   "outputs": [],
   "source": [
    "c.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "对于轮询非类文件对象，比如队列通常都是比较棘手的问题。 \n",
    "\n",
    "例如，如果你不使用上面的套接字技术， 你唯一的选择就是编写代码来循环遍历这些队列并使用一个定时器。\n",
    "\n",
    "像下面这样：\n",
    "\n",
    "```py\n",
    "import time\n",
    "def consumer(queues):\n",
    "    while True:\n",
    "        for q in queues:\n",
    "            if not q.empty():\n",
    "                item = q.get()\n",
    "                print('Got:', item)\n",
    "\n",
    "        # Sleep briefly to avoid 100% CPU\n",
    "        #time.sleep(0.01)\n",
    "        time.sleep(0.1)\n",
    "```\n",
    "\n",
    "这样做其实不合理，还会引入其他的性能问题。 \n",
    "\n",
    "例如，如果新的数据被加入到一个队列中，至少要花10毫秒才能被发现。 \n",
    "\n",
    "如果你之前的轮询还要去轮询其他对象，比如网络套接字那还会有更多问题。 \n",
    "\n",
    "例如，如果你想同时轮询套接字和队列，你可能要像下面这样使用：\n",
    "\n",
    "```py\n",
    "import select\n",
    "\n",
    "def event_loop(sockets, queues):\n",
    "    while True:\n",
    "        # polling with a timeout\n",
    "        can_read, _, _ = select.select(sockets, [], [], 0.01)\n",
    "        for r in can_read:\n",
    "            handle_read(r)\n",
    "        for q in queues:\n",
    "            if not q.empty():\n",
    "                item = q.get()\n",
    "                print('Got:', item)\n",
    "```\n",
    "\n",
    "这个方案通过将队列和套接字等同对待来解决了大部分的问题。 \n",
    "\n",
    "一个单独的 `select()` 调用可被同时用来轮询。 \n",
    "\n",
    "使用超时或其他基于时间的机制来执行周期性检查并没有必要。 \n",
    "\n",
    "甚至，如果数据被加入到一个队列，消费者几乎可以实时的被通知。 \n",
    "\n",
    "尽管会有一点点底层的 `I/O` 损耗，使用它通常会获得更好的响应时间并简化编程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [無法執行]在Unix系统上面启动守护进程\n",
    "\n",
    "在 windows 上 AttributeError: module 'os' has no attribute 'fork'\n",
    "\n",
    "無法執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "192px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
