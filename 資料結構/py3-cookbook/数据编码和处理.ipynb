{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#[csv-collections.namedtuple()]读写CSV数据\" data-toc-modified-id=\"[csv-collections.namedtuple()]读写CSV数据-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>[csv collections.namedtuple()]读写CSV数据</a></span></li><li><span><a href=\"#[json.dumps()-;-json.loads()]读写JSON数据\" data-toc-modified-id=\"[json.dumps()-;-json.loads()]读写JSON数据-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>[json.dumps() ; json.loads()]读写JSON数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#[json.dumps(,-default)-;-json.loads(,-object_hook)]讨论\" data-toc-modified-id=\"[json.dumps(,-default)-;-json.loads(,-object_hook)]讨论-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>[json.dumps(, default) ; json.loads(, object_hook)]讨论</a></span></li></ul></li><li><span><a href=\"#[xml.etree.ElementTree.parse()]解析简单的XML数据\" data-toc-modified-id=\"[xml.etree.ElementTree.parse()]解析简单的XML数据-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>[xml.etree.ElementTree.parse()]解析简单的XML数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[xml.etree.ElementTree.iterparse]增量式解析大型XML文件\" data-toc-modified-id=\"[xml.etree.ElementTree.iterparse]增量式解析大型XML文件-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>[xml.etree.ElementTree.iterparse]增量式解析大型XML文件</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[xml.etree.ElementTree.Element]将字典转换为XML\" data-toc-modified-id=\"[xml.etree.ElementTree.Element]将字典转换为XML-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>[xml.etree.ElementTree.Element]将字典转换为XML</a></span><ul class=\"toc-item\"><li><span><a href=\"#[xml.sax.saxutils.escape()]讨论\" data-toc-modified-id=\"[xml.sax.saxutils.escape()]讨论-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>[xml.sax.saxutils.escape()]讨论</a></span></li></ul></li><li><span><a href=\"#解析和修改XML\" data-toc-modified-id=\"解析和修改XML-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>解析和修改XML</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#利用命名空间解析XML文档\" data-toc-modified-id=\"利用命名空间解析XML文档-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>利用命名空间解析XML文档</a></span></li><li><span><a href=\"#与关系型数据库的交互\" data-toc-modified-id=\"与关系型数据库的交互-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>与关系型数据库的交互</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[binascii(小寫)-;-base64(大寫)]编码和解码十六进制数\" data-toc-modified-id=\"[binascii(小寫)-;-base64(大寫)]编码和解码十六进制数-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>[binascii(小寫) ; base64(大寫)]编码和解码十六进制数</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[base64.b64encode()]编码解码Base64数据\" data-toc-modified-id=\"[base64.b64encode()]编码解码Base64数据-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>[base64.b64encode()]编码解码Base64数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[struct.Struct()]读写二进制数组数据\" data-toc-modified-id=\"[struct.Struct()]读写二进制数组数据-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>[struct.Struct()]读写二进制数组数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#读取嵌套和可变长二进制数据\" data-toc-modified-id=\"读取嵌套和可变长二进制数据-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>读取嵌套和可变长二进制数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#解二进制文件，class，簡化\" data-toc-modified-id=\"解二进制文件，class，簡化-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>解二进制文件，class，簡化</a></span></li><li><span><a href=\"#解二进制文件，Metaclass-元類，簡化\" data-toc-modified-id=\"解二进制文件，Metaclass-元類，簡化-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>解二进制文件，Metaclass 元類，簡化</a></span></li><li><span><a href=\"#更加智能\" data-toc-modified-id=\"更加智能-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>更加智能</a></span></li></ul></li><li><span><a href=\"#[pandas]数据的累加与统计操作\" data-toc-modified-id=\"[pandas]数据的累加与统计操作-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>[pandas]数据的累加与统计操作</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [csv collections.namedtuple()]读写CSV数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设你在一个名叫stocks.csv文件中有一些股票市场数据\n",
    "\n",
    "```\n",
    "Symbol,Price,Date,Time,Change,Volume\n",
    "\"AA\",39.48,\"6/11/2007\",\"9:36am\",-0.18,181800\n",
    "\"AIG\",71.38,\"6/11/2007\",\"9:36am\",-0.15,195500\n",
    "\"AXP\",62.58,\"6/11/2007\",\"9:36am\",-0.46,935000\n",
    "\"BA\",98.31,\"6/11/2007\",\"9:36am\",+0.12,104800\n",
    "\"C\",53.08,\"6/11/2007\",\"9:36am\",-0.25,360900\n",
    "\"CAT\",78.29,\"6/11/2007\",\"9:36am\",-0.23,225400\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "可以考虑使用命名元组\n",
    "\n",
    "```py\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "with open('stock.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # Process row\n",
    "        ...\n",
    "        \n",
    "```\n",
    "\n",
    "为了写入`CSV`数据，你仍然可以使用`csv`模块，不过这时候先创建一个 `writer` 对象。\n",
    "\n",
    "```py\n",
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "         ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "         ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),\n",
    "       ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)\n",
    "```\n",
    "\n",
    "在非法标识符上使用一个正则表达式替换：\n",
    "\n",
    "```py\n",
    "import re\n",
    "with open('stock.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) ]\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # Process row\n",
    "        ...\n",
    "```\n",
    "\n",
    "还有重要的一点需要强调的是，`csv`产生的数据都是字符串类型的，它不会做任何其他类型的转换。 如果你需要做这样的类型转换，你必须自己手动去实现。 下面是一个在`CSV`数据上执行其他类型转换的例子：\n",
    "\n",
    "```py\n",
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "        ...\n",
    "```\n",
    "\n",
    "下面是一个转换字典中特定字段的例子：\n",
    "\n",
    "```py\n",
    "print('Reading as dicts with type conversion')\n",
    "field_types = [ \n",
    "    ('Price', float),\n",
    "    ('Change', float),\n",
    "    ('Volume', int) \n",
    "    ]\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key]))\n",
    "                for key, conversion in field_types)\n",
    "        print(row)\n",
    "```\n",
    "\n",
    "如果你读取`CSV`数据的目的是做数据分析和统计的话， 你可能需要看一看 `Pandas` 包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [json.dumps() ; json.loads()]读写JSON数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`json` 模块提供了一种很简单的方式来编码和解码JSON数据。 其中两个主要的函数是 `json.dumps()` 和 `json.loads()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:47:49.583531Z",
     "start_time": "2019-07-12T13:47:49.576686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"ACME\", \"shares\": 100, \"price\": 542.23}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'ACME', 'shares': 100, 'price': 542.23}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    'name' : 'ACME',\n",
    "    'shares' : 100,\n",
    "    'price' : 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)\n",
    "json_str\n",
    "\n",
    "json_data = json.loads(json_str)\n",
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你要处理的是**文件**而不是字符串，你可以使用 `json.dump()` 和 `json.load()` 来编码和解码`JSON`数据。\n",
    "\n",
    "```py\n",
    "# Writing JSON data\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# Reading data back\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [json.dumps(, default) ; json.loads(, object_hook)]讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`JSON`编码支持的基本数据类型为 `None` ， `bool` ， `int` ， `float` 和 `str` ， 以及包含这些类型数据的`lists`，`tuples`和`dictionaries`。\n",
    "\n",
    "为了遵循`JSON`规范，你应该只编码`Python`的`lists`和`dictionaries`。 而且，在`web`应用程序中，顶层对象被编码为一个字典是一个标准做法。\n",
    "\n",
    "`JSON`编码的格式对于`Python`语法而已几乎是完全一样的，除了一些小的差异之外。 比如，`True`会被映射为`true`，`False`被映射为`false`，而`None`会被映射为`null`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:51:43.395383Z",
     "start_time": "2019-07-12T13:51:43.389527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": true, \"b\": \"Hello\", \"c\": null}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'a': True,\n",
    "    'b': 'Hello',\n",
    "    'c': None\n",
    "}\n",
    "\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以考虑使用`pprint`模块的 `pprint()` 函数来代替普通的 `print()` 函数。\n",
    "\n",
    "`JSON`解码会根据提供的数据创建`dicts`或`lists`。 如果你想要创建其他类型的对象，可以给 `json.loads()` 传递`object_pairs_hook`或`object_hook`参数。 例如，下面是演示如何解码`JSON`数据并在一个`OrderedDict`中保留其顺序的例子：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T13:54:15.652607Z",
     "start_time": "2019-07-12T13:54:15.647734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict\n",
    "\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T14:02:04.683331Z",
     "start_time": "2019-07-12T14:02:04.674543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACME'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "490.1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "\n",
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "data = json.loads(s, object_hook=JSONObject)\n",
    "data.name\n",
    "data.shares\n",
    "data.price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想获得漂亮的格式化字符串后输出，可以使用 `json.dumps()` 的`indent`参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T14:03:14.257825Z",
     "start_time": "2019-07-12T14:03:14.252945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ACME\",\n",
      "    \"shares\": 50,\n",
      "    \"price\": 490.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "data = json.loads(s)\n",
    "\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对象实例**通常并不是`JSON`可序列化的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T14:06:06.100675Z",
     "start_time": "2019-07-12T14:06:06.096798Z"
    }
   },
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "p = Point(2, 3)\n",
    "\n",
    "# json.dumps(p)\n",
    "# TypeError: Object of type 'Point' is not JSON serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想序列化对象实例，你可以提供一个函数，它的输入是一个实例，返回一个可序列化的字典。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T14:07:37.471820Z",
     "start_time": "2019-07-12T14:07:37.466945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"__classname__\": \"Point\", \"x\": 2, \"y\": 3}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def serialize_instance(obj):\n",
    "    d = { '__classname__' : type(obj).__name__ }\n",
    "    d.update(vars(obj))\n",
    "    return d\n",
    "\n",
    "json.dumps(serialize_instance(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想反过来获取这个实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T14:09:05.263617Z",
     "start_time": "2019-07-12T14:09:05.258733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary mapping names to known classes\n",
    "classes = {\n",
    "    'Point' : Point\n",
    "}\n",
    "\n",
    "def unserialize_object(d):\n",
    "    clsname = d.pop('__classname__', None)\n",
    "    if clsname:\n",
    "        cls = classes[clsname]\n",
    "        # Make instance without calling __init__\n",
    "        obj = cls.__new__(cls) \n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "        return obj\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T14:09:45.112811Z",
     "start_time": "2019-07-12T14:09:45.103051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"__classname__\": \"Point\", \"x\": 2, \"y\": 3}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x1d6ebf17e48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obj\n",
    "p = Point(2,3)\n",
    "\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "s\n",
    "\n",
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "a\n",
    "\n",
    "a.x\n",
    "a.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [xml.etree.ElementTree.parse()]解析简单的XML数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用 `xml.etree.ElementTree` 模块从简单的`XML`文档中提取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T14:16:37.079318Z",
     "start_time": "2019-07-12T14:16:32.017896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moshe Zadka: Interfaces are forever\n",
      "Fri, 12 Jul 2019 13:43:11 +0000\n",
      "https://orbifold.xyz/interfaces-are-forever.html\n",
      "\n",
      "PyBites: Code Challenge 62 - Women @ Pycon ES\n",
      "Fri, 12 Jul 2019 12:00:00 +0000\n",
      "https://pybit.es/codechallenge62.html\n",
      "\n",
      "Python Circle: For loop in Django template\n",
      "Fri, 12 Jul 2019 07:45:17 +0000\n",
      "https://www.pythoncircle.com/post/685/for-loop-in-django-template/\n",
      "\n",
      "Python Circle: Creating custom template tags in Django\n",
      "Fri, 12 Jul 2019 04:45:03 +0000\n",
      "https://www.pythoncircle.com/post/42/creating-custom-template-tags-in-django/\n",
      "\n",
      "ListenData: Python list comprehension with Examples\n",
      "Fri, 12 Jul 2019 02:33:26 +0000\n",
      "https://www.listendata.com/2019/07/python-list-comprehension-with-examples.html\n",
      "\n",
      "ListenData: Python Lambda Function with Examples\n",
      "Fri, 12 Jul 2019 02:31:33 +0000\n",
      "https://www.listendata.com/2019/04/python-lambda-function.html\n",
      "\n",
      "PSF GSoC students blogs: Week #6\n",
      "Fri, 12 Jul 2019 00:30:06 +0000\n",
      "http://blogs.python-gsoc.org/en/blogs/js94s-blog/week-6-2/\n",
      "\n",
      "ListenData: 15 ways to read CSV file with pandas\n",
      "Thu, 11 Jul 2019 22:40:55 +0000\n",
      "https://www.listendata.com/2019/06/pandas-read-csv.html\n",
      "\n",
      "Data School: My top 25 pandas tricks (video)\n",
      "Thu, 11 Jul 2019 20:13:32 +0000\n",
      "https://www.dataschool.io/python-pandas-tricks/\n",
      "\n",
      "Codementor: Introduction to unit testing with Python\n",
      "Thu, 11 Jul 2019 18:34:54 +0000\n",
      "https://www.codementor.io/jslvtr/introduction-to-unit-testing-with-python-wsfqd3vrt\n",
      "\n",
      "Peter Bengtsson: SongSearch autocomplete rate now 2+ per second\n",
      "Thu, 11 Jul 2019 17:21:05 +0000\n",
      "https://www.peterbe.com/plog/songsearch-autocomplete-rate-now-2+-per-second\n",
      "\n",
      "PSF GSoC students blogs: Coding and Communication\n",
      "Thu, 11 Jul 2019 17:15:56 +0000\n",
      "http://blogs.python-gsoc.org/en/blogs/yashlambas-blog/coding-and-communication/\n",
      "\n",
      "Python Anywhere: Using our file API\n",
      "Thu, 11 Jul 2019 15:51:46 +0000\n",
      "https://blog.pythonanywhere.com/180/\n",
      "\n",
      "IslandT: Convert hexadecimal number to decimal number with Python program\n",
      "Thu, 11 Jul 2019 13:24:24 +0000\n",
      "https://kibiwebgeek.com/2019/07/11/convert-hexadecimal-number-to-decimal-number-with-python-program/\n",
      "\n",
      "Catalin George Festila: Python 3.7.3 : Three examples with BeautifulSoup.\n",
      "Thu, 11 Jul 2019 12:53:38 +0000\n",
      "http://python-catalin.blogspot.com/2019/07/python-373-three-examples-with.html\n",
      "\n",
      "Python Software Foundation: 2019 PSF Fundraiser - Thank you &amp; debrief\n",
      "Thu, 11 Jul 2019 11:04:24 +0000\n",
      "http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/9sGpXmeE1-c/2019-psf-fundraiser-thank-you-debrief.html\n",
      "\n",
      "PSF GSoC students blogs: Fourth Blog - GSOC 2019\n",
      "Thu, 11 Jul 2019 10:27:58 +0000\n",
      "http://blogs.python-gsoc.org/en/blogs/abhinandan0659s-blog/fourth-blog-gsoc-2019/\n",
      "\n",
      "Full Stack Python: Developer-led Sales for Startups\n",
      "Thu, 11 Jul 2019 04:00:00 +0000\n",
      "https://www.fullstackpython.com/blog/developer-led-sales-startups.html\n",
      "\n",
      "PSF GSoC students blogs: Week 6\n",
      "Thu, 11 Jul 2019 03:07:09 +0000\n",
      "http://blogs.python-gsoc.org/en/blogs/ironmaniiiths-blog/week-6-1/\n",
      "\n",
      "PSF GSoC students blogs: Week 5\n",
      "Thu, 11 Jul 2019 02:58:15 +0000\n",
      "http://blogs.python-gsoc.org/en/blogs/ironmaniiiths-blog/week-5-2/\n",
      "\n",
      "PSF GSoC students blogs: Coding week #6\n",
      "Thu, 11 Jul 2019 02:17:39 +0000\n",
      "http://blogs.python-gsoc.org/en/blogs/mehaksachdevas-blog/coding-week-6/\n",
      "\n",
      "Wingware News: Wing Python IDE 7.0.4 -  July 11, 2019\n",
      "Thu, 11 Jul 2019 01:00:00 +0000\n",
      "https://wingware.com/news/2019-07-11\n",
      "\n",
      "Catalin George Festila: Python 3.7.3 : Testing the Bokeh python module.\n",
      "Thu, 11 Jul 2019 00:47:44 +0000\n",
      "http://python-catalin.blogspot.com/2019/07/python-373-testing-bokeh-python-module.html\n",
      "\n",
      "Matt Layman: Using Git and GitHub to safely store your code\n",
      "Thu, 11 Jul 2019 00:00:00 +0000\n",
      "https://www.mattlayman.com/blog/2019/using-git-github-to-store-code/\n",
      "\n",
      "Randy Zwitch: ODSC webinar&amp;#58; End-to-End Data Science Without Leaving the GPU\n",
      "Thu, 11 Jul 2019 00:00:00 +0000\n",
      "http://randyzwitch.com/omnisci-cudf-rapids-odsc-webinar/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Download the RSS feed and parse it\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)\n",
    "\n",
    "# Extract and output tags of interest\n",
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "\n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```xml\n",
    "<?xml version=\"1.0\"?>\n",
    "<rss version=\"2.0\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n",
    "    <channel>\n",
    "        <title>Planet Python</title>\n",
    "        <link>http://planet.python.org/</link>\n",
    "        <language>en</language>\n",
    "        <description>\n",
    "            Planet Python - http://planet.python.org/\n",
    "        </description>\n",
    "        <item>\n",
    "            <title>Steve Holden: Python for Data Analysis</title>\n",
    "            <guid>\n",
    "                http://holdenweb.blogspot.com/...-data-analysis.html\n",
    "            </guid>\n",
    "            <link>\n",
    "                http://holdenweb.blogspot.com/...-data-analysis.html\n",
    "            </link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Mon, 19 Nov 2012 02:13:51 +0000</pubDate>\n",
    "        </item>\n",
    "        <item>\n",
    "            <title>\n",
    "                Vasudev Ram: The Python Data model (for v2 and v3)\n",
    "            </title>\n",
    "            <guid>http://jugad2.blogspot.com/...-data-model.html</guid>\n",
    "            <link>http://jugad2.blogspot.com/...-data-model.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Sun, 18 Nov 2012 22:06:47 +0000</pubDate>\n",
    "        </item>\n",
    "        <item>\n",
    "            <title>\n",
    "                Python Diary: Been playing around with Object Databases\n",
    "            </title>\n",
    "            <guid>\n",
    "                http://www.pythondiary.com/...-object-databases.html\n",
    "            </guid>\n",
    "            <link>\n",
    "                http://www.pythondiary.com/...-object-databases.html\n",
    "            </link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Sun, 18 Nov 2012 20:40:29 +0000</pubDate>\n",
    "        </item>\n",
    "        ...\n",
    "    </channel>\n",
    "</rss>\n",
    "```\n",
    "\n",
    "\n",
    "`xml.etree.ElementTree.parse()` 函数解析整个`XML`文档并将其转换成一个文档对象。 然后，你就能使用 `find()` 、`iterfind()` 和 `findtext()` 等方法来搜索特定的`XML`元素了。 这些函数的参数就是某个指定的标签名，例如 `channel/item` 或 `title` 。\n",
    "\n",
    "执行 `doc.iterfind('channel/item')` 来搜索所有在 `channel` 元素下面的 `item` 元素。 `doc` 代表文档的最顶层(也就是第一级的 `rss` 元素)。 然后接下来的调用 `item.findtext()` 会从已找到的 `item` 元素位置开始搜索。\n",
    "\n",
    "`ElementTree` 模块中的每个元素有一些重要的属性和方法，在解析的时候非常有用。 `tag` 属性包含了标签的名字，`text` 属性包含了内部的文本，而 `get()` 方法能获取属性值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T14:24:39.224383Z",
     "start_time": "2019-07-12T14:24:39.213647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x1d6ebf28390>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Element 'title' at 0x000001D6EBF3B3B8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Planet Python'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc\n",
    "\n",
    "e = doc.find('channel/title')\n",
    "e\n",
    "\n",
    "e.tag\n",
    "\n",
    "e.text\n",
    "\n",
    "e.get('some_attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [xml.etree.ElementTree.iterparse]增量式解析大型XML文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任何时候只要你遇到增量式的数据处理时，第一时间就应该想到迭代器和生成器。 下面是一个很简单的函数，只使用很少的内存就能增量式的处理一个大型`XML`文件："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```xml\n",
    "<response>\n",
    "    <row>\n",
    "        <row ...>\n",
    "            <creation_date>2012-11-18T00:00:00</creation_date>\n",
    "            <status>Completed</status>\n",
    "            <completion_date>2012-11-18T00:00:00</completion_date>\n",
    "            <service_request_number>12-01906549</service_request_number>\n",
    "            <type_of_service_request>Pot Hole in Street</type_of_service_request>\n",
    "            <current_activity>Final Outcome</current_activity>\n",
    "            <most_recent_action>CDOT Street Cut ... Outcome</most_recent_action>\n",
    "            <street_address>4714 S TALMAN AVE</street_address>\n",
    "            <zip>60632</zip>\n",
    "            <x_coordinate>1159494.68618856</x_coordinate>\n",
    "            <y_coordinate>1873313.83503384</y_coordinate>\n",
    "            <ward>14</ward>\n",
    "            <police_district>9</police_district>\n",
    "            <community_area>58</community_area>\n",
    "            <latitude>41.808090232127896</latitude>\n",
    "            <longitude>-87.69053684711305</longitude>\n",
    "            <location latitude=\"41.808090232127896\"\n",
    "            longitude=\"-87.69053684711305\" />\n",
    "        </row>\n",
    "        <row ...>\n",
    "            <creation_date>2012-11-18T00:00:00</creation_date>\n",
    "            <status>Completed</status>\n",
    "            <completion_date>2012-11-18T00:00:00</completion_date>\n",
    "            <service_request_number>12-01906695</service_request_number>\n",
    "            <type_of_service_request>Pot Hole in Street</type_of_service_request>\n",
    "            <current_activity>Final Outcome</current_activity>\n",
    "            <most_recent_action>CDOT Street Cut ... Outcome</most_recent_action>\n",
    "            <street_address>3510 W NORTH AVE</street_address>\n",
    "            <zip>60647</zip>\n",
    "            <x_coordinate>1152732.14127696</x_coordinate>\n",
    "            <y_coordinate>1910409.38979075</y_coordinate>\n",
    "            <ward>26</ward>\n",
    "            <police_district>14</police_district>\n",
    "            <community_area>23</community_area>\n",
    "            <latitude>41.91002084292946</latitude>\n",
    "            <longitude>-87.71435952353961</longitude>\n",
    "            <location latitude=\"41.91002084292946\"\n",
    "            longitude=\"-87.71435952353961\" />\n",
    "        </row>\n",
    "    </row>\n",
    "</response>\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设你想写一个脚本来按照坑洼报告数量排列邮编号码\n",
    "\n",
    "```py\n",
    "from xml.etree.ElementTree import parse\n",
    "from collections import Counter\n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "doc = parse('potholes.xml')\n",
    "for pothole in doc.iterfind('row/row'):\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n",
    "```\n",
    "\n",
    "这个脚本唯一的问题是它会先将整个XML文件加载到内存中然后解析。\n",
    "\n",
    "需要用到450MB左右的内存空间\n",
    "\n",
    "```py\n",
    "\n",
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # Skip the root element\n",
    "    next(doc)\n",
    "\n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem\n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n",
    "```\n",
    "\n",
    "只需要7MB的内存–大大节约了内存资源。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iterparse()` 方法允许对`XML`文档进行增量操作。 使用时，你需要提供文件名和一个包含下面一种或多种类型的事件列表： `start` , `end`, `start-ns` 和 `end-ns` 。 由 `iterparse()` 创建的迭代器会产生形如 (`event`, `elem`) 的元组， 其中 `event` 是上述事件列表中的某一个，而 `elem` 是相应的`XML`元素\n",
    "\n",
    "有一个名为 `pred.xml` 的文档，类似下面这样：\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\"?>\n",
    "<stop>\n",
    "    <id>14791</id>\n",
    "    <nm>Clark &amp; Balmoral</nm>\n",
    "    <sri>\n",
    "        <rt>22</rt>\n",
    "        <d>North Bound</d>\n",
    "        <dd>North Bound</dd>\n",
    "    </sri>\n",
    "    <cr>22</cr>\n",
    "    <pre>\n",
    "        <pt>5 MIN</pt>\n",
    "        <fd>Howard</fd>\n",
    "        <v>1378</v>\n",
    "        <rn>22</rn>\n",
    "    </pre>\n",
    "    <pre>\n",
    "        <pt>15 MIN</pt>\n",
    "        <fd>Howard</fd>\n",
    "        <v>1867</v>\n",
    "        <rn>22</rn>\n",
    "    </pre>\n",
    "</stop>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T10:09:07.489489Z",
     "start_time": "2019-07-13T10:09:07.477778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'stop' at 0x000001D6EBFB2A98>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('start', <Element 'id' at 0x000001D6EBF82098>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('end', <Element 'id' at 0x000001D6EBF82098>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('start', <Element 'nm' at 0x000001D6EBF820E8>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import (\n",
    "    Element, iterparse, parse, tostring\n",
    ")\n",
    "\n",
    "doc = iterparse('pred.xml',('start','end'))\n",
    "\n",
    "next(doc)\n",
    "next(doc)\n",
    "next(doc)\n",
    "next(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [xml.etree.ElementTree.Element]将字典转换为XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T05:43:51.008260Z",
     "start_time": "2019-07-13T05:43:50.995573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stock' at 0x000001D6EBFF25E8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'<stock><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'<stock _id=\"1234\"><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def dict_to_xml(tag, d):\n",
    "    '''\n",
    "    Turn a simple dict of key/value pairs into XML\n",
    "    '''\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "    return elem\n",
    "\n",
    "# ========= dict to xml =============\n",
    "s = { 'name': 'GOOG', 'shares': 100, 'price':490.1 }\n",
    "e = dict_to_xml('stock', s)\n",
    "e\n",
    "\n",
    "# ========= xml to b'' =============\n",
    "from xml.etree.ElementTree import tostring\n",
    "tostring(e)\n",
    "\n",
    "# ======= 如果你想给某个元素添加属性值 =====\n",
    "e.set('_id','1234')\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [xml.sax.saxutils.escape()]讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字符 `‘<’` 和 `‘>’` 處理 \n",
    "\n",
    "替换成 `&lt;` 和 `&gt;`\n",
    "\n",
    "可以使用 `xml.sax.saxutils` 中的 `escape()` 和 `unescape()` 函数\n",
    "\n",
    "创建 `Element` 实例而不是字符串， 那就是使用字符串组合构造一个更大的文档并不是那么容易。 而 `Element` 实例可以不用考虑解析XML文本的情况下通过多种方式被处理。 也就是说，你可以在一个高级数据结构上完成你所有的操作，并在最后以字符串的形式将其输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T05:49:25.715412Z",
     "start_time": "2019-07-13T05:49:25.706627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<item><name><spam></name></item>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'<item><name>&lt;spam&gt;</name></item>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_to_xml_str(tag, d):\n",
    "    '''\n",
    "    Turn a simple dict of key/value pairs into XML\n",
    "    '''\n",
    "    parts = ['<{}>'.format(tag)]\n",
    "    for key, val in d.items():\n",
    "        parts.append('<{0}>{1}</{0}>'.format(key,val))\n",
    "    parts.append('</{}>'.format(tag))\n",
    "    return ''.join(parts)\n",
    "\n",
    "d = { 'name' : '<spam>' }\n",
    "\n",
    "# String creation\n",
    "dict_to_xml_str('item',d)\n",
    "\n",
    "# Proper XML creation\n",
    "e = dict_to_xml('item',d)\n",
    "tostring(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T05:50:14.534751Z",
     "start_time": "2019-07-13T05:50:14.106767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&lt;spam&gt;'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'<spam>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.sax.saxutils import escape, unescape\n",
    "escape('<spam>')\n",
    "unescape(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解析和修改XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一个名为 `pred.xml` 的文档，类似下面这样：\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\"?>\n",
    "<stop>\n",
    "    <id>14791</id>\n",
    "    <nm>Clark &amp; Balmoral</nm>\n",
    "    <sri>\n",
    "        <rt>22</rt>\n",
    "        <d>North Bound</d>\n",
    "        <dd>North Bound</dd>\n",
    "    </sri>\n",
    "    <cr>22</cr>\n",
    "    <pre>\n",
    "        <pt>5 MIN</pt>\n",
    "        <fd>Howard</fd>\n",
    "        <v>1378</v>\n",
    "        <rn>22</rn>\n",
    "    </pre>\n",
    "    <pre>\n",
    "        <pt>15 MIN</pt>\n",
    "        <fd>Howard</fd>\n",
    "        <v>1867</v>\n",
    "        <rn>22</rn>\n",
    "    </pre>\n",
    "</stop>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T06:08:53.315067Z",
     "start_time": "2019-07-13T06:08:53.300432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stop' at 0x000001D6EC012E58>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse, Element\n",
    "doc = parse('pred.xml')\n",
    "root = doc.getroot()\n",
    "root\n",
    "\n",
    "root.remove(root.find('sri'))\n",
    "root.remove(root.find('cr'))\n",
    "# Insert a new element after <nm>...</nm>\n",
    "root.getchildren().index(root.find('nm'))\n",
    "\n",
    "e = Element('spam')\n",
    "e.text = 'This is a test'\n",
    "root.insert(2, e)\n",
    "\n",
    "# Write back to a file\n",
    "doc.write('newpred.xml', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "新的`XML`文件 `newpred.xml`\n",
    "\n",
    "```xml\n",
    "<?xml version='1.0' encoding='us-ascii'?>\n",
    "<stop>\n",
    "    <id>14791</id>\n",
    "    <nm>Clark &amp; Balmoral</nm>\n",
    "    <spam>This is a test</spam>\n",
    "    <pre>\n",
    "        <pt>5 MIN</pt>\n",
    "        <fd>Howard</fd>\n",
    "        <v>1378</v>\n",
    "        <rn>22</rn>\n",
    "    </pre>\n",
    "    <pre>\n",
    "        <pt>15 MIN</pt>\n",
    "        <fd>Howard</fd>\n",
    "        <v>1867</v>\n",
    "        <rn>22</rn>\n",
    "    </pre>\n",
    "</stop>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "如果你删除某个元素，通过调用父节点的 `remove()` 方法从它的直接父节点中删除。 如果你插入或增加新的元素，你同样使用父节点元素的 `insert()` 和 `append()` 方法。 还能对元素使用索引和切片操作，比如 `element[i]` 或 `element[i:j]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用命名空间解析XML文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "使用了命名空间的文档 `Namespace.xml`\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<top>\n",
    "    <author>David Beazley</author>\n",
    "    <content>\n",
    "        <html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
    "            <head>\n",
    "                <title>Hello World</title>\n",
    "            </head>\n",
    "            <body>\n",
    "                <h1>Hello World!</h1>\n",
    "            </body>\n",
    "        </html>\n",
    "    </content>\n",
    "</top>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T10:12:23.795534Z",
     "start_time": "2019-07-13T10:12:23.781433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David Beazley'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Element 'content' at 0x000001D6EBF82E58>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Element '{http://www.w3.org/1999/xhtml}html' at 0x000001D6EBF82D68>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse, Element\n",
    "doc = parse('Namespace.xml')\n",
    "\n",
    "# Some queries that work\n",
    "doc.findtext('author') # 'David Beazley'\n",
    "doc.find('content') # <Element 'content' at 0x100776ec0>\n",
    "\n",
    "# A query involving a namespace (doesn't work)\n",
    "doc.find('content/html') \n",
    "# Works if fully qualified\n",
    "doc.find('content/{http://www.w3.org/1999/xhtml}html')\n",
    "\n",
    "# Doesn't work\n",
    "doc.findtext('content/{http://www.w3.org/1999/xhtml}html/head/title')\n",
    "# Fully qualified\n",
    "doc.findtext(\n",
    "    'content/{http://www.w3.org/1999/xhtml}html/'+\n",
    "    '{http://www.w3.org/1999/xhtml}head/'+\n",
    "    '{http://www.w3.org/1999/xhtml}title'\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T12:25:49.742861Z",
     "start_time": "2019-07-13T12:25:49.736962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# str.format_map()\n",
    "\n",
    "s = {'a':1,'z':2}\n",
    "\n",
    "print('{a}'.format_map(s))\n",
    "\n",
    "print('{a}{z}'.format_map(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T10:14:41.342494Z",
     "start_time": "2019-07-13T10:14:41.016064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'content/{http://www.w3.org/1999/xhtml}html'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Element '{http://www.w3.org/1999/xhtml}html' at 0x000001D6EBF82D68>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end <Element 'author' at 0x000001D6EBF6A688>\n",
      "start-ns ('', 'http://www.w3.org/1999/xhtml')\n",
      "end <Element '{http://www.w3.org/1999/xhtml}title' at 0x000001D6EBF6A818>\n",
      "end <Element '{http://www.w3.org/1999/xhtml}head' at 0x000001D6EBF6A7C8>\n",
      "end <Element '{http://www.w3.org/1999/xhtml}h1' at 0x000001D6EBF6A8B8>\n",
      "end <Element '{http://www.w3.org/1999/xhtml}body' at 0x000001D6EBF6A868>\n",
      "end <Element '{http://www.w3.org/1999/xhtml}html' at 0x000001D6EBF6A778>\n",
      "end-ns None\n",
      "end <Element 'content' at 0x000001D6EBF6A6D8>\n",
      "end <Element 'top' at 0x000001D6EBF824A8>\n"
     ]
    }
   ],
   "source": [
    "class XMLNamespaces:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.namespaces = {}\n",
    "        for name, uri in kwargs.items():\n",
    "            self.register(name, uri)\n",
    "    def register(self, name, uri):\n",
    "        self.namespaces[name] = '{'+uri+'}'\n",
    "    def __call__(self, path):\n",
    "        return path.format_map(self.namespaces)\n",
    "    \n",
    "ns = XMLNamespaces(html='http://www.w3.org/1999/xhtml')\n",
    "ns('content/{html}html')\n",
    "\n",
    "doc.find(ns('content/{html}html'))\n",
    "doc.findtext(ns('content/{html}html/{html}head/{html}title'))\n",
    "\n",
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "# 使用 iterparse() 函数的话就可以获取更多关于命名空间处理范围的信息。\n",
    "for evt, elem in iterparse(\n",
    "    'Namespace.xml', \n",
    "    ('end', 'start-ns', 'end-ns')\n",
    "):\n",
    "    print(evt, elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 与关系型数据库的交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:26:43.870532Z",
     "start_time": "2019-07-15T09:26:43.644516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x25466764a40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = [\n",
    "    ('GOOG', 100, 490.1),\n",
    "    ('AAPL', 50, 545.75),\n",
    "    ('FB', 150, 7.45),\n",
    "    ('HPQ', 75, 33.2),\n",
    "]\n",
    "\n",
    "\n",
    "# 连接到数据库\n",
    "import sqlite3\n",
    "db = sqlite3.connect('database.db')\n",
    "\n",
    "# 创建一个游标, 执行SQL查询语句\n",
    "c = db.cursor()\n",
    "c.execute('create table portfolio (symbol text, shares integer, price real)')\n",
    "db.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:26:45.501789Z",
     "start_time": "2019-07-15T09:26:45.323018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x25466764a40>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 插入多条记录\n",
    "c.executemany('insert into portfolio values (?,?,?)', stocks)\n",
    "db.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:26:47.648607Z",
     "start_time": "2019-07-15T09:26:47.643755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GOOG', 100, 490.1)\n",
      "('AAPL', 50, 545.75)\n",
      "('FB', 150, 7.45)\n",
      "('HPQ', 75, 33.2)\n"
     ]
    }
   ],
   "source": [
    "# 执行某个查询\n",
    "for row in db.execute('select * from portfolio'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想接受用户输入作为参数来执行查询操作，必须确保你使用下面这样的占位符`?`来进行引用参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:26:50.835720Z",
     "start_time": "2019-07-15T09:26:50.831816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GOOG', 100, 490.1)\n",
      "('AAPL', 50, 545.75)\n"
     ]
    }
   ],
   "source": [
    "min_price = 100\n",
    "for row in db.execute(\n",
    "    'select * from portfolio where price >= ?',\n",
    "    (min_price,)\n",
    "):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:26:52.051891Z",
     "start_time": "2019-07-15T09:26:52.046972Z"
    }
   },
   "outputs": [],
   "source": [
    "# 關閉\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个难点是数据库中的数据和`Python`类型直接的映射。 对于日期类型，通常可以使用 `datetime` 模块中的 `datetime` 实例， 或者可能是 `time` 模块中的系统时间戳。 对于数字类型，特别是使用到小数的金融数据，可以用 `decimal` 模块中的 `Decimal` 实例来表示。 不幸的是，对于不同的数据库而言具体映射规则是不一样的，你必须参考相应的文档。\n",
    "\n",
    "另外一个更加复杂的问题就是`SQL`语句字符串的构造。 你千万不要使用`Python`字符串格式化操作符(如`%`)或者 `.format()` 方法来创建这样的字符串。 如果传递给这些格式化操作符的值来自于用户的输入，那么你的程序就很有可能遭受`SQL注入攻击`。 查询语句中的通配符 `?` 指示后台数据库使用它自己的字符串替换机制，这样更加的安全。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [binascii(小寫) ; base64(大寫)]编码和解码十六进制数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将一个十六进制字符串解码成一个字节字符串或者将一个字节字符串编码成一个十六进制字符串\n",
    "\n",
    "**binascii**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:16:28.329726Z",
     "start_time": "2019-07-14T06:16:28.115943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656c6c6f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial byte string\n",
    "s = b'hello'\n",
    "\n",
    "# Encode as hex\n",
    "import binascii\n",
    "\n",
    "h = binascii.b2a_hex(s)\n",
    "h # b'68656c6c6f'\n",
    "\n",
    "# Decode back to bytes\n",
    "binascii.a2b_hex(h) # b'hello'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**base64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:17:21.519114Z",
     "start_time": "2019-07-14T06:17:21.511306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656C6C6F'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "h = base64.b16encode(s)\n",
    "h\n",
    "\n",
    "base64.b16decode(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大部分情况下，通过使用上述的函数来转换十六进制是很简单的。 上面两种技术的主要不同在于大小写的处理。 函数 `base64.b16decode()` 和 `base64.b16encode()` 只能操作大写形式的十六进制字母， 而 `binascii` 模块中的函数大小写都能处理。\n",
    "\n",
    "还有一点需要注意的是编码函数所产生的输出总是一个字节字符串。 如果想强制以`Unicode`形式输出，你需要增加一个额外的界面步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:20:55.257458Z",
     "start_time": "2019-07-14T06:20:55.251575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'68656C6C6F'\n",
      "68656C6C6F\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = b'hello'\n",
    "\n",
    "h = base64.b16encode(s)\n",
    "print(h)\n",
    "\n",
    "print(h.decode('ascii'))\n",
    "\n",
    "s.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [base64.b64encode()]编码解码Base64数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`base64` 模块中有两个函数 `b64encode()` and `b64decode()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:22:43.597536Z",
     "start_time": "2019-07-14T06:22:43.591680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aGVsbG8='"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some byte data\n",
    "s = b'hello'\n",
    "import base64\n",
    "\n",
    "# Encode as Base64\n",
    "a = base64.b64encode(s)\n",
    "a\n",
    "#b'aGVsbG8='\n",
    "\n",
    "# Decode from Base64\n",
    "base64.b64decode(a)\n",
    "#b'hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Base64`编码仅仅用于面向字节的数据比如字节字符串和字节数组。 此外，编码处理的输出结果总是一个字节字符串。 如果你想混合使用`Base64`编码的数据和`Unicode`文本，你必须添加一个额外的解码步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:24:16.770419Z",
     "start_time": "2019-07-14T06:24:16.765540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aGVsbG8='"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = b'hello'\n",
    "a = base64.b64encode(s).decode('ascii')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当解码`Base64`的时候，字节字符串和`Unicode`文本都可以作为参数。 但是，`Unicode`字符串只能包含`ASCII`字符。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [struct.Struct()]读写二进制数组数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用 `struct` 模块处理二进制数据。 下面是一段示例代码将一个`Python`元组列表写入一个二进制文件，并使用 `struct` 将每个元组编码为一个结构体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T08:46:36.251805Z",
     "start_time": "2019-07-15T08:46:36.240097Z"
    }
   },
   "outputs": [],
   "source": [
    "from struct import Struct\n",
    "def write_records(records, format, f):\n",
    "    '''\n",
    "    Write a sequence of tuples to a binary file of structures.\n",
    "    '''\n",
    "    record_struct = Struct(format)\n",
    "    for r in records:\n",
    "        f.write(record_struct.pack(*r))\n",
    "\n",
    "# Example\n",
    "if __name__ == '__main__':\n",
    "    records = [ (1, 2.3, 4.5),\n",
    "                (13, 7.8, 9.0),\n",
    "                (12, 13.4, 56.7) ]\n",
    "    with open('data.b', 'wb') as f:\n",
    "        write_records(records, '<idd', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T08:46:38.292359Z",
     "start_time": "2019-07-15T08:46:38.284550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2.3, 4.5)\n",
      "(13, 7.8, 9.0)\n",
      "(12, 13.4, 56.7)\n",
      "(1, 2.3, 4.5)\n",
      "(13, 7.8, 9.0)\n",
      "(12, 13.4, 56.7)\n"
     ]
    }
   ],
   "source": [
    "from struct import Struct\n",
    "\n",
    "# 塊狀讀取\n",
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(record_struct.size), b'')\n",
    "    return (record_struct.unpack(chunk) for chunk in chunks)\n",
    "\n",
    "# 一次性讀取，分片解析\n",
    "def unpack_records(format, data):\n",
    "    record_struct = Struct(format)\n",
    "    return (\n",
    "        record_struct.unpack_from(data, offset)\n",
    "        for offset in range(0, len(data), record_struct.size)\n",
    "    )\n",
    "\n",
    "# Example\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # 塊狀讀取\n",
    "    with open('data.b','rb') as f:\n",
    "        for rec in read_records('<idd', f):\n",
    "            # Process rec\n",
    "            print(rec)\n",
    "            \n",
    "    # 一次性讀取\n",
    "    with open('data.b', 'rb') as f:\n",
    "        data = f.read()\n",
    "    for rec in unpack_records('<idd', data):\n",
    "        # Process rec    \n",
    "        print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于需要编码和解码二进制数据的程序而言，通常会使用 `struct` 模块。 为了声明一个新的结构体，只需要像这样创建一个 `Struct` 实例即可\n",
    "\n",
    "```py\n",
    "# Little endian 32-bit integer, two double precision floats\n",
    "record_struct = Struct('<idd')\n",
    "```\n",
    "\n",
    "'<idd' -- (13, 7.8, 9.0)\n",
    "\n",
    "    <: 字节顺序\n",
    "    i: int\t  4byte\n",
    "    d: double 8byte\n",
    "\n",
    "\n",
    "[Struct Doc](https://docs.python.org/3/library/struct.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T08:53:02.731870Z",
     "start_time": "2019-07-15T08:53:02.721134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 2.0, 3.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from struct import Struct\n",
    "record_struct = Struct('<idd')\n",
    "record_struct.size\n",
    "\n",
    "#s = (1, 2.0, 3.0)\n",
    "#record_struct.pack(*s)\n",
    "\n",
    "record_struct.pack(1, 2.0, 3.0)\n",
    "\n",
    "\n",
    "import struct\n",
    "\n",
    "#p = struct.pack('<idd', *s)\n",
    "#struct.unpack('<idd',p)\n",
    "\n",
    "struct.pack('<idd', 1, 2.0, 3.0)\n",
    "struct.unpack('<idd', _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取二进制结构的代码要用到一些非常有趣而优美的编程技巧。 在函数　`read_records` 中，`iter()` 被用来创建一个返回固定大小数据块的迭代器，参考5.8小节。 这个迭代器会不断的调用一个用户提供的可调用对象(比如 `lambda: f.read(record_struct.size) )`， 直到它返回一个特殊的值(如`b’‘`)，这时候迭代停止。\n",
    "\n",
    "```py\n",
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(record_struct.size), b'')\n",
    "    return (record_struct.unpack(chunk) for chunk in chunks)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:09:50.839855Z",
     "start_time": "2019-07-15T09:09:50.833999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<callable_iterator at 0x2546677a668>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x01\\x00\\x00\\x00ffffff\\x02@\\x00\\x00\\x00\\x00\\x00\\x00\\x12@'\n",
      "b'\\r\\x00\\x00\\x00333333\\x1f@\\x00\\x00\\x00\\x00\\x00\\x00\"@'\n",
      "b'\\x0c\\x00\\x00\\x00\\xcd\\xcc\\xcc\\xcc\\xcc\\xcc*@\\x9a\\x99\\x99\\x99\\x99YL@'\n"
     ]
    }
   ],
   "source": [
    "f = open('data.b', 'rb')\n",
    "chunks = iter(lambda: f.read(20), b'')\n",
    "chunks\n",
    "\n",
    "for chk in chunks:\n",
    "    print(chk)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在函数 `unpack_records()` 中使用了另外一种方法 `unpack_from()` \n",
    "\n",
    "如果你使用 `unpack()` 来代替 `unpack_from()` ， 你需要修改代码来构造大量的小的切片以及进行偏移量的计算\n",
    "\n",
    "\n",
    "```py\n",
    "\n",
    "# unpack_from()\n",
    "# 一次性讀取，分片解析\n",
    "def unpack_records(format, data):\n",
    "    record_struct = Struct(format)\n",
    "    return (\n",
    "        record_struct.unpack_from(data, offset)\n",
    "        for offset in range(0, len(data), record_struct.size)\n",
    "    )\n",
    "\n",
    "\n",
    "# unpack()\n",
    "def unpack_records(format, data):\n",
    "    record_struct = Struct(format)\n",
    "    return (\n",
    "        record_struct.unpack(data[offset:offset + record_struct.size])\n",
    "        for offset in range(0, len(data), record_struct.size)\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在解包的时候，`collections` 模块中的命名元组对象或许是你想要用到的。 它可以让你给返回元组设置属性名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:12:49.475518Z",
     "start_time": "2019-07-15T09:12:49.468686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2.3, 4.5\n",
      "13, 7.8, 9.0\n",
      "12, 13.4, 56.7\n"
     ]
    }
   ],
   "source": [
    "from struct import Struct\n",
    "\n",
    "# 塊狀讀取\n",
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(record_struct.size), b'')\n",
    "    return (record_struct.unpack(chunk) for chunk in chunks)\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Record = namedtuple('Record', ['kind','x','y'])\n",
    "\n",
    "with open('data.b', 'rb') as f:\n",
    "    records = (Record(*r) for r in read_records('<idd', f))\n",
    "\n",
    "    for r in records:\n",
    "        print(r.kind, r.x, r.y, sep=', ', end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的程序需要处理大量的二进制数据，你最好使用 `numpy` 模块。 例如，你可以将一个二进制数据读取到一个**结构化数组**中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:16:12.274103Z",
     "start_time": "2019-07-15T09:16:12.143945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 1,  2.3,  4.5), (13,  7.8,  9. ), (12, 13.4, 56.7)],\n",
       "      dtype=[('f0', '<i4'), ('f1', '<f8'), ('f2', '<f8')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 2.3, 4.5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "f = open('data.b', 'rb')\n",
    "records = np.fromfile(f, dtype='<i,<d,<d')\n",
    "records\n",
    "records[0]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:05:25.095464Z",
     "start_time": "2019-07-15T11:05:25.084726Z"
    }
   },
   "source": [
    "# 读取嵌套和可变长二进制数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设你用下面的`Python`数据结构 来表示一个组成一系列多边形的点的集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:03:06.883411Z",
     "start_time": "2019-07-17T05:03:06.854101Z"
    }
   },
   "outputs": [],
   "source": [
    "polys = [\n",
    "    [ (1.0, 2.5), (3.5, 4.0), (2.5, 1.5) ],\n",
    "    [ (7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0) ],\n",
    "    [ (3.4, 6.3), (1.2, 0.5), (4.6, 9.2) ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二进制文件\n",
    "\n",
    "    +------+--------+------------------------------------+\n",
    "    |Byte  | Type   |  Description                       |\n",
    "    +======+========+====================================+\n",
    "    |0+4     | int    |  文件代码（0x1234，小端）          |\n",
    "    +------+--------+------------------------------------+\n",
    "    |4+8   | double |  x 的最小值（小端）                |\n",
    "    +------+--------+------------------------------------+\n",
    "    |12+8  | double |  y 的最小值（小端）                |\n",
    "    +------+--------+------------------------------------+\n",
    "    |20+8  | double |  x 的最大值（小端）                |\n",
    "    +------+--------+------------------------------------+\n",
    "    |28+8  | double |  y 的最大值（小端）                |\n",
    "    +------+--------+------------------------------------+\n",
    "    |36+4  | int    |  多边形数量（小端）                |\n",
    "    +------+--------+------------------------------------+\n",
    "    \n",
    "多边形记录\n",
    "\n",
    "    +------+--------+-------------------------------------------+\n",
    "    |Byte  | Type   |  Description                              |\n",
    "    +======+========+===========================================+\n",
    "    |0     | int    |  记录长度（N字节）                        |\n",
    "    +------+--------+-------------------------------------------+\n",
    "    |4-N   | Points |  (X,Y) 坐标，以浮点数表示                 |\n",
    "    +------+--------+-------------------------------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:07:26.514817Z",
     "start_time": "2019-07-17T05:07:26.504086Z"
    }
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import itertools\n",
    "\n",
    "def write_polys(filename, polys):\n",
    "    # Determine bounding box\n",
    "    flattened = list(itertools.chain(*polys))\n",
    "    min_x = min(x for x, y in flattened)\n",
    "    max_x = max(x for x, y in flattened)\n",
    "    min_y = min(y for x, y in flattened)\n",
    "    max_y = max(y for x, y in flattened)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(\n",
    "            struct.pack(\n",
    "                '<iddddi', 0x1234,\n",
    "                min_x, min_y,\n",
    "                max_x, max_y,\n",
    "                len(polys)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        for poly in polys:\n",
    "            # 记录长度\n",
    "            size = len(poly) * struct.calcsize('<dd')\n",
    "            f.write(struct.pack('<i', size + 4))\n",
    "            for pt in poly:\n",
    "                # 记录 (X,Y) 坐标\n",
    "                f.write(struct.pack('<dd', *pt))\n",
    "                \n",
    "def read_polys(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read the header\n",
    "        header = f.read(40)\n",
    "        file_code, min_x, min_y, max_x, max_y, num_polys = \\\n",
    "            struct.unpack('<iddddi', header)\n",
    "        \n",
    "        # 多边形数量\n",
    "        polys = []\n",
    "        for n in range(num_polys):\n",
    "            # 多边形 Points 的組成\n",
    "            pbytes, = struct.unpack('<i', f.read(4))\n",
    "            poly = []\n",
    "            # 各個 Points\n",
    "            for m in range(pbytes // 16):\n",
    "                pt = struct.unpack('<dd', f.read(16))\n",
    "                poly.append(pt)\n",
    "            polys.append(poly)\n",
    "    return polys               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:08:11.380720Z",
     "start_time": "2019-07-17T05:08:11.363179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1.0, 2.5), (3.5, 4.0), (2.5, 1.5)],\n",
       " [(7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0)],\n",
       " [(3.4, 6.3), (1.2, 0.5), (4.6, 9.2)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_polys('polys.bin', polys)\n",
    "\n",
    "read_polys('polys.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解二进制文件，class，簡化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:09:28.870219Z",
     "start_time": "2019-07-17T05:09:28.864362Z"
    }
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "class StructField:\n",
    "    '''\n",
    "    Descriptor representing a simple structure field\n",
    "    '''\n",
    "    def __init__(self, format, offset):\n",
    "        self.format = format\n",
    "        self.offset = offset\n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            r = struct.unpack_from(\n",
    "                self.format, instance._buffer, self.offset\n",
    "            )\n",
    "            return r[0] if len(r) == 1 else r\n",
    "\n",
    "class Structure:\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = memoryview(bytedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:09:30.057388Z",
     "start_time": "2019-07-17T05:09:30.052514Z"
    }
   },
   "outputs": [],
   "source": [
    "class PolyHeader(Structure):\n",
    "    file_code = StructField('<i', 0)\n",
    "    min_x = StructField('<d', 4)\n",
    "    min_y = StructField('<d', 12)\n",
    "    max_x = StructField('<d', 20)\n",
    "    max_y = StructField('<d', 28)\n",
    "    num_polys = StructField('<i', 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:14:58.450532Z",
     "start_time": "2019-07-17T05:14:58.438820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader(f.read(40))\n",
    "\n",
    "phead.file_code == 0x1234 # True\n",
    "phead.min_x # 0.5\n",
    "phead.min_y # 0.5\n",
    "phead.max_x # 7.0\n",
    "phead.max_y # 9.2\n",
    "phead.num_polys # 3\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解二进制文件，Metaclass 元類，簡化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:27:50.251960Z",
     "start_time": "2019-07-17T05:27:50.243237Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import struct\n",
    "\n",
    "class StructField:\n",
    "    '''\n",
    "    Descriptor representing a simple structure field\n",
    "    '''\n",
    "    def __init__(self, format, offset):\n",
    "        self.format = format\n",
    "        self.offset = offset\n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            r = struct.unpack_from(\n",
    "                self.format, instance._buffer, self.offset\n",
    "            )\n",
    "            return r[0] if len(r) == 1 else r\n",
    "\n",
    "class StructureMeta(type):\n",
    "    '''\n",
    "    Metaclass that automatically creates StructField descriptors\n",
    "    '''\n",
    "    def __init__(self, clsname, bases, clsdict):\n",
    "        \n",
    "        fields = getattr(self, '_fields_', [])\n",
    "        byte_order = ''\n",
    "        offset = 0\n",
    "        \n",
    "        for format, fieldname in fields:\n",
    "            if format.startswith(('<','>','!','@')):\n",
    "                byte_order = format[0]\n",
    "                format = format[1:]\n",
    "            format = byte_order + format\n",
    "            \n",
    "            # file_code = StructField('<i', 0)\n",
    "            # min_x = StructField('<d', 4)\n",
    "            setattr(self, fieldname, StructField(format, offset))\n",
    "            offset += struct.calcsize(format)\n",
    "            \n",
    "        setattr(self, 'struct_size', offset)\n",
    "\n",
    "class Structure(metaclass=StructureMeta):\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = bytedata\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, f):\n",
    "        return cls(f.read(cls.struct_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:28:06.650566Z",
     "start_time": "2019-07-17T05:28:06.645686Z"
    }
   },
   "outputs": [],
   "source": [
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        ('d', 'min_x'),\n",
    "        ('d', 'min_y'),\n",
    "        ('d', 'max_x'),\n",
    "        ('d', 'max_y'),\n",
    "        ('i', 'num_polys')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T05:28:07.892696Z",
     "start_time": "2019-07-17T05:28:07.872200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "\n",
    "phead.file_code == 0x1234 # True\n",
    "phead.min_x # 0.5\n",
    "phead.min_y # 0.5\n",
    "phead.max_x # 7.0\n",
    "phead.max_y # 9.2\n",
    "phead.num_polys # 3\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更加智能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:42:46.710043Z",
     "start_time": "2019-07-17T06:42:46.699339Z"
    }
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "# ===============================\n",
    "#   StructField('<d', 4)\n",
    "# ===============================\n",
    "class StructField:\n",
    "    '''\n",
    "    Descriptor representing a simple structure field\n",
    "    '''\n",
    "    def __init__(self, format, offset):\n",
    "        self.format = format\n",
    "        self.offset = offset\n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            r = struct.unpack_from(\n",
    "                self.format, instance._buffer, self.offset\n",
    "            )\n",
    "            return r[0] if len(r) == 1 else r\n",
    "\n",
    "# ===============================\n",
    "#   延伸定義 StructField EX.\n",
    "#   class Point(Structure):\n",
    "#    _fields_ = [\n",
    "#        ('<d', 'x'),\n",
    "#        ('d', 'y')\n",
    "#    ]\n",
    "#\n",
    "#   (Point, 'min'), # nested struct\n",
    "# =============================== \n",
    "class NestedStruct:\n",
    "    '''\n",
    "    Descriptor representing a nested structure\n",
    "    '''\n",
    "    def __init__(self, name, struct_type, offset):\n",
    "        self.name = name\n",
    "        self.struct_type = struct_type\n",
    "        self.offset = offset\n",
    "\n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            data = instance._buffer[\n",
    "                # 切片\n",
    "                self.offset:\n",
    "                self.offset + self.struct_type.struct_size\n",
    "            ]\n",
    "            result = self.struct_type(data)\n",
    "            # Save resulting structure back on instance to avoid\n",
    "            # further recomputation of this step\n",
    "            setattr(instance, self.name, result)\n",
    "            return result\n",
    "        \n",
    "# ===============================\n",
    "#   解析 \n",
    "#   class Point(Structure):\n",
    "#    _fields_ = [\n",
    "#        ('<d', 'x'),\n",
    "#        ('d', 'y')\n",
    "#    ]\n",
    "#\n",
    "#   to: x = StructField('<d', 4)\n",
    "# ===============================        \n",
    "class StructureMeta(type):\n",
    "    '''\n",
    "    Metaclass that automatically creates StructField descriptors\n",
    "    '''\n",
    "    def __init__(self, clsname, bases, clsdict):\n",
    "        fields = getattr(self, '_fields_', [])\n",
    "        byte_order = ''\n",
    "        offset = 0\n",
    "        for format, fieldname in fields:\n",
    "            if isinstance(format, StructureMeta):\n",
    "                setattr(\n",
    "                    self, fieldname,\n",
    "                    NestedStruct(fieldname, format, offset)\n",
    "                )\n",
    "                offset += format.struct_size\n",
    "            else:\n",
    "                if format.startswith(('<','>','!','@')):\n",
    "                    byte_order = format[0]\n",
    "                    format = format[1:]\n",
    "                format = byte_order + format\n",
    "                \n",
    "                # file_code = StructField('<i', 0)\n",
    "                # min_x = StructField('<d', 4)\n",
    "                setattr(self, fieldname, StructField(format, offset))\n",
    "                offset += struct.calcsize(format)\n",
    "        setattr(self, 'struct_size', offset)\n",
    "\n",
    "        \n",
    "# ===============================        \n",
    "#  使用元類 StructureMeta         \n",
    "# ===============================    \n",
    "class Structure(metaclass=StructureMeta):\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = bytedata\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, f):\n",
    "        return cls(f.read(cls.struct_size))\n",
    "\n",
    "    \n",
    "# =============================== \n",
    "#  SizedRecord  \n",
    "#   \n",
    "#  可以使用 iter_as() 方法来达到目的，\n",
    "#  这个方法接受一个结构格式化编码或者是 Structure 类作为输入。 \n",
    "#  这样子可以很灵活的去解析数据         \n",
    "# ===============================      \n",
    "class SizedRecord:\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = memoryview(bytedata)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, f, size_fmt, includes_size=True):\n",
    "        sz_nbytes = struct.calcsize(size_fmt)\n",
    "        sz_bytes = f.read(sz_nbytes)\n",
    "        sz, = struct.unpack(size_fmt, sz_bytes)\n",
    "        buf = f.read(sz - includes_size * sz_nbytes)\n",
    "        return cls(buf)\n",
    "\n",
    "    def iter_as(self, code):\n",
    "        if isinstance(code, str):\n",
    "            s = struct.Struct(code)\n",
    "            for off in range(0, len(self._buffer), s.size):\n",
    "                yield s.unpack_from(self._buffer, off)\n",
    "        elif isinstance(code, StructureMeta):\n",
    "            size = code.struct_size\n",
    "            for off in range(0, len(self._buffer), size):\n",
    "                data = self._buffer[off:off+size]\n",
    "                yield code(data)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:58:00.969548Z",
     "start_time": "2019-07-17T06:58:00.962725Z"
    }
   },
   "outputs": [],
   "source": [
    "class Point(Structure):\n",
    "    _fields_ = [\n",
    "        ('<d', 'x'),\n",
    "        ('d', 'y')\n",
    "    ]\n",
    "\n",
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        (Point, 'min'), # nested struct\n",
    "        (Point, 'max'), # nested struct\n",
    "        ('i', 'num_polys')\n",
    "    ]\n",
    "    \n",
    "# 使用 SizedRecord 去解析\n",
    "def read_polys(filename):\n",
    "    polys = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        phead = PolyHeader.from_file(f)\n",
    "        for n in range(phead.num_polys):\n",
    "            rec = SizedRecord.from_file(f, '<i')\n",
    "            poly = [ (p.x, p.y) for p in rec.iter_as(Point) ]\n",
    "            polys.append(poly)\n",
    "    return polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:43:47.343839Z",
     "start_time": "2019-07-17T06:43:47.327274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x219f1e70b00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9.2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "\n",
    "phead.file_code == 0x1234 # True\n",
    "\n",
    "phead.min # Nested structure \n",
    "\n",
    "phead.min.x # 0.5\n",
    "phead.min.y # 0.5\n",
    "phead.max.x # 7.0\n",
    "phead.max.y # 9.2\n",
    "phead.num_polys # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:58:04.495788Z",
     "start_time": "2019-07-17T06:58:04.489932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1.0, 2.5), (3.5, 4.0), (2.5, 1.5)],\n",
       " [(7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0)],\n",
       " [(3.4, 6.3), (1.2, 0.5), (4.6, 9.2)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_polys('polys.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SizedRecord**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:52:10.744372Z",
     "start_time": "2019-07-17T06:52:10.735618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.SizedRecord at 0x219f0b05208>,\n",
       " <__main__.SizedRecord at 0x219f1e70080>,\n",
       " <__main__.SizedRecord at 0x219f1e709e8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "phead.num_polys\n",
    "\n",
    "polydata = [ \n",
    "    SizedRecord.from_file(f, '<i')\n",
    "    for n in range(phead.num_polys)\n",
    "]\n",
    "\n",
    "polydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，`SizedRecord` 实例的内容还没有被解析出来。 可以使用 `iter_as()` 方法来达到目的，这个方法接受一个结构格式化编码或者是 `Structure` 类作为输入。 这样子可以很灵活的去解析数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:52:35.112653Z",
     "start_time": "2019-07-17T06:52:35.107758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon 0\n",
      "(1.0, 2.5)\n",
      "(3.5, 4.0)\n",
      "(2.5, 1.5)\n",
      "Polygon 1\n",
      "(7.0, 1.2)\n",
      "(5.1, 3.0)\n",
      "(0.5, 7.5)\n",
      "(0.8, 9.0)\n",
      "Polygon 2\n",
      "(3.4, 6.3)\n",
      "(1.2, 0.5)\n",
      "(4.6, 9.2)\n"
     ]
    }
   ],
   "source": [
    "for n, poly in enumerate(polydata):\n",
    "    print('Polygon', n)\n",
    "    for p in poly.iter_as('<dd'):\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:52:48.984906Z",
     "start_time": "2019-07-17T06:52:48.980026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon 0\n",
      "1.0 2.5\n",
      "3.5 4.0\n",
      "2.5 1.5\n",
      "Polygon 1\n",
      "7.0 1.2\n",
      "5.1 3.0\n",
      "0.5 7.5\n",
      "0.8 9.0\n",
      "Polygon 2\n",
      "3.4 6.3\n",
      "1.2 0.5\n",
      "4.6 9.2\n"
     ]
    }
   ],
   "source": [
    "for n, poly in enumerate(polydata):\n",
    "    print('Polygon', n)\n",
    "    for p in poly.iter_as(Point):\n",
    "        print(p.x, p.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:53:14.454233Z",
     "start_time": "2019-07-17T06:53:14.450330Z"
    }
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [pandas]数据的累加与统计操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:13:29.466306Z",
     "start_time": "2019-07-15T11:13:29.438979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creation Date</th>\n",
       "      <th>Status</th>\n",
       "      <th>Completion Date</th>\n",
       "      <th>Service Request Number</th>\n",
       "      <th>Type of Service Request</th>\n",
       "      <th>Number of Premises Baited</th>\n",
       "      <th>Number of Premises with Garbage</th>\n",
       "      <th>Number of Premises with Rats</th>\n",
       "      <th>Current Activity</th>\n",
       "      <th>Most Recent Action</th>\n",
       "      <th>...</th>\n",
       "      <th>Police District</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Historical Wards 2003-2015</th>\n",
       "      <th>Zip Codes</th>\n",
       "      <th>Community Areas</th>\n",
       "      <th>Census Tracts</th>\n",
       "      <th>Wards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/18/2018</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-03388270</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>41.940253</td>\n",
       "      <td>-87.696093</td>\n",
       "      <td>(41.940252960348, -87.696092533073)</td>\n",
       "      <td>2</td>\n",
       "      <td>21538</td>\n",
       "      <td>22</td>\n",
       "      <td>425.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/18/2018</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-03388125</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>41.988475</td>\n",
       "      <td>-87.705812</td>\n",
       "      <td>(41.98847449993, -87.705811949507)</td>\n",
       "      <td>46</td>\n",
       "      <td>4450</td>\n",
       "      <td>20</td>\n",
       "      <td>65.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/18/2018</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-03388055</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>41.963051</td>\n",
       "      <td>-87.727885</td>\n",
       "      <td>(41.963051420227, -87.727885158144)</td>\n",
       "      <td>28</td>\n",
       "      <td>21869</td>\n",
       "      <td>14</td>\n",
       "      <td>257.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/18/2018</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-03386546</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>41.928771</td>\n",
       "      <td>-87.668625</td>\n",
       "      <td>(41.928771396163, -87.668625093921)</td>\n",
       "      <td>16</td>\n",
       "      <td>21190</td>\n",
       "      <td>68</td>\n",
       "      <td>743.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/18/2018</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-03387374</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>41.925397</td>\n",
       "      <td>-87.797734</td>\n",
       "      <td>(41.925396948049, -87.797734406018)</td>\n",
       "      <td>39</td>\n",
       "      <td>4454</td>\n",
       "      <td>18</td>\n",
       "      <td>136.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Creation Date Status  Completion Date Service Request Number  \\\n",
       "0    12/18/2018   Open              NaN            18-03388270   \n",
       "1    12/18/2018   Open              NaN            18-03388125   \n",
       "2    12/18/2018   Open              NaN            18-03388055   \n",
       "3    12/18/2018   Open              NaN            18-03386546   \n",
       "4    12/18/2018   Open              NaN            18-03387374   \n",
       "\n",
       "        Type of Service Request  Number of Premises Baited  \\\n",
       "0  Rodent Baiting/Rat Complaint                        NaN   \n",
       "1  Rodent Baiting/Rat Complaint                        NaN   \n",
       "2  Rodent Baiting/Rat Complaint                        NaN   \n",
       "3  Rodent Baiting/Rat Complaint                        NaN   \n",
       "4  Rodent Baiting/Rat Complaint                        NaN   \n",
       "\n",
       "   Number of Premises with Garbage  Number of Premises with Rats  \\\n",
       "0                              NaN                           NaN   \n",
       "1                              NaN                           NaN   \n",
       "2                              NaN                           NaN   \n",
       "3                              NaN                           NaN   \n",
       "4                              NaN                           NaN   \n",
       "\n",
       "   Current Activity  Most Recent Action  ...  Police District  Community Area  \\\n",
       "0               NaN                 NaN  ...               17              21   \n",
       "1               NaN                 NaN  ...               20               2   \n",
       "2               NaN                 NaN  ...               17              14   \n",
       "3               NaN                 NaN  ...               19               7   \n",
       "4               NaN                 NaN  ...               25              18   \n",
       "\n",
       "    Latitude  Longitude                             Location  \\\n",
       "0  41.940253 -87.696093  (41.940252960348, -87.696092533073)   \n",
       "1  41.988475 -87.705812   (41.98847449993, -87.705811949507)   \n",
       "2  41.963051 -87.727885  (41.963051420227, -87.727885158144)   \n",
       "3  41.928771 -87.668625  (41.928771396163, -87.668625093921)   \n",
       "4  41.925397 -87.797734  (41.925396948049, -87.797734406018)   \n",
       "\n",
       "   Historical Wards 2003-2015  Zip Codes  Community Areas  Census Tracts Wards  \n",
       "0                           2      21538               22          425.0    20  \n",
       "1                          46       4450               20           65.0    24  \n",
       "2                          28      21869               14          257.0    12  \n",
       "3                          16      21190               68          743.0    40  \n",
       "4                          39       4454               18          136.0    44  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "rats = pandas.read_csv('rats.csv')\n",
    "rats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:16:08.156576Z",
     "start_time": "2019-07-15T11:16:08.150722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21538,  4450, 21869, 21190,  4454,  4299,  4300, 21569, 22268,\n",
       "       22216, 21186, 21192], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate range of values for a Zip Code\n",
    "rats['Zip Codes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:16:33.511732Z",
     "start_time": "2019-07-15T11:16:33.505848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data\n",
    "crew_dispatched = rats[rats['Zip Codes'] == 21538]\n",
    "len(crew_dispatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:18:15.072281Z",
     "start_time": "2019-07-15T11:18:15.063497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60614    3\n",
       "60652    2\n",
       "60638    1\n",
       "60651    1\n",
       "60618    1\n",
       "60615    1\n",
       "60630    1\n",
       "60613    1\n",
       "60644    1\n",
       "60659    1\n",
       "Name: ZIP Code, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find 10 most rat-infested ZIP codes in Chicago\n",
    "rats['ZIP Code'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:21:59.033083Z",
     "start_time": "2019-07-15T11:21:59.024299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP Code\n",
       "60613     18\n",
       "60614    120\n",
       "60615     10\n",
       "60618     20\n",
       "60623     28\n",
       "60630     12\n",
       "60638      6\n",
       "60644      7\n",
       "60651     45\n",
       "60652     60\n",
       "60659     24\n",
       "60707     44\n",
       "Name: Wards, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by \n",
    "datas = rats.groupby('ZIP Code')\n",
    "datas.Wards.sum()\n",
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "192px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
