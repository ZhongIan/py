{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#[re.split()-非捕获分组，如-(?:...)]使用多个界定符分割字符串\" data-toc-modified-id=\"[re.split()-非捕获分组，如-(?:...)]使用多个界定符分割字符串-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>[re.split() 非捕获分组，如 (?:...)]使用多个界定符分割字符串</a></span></li><li><span><a href=\"#[str.startswith()]字符串开头或结尾匹配\" data-toc-modified-id=\"[str.startswith()]字符串开头或结尾匹配-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>[str.startswith()]字符串开头或结尾匹配</a></span></li><li><span><a href=\"#[*?]用Shell通配符匹配字符串\" data-toc-modified-id=\"[*?]用Shell通配符匹配字符串-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>[*?]用Shell通配符匹配字符串</a></span></li><li><span><a href=\"#[re]字符串匹配和搜索\" data-toc-modified-id=\"[re]字符串匹配和搜索-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>[re]字符串匹配和搜索</a></span></li><li><span><a href=\"#[re.sub()]字符串搜索和替换\" data-toc-modified-id=\"[re.sub()]字符串搜索和替换-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>[re.sub()]字符串搜索和替换</a></span></li><li><span><a href=\"#[re.IGNORECASE]字符串忽略大小写的搜索替换\" data-toc-modified-id=\"[re.IGNORECASE]字符串忽略大小写的搜索替换-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>[re.IGNORECASE]字符串忽略大小写的搜索替换</a></span></li><li><span><a href=\"#最短匹配模式\" data-toc-modified-id=\"最短匹配模式-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>最短匹配模式</a></span></li><li><span><a href=\"#(?:.|\\n)跨行匹配模式\" data-toc-modified-id=\"(?:.|\\n)跨行匹配模式-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>(?:.|\\n)跨行匹配模式</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[unicodedata]将Unicode文本标准化\" data-toc-modified-id=\"[unicodedata]将Unicode文本标准化-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>[unicodedata]将Unicode文本标准化</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#在正则式中使用Unicode[建議安裝第三方套件]\" data-toc-modified-id=\"在正则式中使用Unicode[建議安裝第三方套件]-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>在正则式中使用Unicode[建議安裝第三方套件]</a></span></li><li><span><a href=\"#[str.strip()-re.sub()]删除字符串中不需要的字符\" data-toc-modified-id=\"[str.strip()-re.sub()]删除字符串中不需要的字符-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>[str.strip() re.sub()]删除字符串中不需要的字符</a></span></li><li><span><a href=\"#[str.translate()]审查清理文本字符串\" data-toc-modified-id=\"[str.translate()]审查清理文本字符串-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>[str.translate()]审查清理文本字符串</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[format()]字符串对齐\" data-toc-modified-id=\"[format()]字符串对齐-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>[format()]字符串对齐</a></span><ul class=\"toc-item\"><li><span><a href=\"#format()\" data-toc-modified-id=\"format()-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>format()</a></span></li></ul></li><li><span><a href=\"#[join()]合并拼接字符串\" data-toc-modified-id=\"[join()]合并拼接字符串-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>[join()]合并拼接字符串</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[format()-format_map()-和-vars()]字符串中插入变量\" data-toc-modified-id=\"[format()-format_map()-和-vars()]字符串中插入变量-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>[format() format_map() 和 vars()]字符串中插入变量</a></span></li><li><span><a href=\"#[textwrap.fill()]以指定列宽格式化字符串\" data-toc-modified-id=\"[textwrap.fill()]以指定列宽格式化字符串-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>[textwrap.fill()]以指定列宽格式化字符串</a></span><ul class=\"toc-item\"><li><span><a href=\"#[os.get_terminal_size()]讨论\" data-toc-modified-id=\"[os.get_terminal_size()]讨论-16.1\"><span class=\"toc-item-num\">16.1&nbsp;&nbsp;</span>[os.get_terminal_size()]讨论</a></span></li></ul></li><li><span><a href=\"#[html.escape()]在字符串中处理html和xml\" data-toc-modified-id=\"[html.escape()]在字符串中处理html和xml-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>[html.escape()]在字符串中处理html和xml</a></span><ul class=\"toc-item\"><li><span><a href=\"#[html.parse-xml.etree.ElementTree]讨论\" data-toc-modified-id=\"[html.parse-xml.etree.ElementTree]讨论-17.1\"><span class=\"toc-item-num\">17.1&nbsp;&nbsp;</span>[html.parse xml.etree.ElementTree]讨论</a></span></li></ul></li><li><span><a href=\"#字符串令牌解析\" data-toc-modified-id=\"字符串令牌解析-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>字符串令牌解析</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-18.1\"><span class=\"toc-item-num\">18.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li><li><span><a href=\"#[3-+-4-=-7-字符解析處理]实现一个简单的递归下降分析器\" data-toc-modified-id=\"[3-+-4-=-7-字符解析處理]实现一个简单的递归下降分析器-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>[3 + 4 = 7 字符解析處理]实现一个简单的递归下降分析器</a></span><ul class=\"toc-item\"><li><span><a href=\"#PLY-模塊\" data-toc-modified-id=\"PLY-模塊-19.1\"><span class=\"toc-item-num\">19.1&nbsp;&nbsp;</span>PLY 模塊</a></span></li></ul></li><li><span><a href=\"#[b'-']字节字符串上的字符串操作\" data-toc-modified-id=\"[b'-']字节字符串上的字符串操作-20\"><span class=\"toc-item-num\">20&nbsp;&nbsp;</span>[b' ']字节字符串上的字符串操作</a></span><ul class=\"toc-item\"><li><span><a href=\"#讨论\" data-toc-modified-id=\"讨论-20.1\"><span class=\"toc-item-num\">20.1&nbsp;&nbsp;</span>讨论</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "**來源**\n",
    "\n",
    "[python3-cookbook 第二章：字符串和文本](https://python3-cookbook.readthedocs.io/zh_CN/latest/chapters/p02_strings_and_text.html)\n",
    "\n",
    "**小計**\n",
    "\n",
    "    str.startswith() # 字符串开头或结尾匹配\n",
    "    str.strip() # 删除字符串[首尾]中不需要的字符\n",
    "    str.lstrip() # 左\n",
    "    str.rstrip() # 右\n",
    "    str.join() \n",
    "    str.translate() # 替換 ord\n",
    "\n",
    "    format() # 字符串对齐 格式\n",
    "\n",
    "    s.format_map(vars()) # 在作用域中尋找\n",
    "\n",
    "\n",
    "    re.split()\n",
    "    re.sub() # 替換\n",
    "        (?:.|\\n) # 跨行匹配模式\n",
    "        r'\"(.*?)\"' # 最短匹配模式\n",
    "\n",
    "    re.IGNORECASE # 字符串忽略大小写的搜索替换\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [re.split() 非捕获分组，如 (?:...)]使用多个界定符分割字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T06:54:40.686502Z",
     "start_time": "2019-06-24T06:54:40.678694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "line = 'asdf fjdk; afed, fjek,asdf, foo'\n",
    "re.split(r'[;,\\s]\\s*', line)\n",
    "\n",
    "# 分組\n",
    "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保留分割字符串，用来在后面重新构造一个新的输出字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T06:57:14.274596Z",
     "start_time": "2019-06-24T06:57:14.264850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[' ', ';', ',', ',', ',', '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'asdf fjdk;afed,fjek,asdf,foo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = fields[::2]\n",
    "delimiters = fields[1::2] + ['']\n",
    "\n",
    "values\n",
    "delimiters\n",
    "\n",
    "''.join(v+d for v,d in zip(values, delimiters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**非捕获分组，形如 (?:...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T06:58:16.902427Z",
     "start_time": "2019-06-24T06:58:16.897546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'(?:,|;|\\s)\\s*', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [str.startswith()]字符串开头或结尾匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T09:21:52.954430Z",
     "start_time": "2019-06-24T09:21:52.935885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'spam.txt'\n",
    "\n",
    "filename.endswith('.txt') # True\n",
    "filename.startswith('file:') # False\n",
    "\n",
    "url = 'http://www.python.org'\n",
    "\n",
    "url.startswith('http:') # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**多匹配**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T09:23:15.800257Z",
     "start_time": "2019-06-24T09:23:15.792449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo.c', 'spam.c', 'spam.h']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [ 'Makefile', 'foo.c', 'bar.py', 'spam.c', 'spam.h' ]\n",
    "\n",
    "[name for name in filenames if name.endswith(('.c', '.h'))]\n",
    "any(name.endswith('.py') for name in filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只接收`tuple()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T09:25:10.348992Z",
     "start_time": "2019-06-24T09:25:10.042529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "TypeError",
     "evalue": "startswith first arg must be str or a tuple of str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-380c5803e15b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: startswith first arg must be str or a tuple of str, not list"
     ]
    }
   ],
   "source": [
    "choices = ['http:', 'ftp:']\n",
    "url = 'http://www.python.org'\n",
    "\n",
    "url.startswith(tuple(choices))\n",
    "\n",
    "url.startswith(choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [*?]用Shell通配符匹配字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T09:28:57.374659Z",
     "start_time": "2019-06-24T09:28:57.363470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Dat1.csv', 'Dat2.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fnmatch import fnmatch, fnmatchcase\n",
    "\n",
    "fnmatch('foo.txt', '*.txt') # True\n",
    "fnmatch('foo.txt', '?oo.txt') # True\n",
    "fnmatch('Dat45.csv', 'Dat[0-9]*') # True\n",
    "\n",
    "names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']\n",
    "[name for name in names if fnmatch(name, 'Dat*.csv')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**大小写敏感-依作業系統**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T09:31:06.008915Z",
     "start_time": "2019-06-24T09:31:06.003085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On OS X (Mac)\n",
    "fnmatch('foo.txt', '*.TXT') # False\n",
    "# On Windows\n",
    "fnmatch('foo.txt', '*.TXT') # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T09:32:03.954898Z",
     "start_time": "2019-06-24T09:32:03.947090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5412 N CLARK ST', '1060 W ADDISON ST', '2122 N CLARK ST']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['5412 N CLARK ST']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = [\n",
    "    '5412 N CLARK ST',\n",
    "    '1060 W ADDISON ST',\n",
    "    '1039 W GRANVILLE AVE',\n",
    "    '2122 N CLARK ST',\n",
    "    '4802 N BROADWAY',\n",
    "]\n",
    "\n",
    "from fnmatch import fnmatchcase\n",
    "\n",
    "[addr for addr in addresses if fnmatchcase(addr, '* ST')]\n",
    "\n",
    "[addr for addr in addresses if fnmatchcase(addr, '54[0-9][0-9] *CLARK*')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [re]字符串匹配和搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基本字符串方法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T03:05:54.664164Z",
     "start_time": "2019-06-25T03:05:54.558818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "# Exact match\n",
    "text == 'yeah' # False\n",
    "\n",
    "# Match at start or end\n",
    "text.startswith('yeah') # True\n",
    "\n",
    "text.endswith('no') # False\n",
    "\n",
    "# Search for the location of the first occurrence\n",
    "text.find('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**正则表达式和 re 模块**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T03:07:25.619580Z",
     "start_time": "2019-06-25T03:07:25.537461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "text1 = '11/27/2012'\n",
    "text2 = 'Nov 27, 2012'\n",
    "\n",
    "import re\n",
    "# Simple matching: \\d+ means match one or more digits\n",
    "\n",
    "if re.match(r'\\d+/\\d+/\\d+', text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "    \n",
    "if re.match(r'\\d+/\\d+/\\d+', text2):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**同一个模式去做多次匹配**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T03:10:47.196336Z",
     "start_time": "2019-06-25T03:10:47.191346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "datepat = re.compile(r'\\d+/\\d+/\\d+')\n",
    "\n",
    "if datepat.match(text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "    \n",
    "if datepat.match(text2):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`match()` 总是从字符串开始去匹配，如果你想查找字符串任意部分的模式出现位置， 使用 `findall()` 方法去代替。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T03:12:38.418109Z",
     "start_time": "2019-06-25T03:12:38.292389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11/27/2012', '3/13/2013']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "datepat.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**捕获分组**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T03:19:31.703953Z",
     "start_time": "2019-06-25T03:19:31.667181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 10), match='11/27/2012'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'11/27/2012'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'11'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'27'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2012'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('11', '27', '2012')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('11', '27', '2012'), ('3', '13', '2013')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-11-27\n",
      "2013-3-13\n",
      "-----------\n",
      "('11', '27', '2012')\n",
      "('3', '13', '2013')\n"
     ]
    }
   ],
   "source": [
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "\n",
    "m = datepat.match('11/27/2012')\n",
    "m\n",
    "# Extract the contents of each group\n",
    "m.group(0) # '11/27/2012'\n",
    "m.group(1) # '11'\n",
    "m.group(2) # '27'\n",
    "m.group(3) # '2012'\n",
    "m.groups() # ('11', '27', '2012')\n",
    "month, day, year = m.groups()\n",
    "\n",
    "# Find all matches (notice splitting into tuples)\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "\n",
    "datepat.findall(text) # 返回列表\n",
    "\n",
    "for month, day, year in datepat.findall(text):\n",
    "    print('{}-{}-{}'.format(year, month, day))\n",
    "\n",
    "print('-----------')\n",
    "# finditer() 迭代方式返回匹配    \n",
    "for m in datepat.finditer(text):\n",
    "    print(m.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T03:23:57.542351Z",
     "start_time": "2019-06-25T03:23:57.539359Z"
    }
   },
   "source": [
    "```py\n",
    "r'(\\d+)/(\\d+)/(\\d+)'\n",
    "# = '(\\\\d+)/(\\\\d+)/(\\\\d+)'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [re.sub()]字符串搜索和替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T13:37:43.977865Z",
     "start_time": "2019-06-25T13:37:43.958345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yep, but no, but yep, but no, but yep'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "text.replace('yeah', 'yep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`re` 模块中的 `sub()` 函数。 为了说明这个，假设你想将形式为 `11/27/2012` 的日期字符串改成 `2012-11-27`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T13:39:55.535112Z",
     "start_time": "2019-06-25T13:39:55.428727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 2012-11-27. PyCon starts 2013-3-13.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Today is 2012-11-27. PyCon starts 2013-3-13.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "import re\n",
    "re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text)\n",
    "\n",
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "datepat.sub(r'\\3-\\1-\\2', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T14:11:34.471998Z",
     "start_time": "2019-06-25T14:11:34.432018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 10), match='11/27/2012'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'11/27/2012'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'11'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'27'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2012'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('11', '27', '2012')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Today is 27 Nov 2012. PyCon starts 13 Mar 2013.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "\n",
    "m = datepat.match('11/27/2012')\n",
    "m\n",
    "# Extract the contents of each group\n",
    "m.group(0) # '11/27/2012'\n",
    "m.group(1) # '11'\n",
    "m.group(2) # '27'\n",
    "m.group(3) # '2012'\n",
    "m.groups() # ('11', '27', '2012')\n",
    "month, day, year = m.groups()\n",
    "\n",
    "# 轉換月焚為中文 11 -> Nov\n",
    "from calendar import month_abbr\n",
    "\n",
    "def change_date(m):\n",
    "    mon_name = month_abbr[int(m.group(1))]\n",
    "    return '{} {} {}'.format(m.group(2), mon_name, m.group(3))\n",
    "\n",
    "datepat.sub(change_date, text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果除了替换后的结果外，你还想知道有多少替换发生了，可以使用 `re.subn()` 来代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T14:11:59.266865Z",
     "start_time": "2019-06-25T14:11:59.260987Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 2012-11-27. PyCon starts 2013-3-13.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtext, n = datepat.subn(r'\\3-\\1-\\2', text)\n",
    "\n",
    "newtext\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [re.IGNORECASE]字符串忽略大小写的搜索替换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了在文本操作时忽略大小写，你需要在使用 re 模块的时候给这些操作提供 `re.IGNORECASE` 标志参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T17:01:06.062587Z",
     "start_time": "2019-06-26T17:01:05.663908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PYTHON', 'python', 'Python']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'UPPER snake, lower snake, Mixed snake'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'UPPER PYTHON, lower python, Mixed Python'\n",
    "\n",
    "re.findall('python', text, flags=re.IGNORECASE)\n",
    "\n",
    "re.sub('python', 'snake', text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T17:04:19.695471Z",
     "start_time": "2019-06-26T17:04:19.386970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPPER SNAKE, lower snake, Mixed Snake'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matchcase(word):\n",
    "    def replace(m):\n",
    "        text = m.group()\n",
    "        # 'PYTHON'\n",
    "        if text.isupper():\n",
    "            return word.upper()\n",
    "        # 'python'\n",
    "        elif text.islower():\n",
    "            return word.lower()\n",
    "        # 'Python'\n",
    "        elif text[0].isupper():\n",
    "            # 返回一個首字母大寫的字符串\n",
    "            return word.capitalize()\n",
    "        else:\n",
    "            return word\n",
    "    return replace\n",
    "\n",
    "re.sub('python', matchcase('snake'), text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最短匹配模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T17:08:58.905956Z",
     "start_time": "2019-06-26T17:08:58.862812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['no.\" Phone says \"yes.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_pat = re.compile(r'\"(.*)\"')\n",
    "\n",
    "text1 = 'Computer says \"no.\"'\n",
    "str_pat.findall(text1)\n",
    "\n",
    "text2 = 'Computer says \"no.\" Phone says \"yes.\"'\n",
    "str_pat.findall(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模式 `r'\\\"(.*)\\\"'` 的意图是匹配被双引号包含的文本。 但是在正则表达式中*操作符是贪婪的，因此匹配操作会查找最长的可能匹配。 于是在第二个例子中搜索 text2 的时候返回结果并不是我们想要的\n",
    "\n",
    "**`r'\"(.*?)\"'`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T17:09:55.738840Z",
     "start_time": "2019-06-26T17:09:55.663116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no.', 'yes.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_pat = re.compile(r'\"(.*?)\"')\n",
    "str_pat.findall(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (?:.|\\n)跨行匹配模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个问题很典型的出现在当你用点(.)去匹配任意字符的时候，忘记了点(.)不能匹配换行符的事实"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T17:19:43.219725Z",
     "start_time": "2019-06-26T17:19:43.098734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is a comment ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*(.*?)\\*/')\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = '''/* this is a\n",
    "    multiline comment */\n",
    "    '''\n",
    "comment.findall(text1)\n",
    "comment.findall(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**换行的支持**\n",
    "\n",
    "`(?:.|\\n)` 指定了一个非捕获组 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T17:22:14.634657Z",
     "start_time": "2019-06-26T17:22:14.628803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is a\\n    multiline comment ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')\n",
    "comment.findall(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "`re.compile()` 函数接受一个标志参数叫 `re.DOTALL` ，在这里非常有用。 它可以让正则表达式中的点(.)匹配包括 *换行符* 在内的任意字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T17:28:43.029443Z",
     "start_time": "2019-06-26T17:28:42.917737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is a\\n    multiline comment ']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "comment.findall(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于简单的情况使用 `re.DOTALL` 标记参数工作的很好， 但是如果模式非常复杂 这时候使用这个标记参数就可能出现一些问题。 如果让你选择的话，最好还是定义自己的正则表达式模式，这样它可以在不需要额外的标记参数下也能工作的很好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [unicodedata]将Unicode文本标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T09:58:44.659631Z",
     "start_time": "2019-06-28T09:58:44.558589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy Jalapeño'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Spicy Jalapeño'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "s2 = 'Spicy Jalapen\\u0303o'\n",
    "s1 # 'Spicy Jalapeño'\n",
    "s2 # 'Spicy Jalapeño'\n",
    "s1 == s2 # False\n",
    "len(s1) # 14\n",
    "len(s2) # 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NFC`: 第一种使用整体字符`”ñ”(U+00F1)`\n",
    "\n",
    "`NFD`: 第二种使用拉丁字母`”n”`后面跟一个`”~”`的组合字符`(U+0303)`。\n",
    "\n",
    "在需要比较字符串的程序中使用字符的多种表示会产生问题。 为了修正这个问题，你可以使用`unicodedata`模块先将文本标准化 \n",
    "\n",
    "`unicodedata.normalize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T10:00:08.536008Z",
     "start_time": "2019-06-28T10:00:08.198207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Spicy Jalape\\xf1o'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Spicy Jalapen\\u0303o'\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "t1 = unicodedata.normalize('NFC', s1)\n",
    "t2 = unicodedata.normalize('NFC', s2)\n",
    "\n",
    "t1 == t2 # True\n",
    "\n",
    "print(ascii(t1)) # 'Spicy Jalape\\xf1o'\n",
    "\n",
    "t3 = unicodedata.normalize('NFD', s1)\n",
    "t4 = unicodedata.normalize('NFD', s2)\n",
    "\n",
    "t3 == t4 # True\n",
    "\n",
    "print(ascii(t3)) # 'Spicy Jalapen\\u0303o'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python同样支持扩展的标准化形式`NFKC`和`NFKD`，它们在处理某些字符的时候增加了额外的兼容特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T10:27:36.192555Z",
     "start_time": "2019-06-28T10:27:36.027342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ﬁ'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ﬁ'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'fi'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'fi'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '\\ufb01' # A single character\n",
    "s # 'ﬁ'\n",
    "unicodedata.normalize('NFD', s) # 'ﬁ'\n",
    "\n",
    "# Notice how the combined letters are broken apart here\n",
    "unicodedata.normalize('NFKD', s) # 'fi'\n",
    "unicodedata.normalize('NFKC', s) # 'fi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "在清理和过滤文本的时候字符的标准化也是很重要的。 比如，假设你想清除掉一些文本上面的变音符的时候(可能是为了搜索和匹配)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T10:30:39.856456Z",
     "start_time": "2019-06-28T10:30:39.814119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy Jalapeno'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "t1 = unicodedata.normalize('NFD', s1)\n",
    "# NFD: 拉丁字母”n”后面跟一个”~”的组合字符(U+0303)\n",
    "\n",
    "# combining() 函数可以测试一个字符是否为和音字符\n",
    "''.join(c for c in t1 if not unicodedata.combining(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在正则式中使用Unicode[建議安裝第三方套件]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T13:23:51.061406Z",
     "start_time": "2019-06-28T13:23:50.722979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='123'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='١٢٣'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "num = re.compile('\\d+')\n",
    "# ASCII digits\n",
    "num.match('123')\n",
    "# Arabic digits\n",
    "num.match('\\u0661\\u0662\\u0663')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当执行匹配和搜索操作的时候，最好是先标准化并且清理所有文本为标准化格式(参考2.9小节)。 但是同样也应该注意一些特殊情况，比如在忽略大小写匹配和大小写转换时的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T13:26:49.749436Z",
     "start_time": "2019-06-28T13:26:49.556335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 6), match='straße'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'STRASSE'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat = re.compile('stra\\u00dfe', re.IGNORECASE)\n",
    "s = 'straße'\n",
    "\n",
    "pat.match(s) # Matches\n",
    "pat.match(s.upper()) # Doesn't match\n",
    "\n",
    "s.upper() # Case folds\n",
    "\n",
    "# 'STRASSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混合使用Unicode和正则表达式通常会让你抓狂。 如果你真的打算这样做的话，最好考虑下安装**第三方正则式库**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [str.strip() re.sub()]删除字符串中不需要的字符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`strip()` 方法能用于删除开始或结尾的字符。 `lstrip()` 和 `rstrip()` 分别从左和从右执行删除操作。 默认情况下，这些方法会去除空白字符，但是你也可以指定其他字符。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T13:32:31.798321Z",
     "start_time": "2019-06-28T13:32:31.750504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'hello world \\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' hello world'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'hello====='"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whitespace stripping\n",
    "s = ' hello world \\n'\n",
    "s.strip() # 'hello world'\n",
    "s.lstrip() # 'hello world \\n'\n",
    "s.rstrip() # ' hello world'\n",
    "\n",
    "# Character stripping\n",
    "t = '-----hello====='\n",
    "t.lstrip('-') # 'hello====='\n",
    "t.strip('-=') # 'hello'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想处理中间的空格，那么你需要求助其他技术。比如使用 `replace() `方法或者是用正则表达式替换。示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T13:36:55.376014Z",
     "start_time": "2019-06-28T13:36:55.370159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'helloworld\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' hello world '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ' hello     world \\n'\n",
    "s.replace(' ', '')\n",
    "import re\n",
    "re.sub('\\s+', ' ', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```py\n",
    "with open(filename) as f:\n",
    "    lines = (line.strip() for line in f)\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "```\n",
    "\n",
    "在这里，表达式 `lines = (line.strip() for line in f)` 执行数据转换操作。 这种方式非常高效，因为它不需要预先读取所有数据放到一个临时的列表中去。 它仅仅只是创建一个生成器，并且每次返回行之前会先执行 `strip` 操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [str.translate()]审查清理文本字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T13:46:21.690428Z",
     "start_time": "2019-06-28T13:46:21.681647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ\\x0cis\\tawesome\\r\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ is awesome\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'pýtĥöñ\\fis\\tawesome\\r\\n'\n",
    "s\n",
    "\n",
    "remap = {\n",
    "    ord('\\t') : ' ',\n",
    "    ord('\\f') : ' ',\n",
    "    ord('\\r') : None # Deleted\n",
    "}\n",
    "a = s.translate(remap)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:05:18.037566Z",
     "start_time": "2019-06-28T14:05:17.636723Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ is awesome\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'python is awesome\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "cmb_chrs = dict.fromkeys(\n",
    "    c for c in range(sys.maxunicode)\n",
    "        if unicodedata.combining(chr(c))\n",
    ")\n",
    "\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "b # 'pýtĥöñ is awesome\\n'\n",
    "b.translate(cmb_chrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的例子，`dict.fromkeys()` 方法构造一个字典，每个`Unicode和音符`(`sys.maxunicode`)作为键，对应的值全部为 `None` 。\n",
    "\n",
    "然后使用 `unicodedata.normalize()` 将原始输入标准化为分解形式字符。 然后再调用 `translate` 函数删除所有重音符。 同样的技术也可以被用来删除其他类型的字符(比如控制字符等)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里构造一个将所有`Unicode数字`字符映射到对应的`ASCII字符`上的表格："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:20:59.106273Z",
     "start_time": "2019-06-28T14:20:58.760283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'123'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitmap = { \n",
    "    c: ord('0') + unicodedata.digit(chr(c))\n",
    "        for c in range(sys.maxunicode)\n",
    "            if unicodedata.category(chr(c)) == 'Nd' \n",
    "}\n",
    "\n",
    "len(digitmap)\n",
    "\n",
    "# Arabic digits\n",
    "x = '\\u0661\\u0662\\u0663'\n",
    "x.translate(digitmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种清理文本的技术涉及到`I/O解码与编码函`。这里的思路是先对文本做一些初步的清理， 然后再结合 `encode()` 或者 `decode()` 操作来清除或修改它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:22:19.479923Z",
     "start_time": "2019-06-28T14:22:19.368659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is awesome\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'pýtĥöñ is awesome\\n'\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "b.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "文本字符清理一个最主要的问题应该是运行的性能。一般来讲，代码越简单运行越快。 对于简单的替换操作， `str.replace()` 方法通常是最快的，甚至在你需要多次调用的时候。 比如，为了清理空白字符，你可以这样做：\n",
    "\n",
    "```py\n",
    "def clean_spaces(s):\n",
    "    s = s.replace('\\r', '')\n",
    "    s = s.replace('\\t', ' ')\n",
    "    s = s.replace('\\f', ' ')\n",
    "    return s\n",
    "```\n",
    "\n",
    "如果你需要执行任何复杂字符对字符的重新映射或者删除操作的话， `tanslate()` 方法会非常的快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [format()]字符串对齐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于基本的字符串对齐操作，可以使用字符串的 `ljust()` , `rjust()` 和 `center()` 方法。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:27:34.388006Z",
     "start_time": "2019-06-28T14:27:34.381174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World         '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'         Hello World'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'    Hello World     '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hello World'\n",
    "text.ljust(20) # 'Hello World         '\n",
    "text.rjust(20) # '         Hello World'\n",
    "text.center(20) # '    Hello World     '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些方法都能接受一个可选的填充字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:28:21.441695Z",
     "start_time": "2019-06-28T14:28:21.340191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'=========Hello World'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'****Hello World*****'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.rjust(20,'=')# '=========Hello World'\n",
    "text.center(20,'*')# '****Hello World*****'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`format()`對齊 `<`,`>`,`^`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:47:12.779964Z",
     "start_time": "2019-06-28T14:47:12.764347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Hello World'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Hello World         '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'    Hello World     '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'=========Hello World'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'****Hello World*****'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'     Hello      World'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'    1.2345'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'   1.23   '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(text, '>20')# '         Hello World'\n",
    "format(text, '<20')# 'Hello World         '\n",
    "format(text, '^20')# '    Hello World     '\n",
    "\n",
    "format(text, '=>20s') # '=========Hello World'\n",
    "format(text, '*^20s') # '****Hello World*****'\n",
    "\n",
    "# 多種格式\n",
    "'{:>10s} {:>10s}'.format('Hello', 'World') # '     Hello      World'\n",
    "\n",
    "# 數字\n",
    "x = 1.2345\n",
    "format(x, '>10') # '    1.2345'\n",
    "format(x, '^10.2f') # '   1.23   '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [join()]合并拼接字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想要合并的字符串是在一个序列或者 `iterable` 中，那么最快的方式就是使用 `join()` 方法。比如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T15:07:18.429791Z",
     "start_time": "2019-06-28T15:07:18.421985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Chicago Not Chicago?'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Is,Chicago,Not,Chicago?'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'IsChicagoNotChicago?'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts = ['Is', 'Chicago', 'Not', 'Chicago?']\n",
    "' '.join(parts)\n",
    "','.join(parts)\n",
    "''.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T15:09:04.821671Z",
     "start_time": "2019-06-28T15:09:04.815815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Chicago Not Chicago?'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Chicago Not Chicago?\n",
      "Is Chicago Not Chicago?\n"
     ]
    }
   ],
   "source": [
    "a = 'Is Chicago'\n",
    "b = 'Not Chicago?'\n",
    "a + ' ' + b\n",
    "\n",
    "print('{} {}'.format(a,b))\n",
    "print(a + ' ' + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T15:53:52.208089Z",
     "start_time": "2019-06-28T15:53:52.203129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strA:strB:strC\n",
      "strA:strB:strC\n",
      "strA:strB:strC\n"
     ]
    }
   ],
   "source": [
    "a = 'strA'\n",
    "b = 'strB'\n",
    "c = 'strC'\n",
    "\n",
    "print(a + ':' + b + ':' + c) # Ugly\n",
    "print(':'.join([a, b, c])) # Still ugly\n",
    "print(a, b, c, sep=':') # Better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# Version 1 (string concatenation)\n",
    "f.write(chunk1 + chunk2)\n",
    "\n",
    "# Version 2 (separate I/O operations)\n",
    "f.write(chunk1)\n",
    "f.write(chunk2)\n",
    "```\n",
    "如果两个字符串很小，那么第一个版本性能会更好些，因为I/O系统调用天生就慢。 另外一方面，如果两个字符串很大，那么第二个版本可能会更加高效， 因为它避免了创建一个很大的临时结果并且要复制大量的内存块数据。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T08:22:01.541386Z",
     "start_time": "2019-06-30T08:22:01.534554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chicago', 'Chicago?', 'Is Not']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample():\n",
    "    yield 'Is'\n",
    "    yield 'Chicago'\n",
    "    yield 'Not'\n",
    "    yield 'Chicago?'\n",
    "    \n",
    "text = ''.join(sample())\n",
    "\n",
    "\n",
    "def combine_if(source, max_len=7):\n",
    "\n",
    "    psrt_list = []\n",
    "\n",
    "    for part in source:\n",
    "        if len(part) < max_len:\n",
    "            psrt_list.append(part)\n",
    "        else:\n",
    "            yield part\n",
    "\n",
    "    yield ' '.join(psrt_list)\n",
    "    \n",
    "    \n",
    "[i for i in combine_if(sample(), max_len=7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [format() format_map() 和 vars()]字符串中插入变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`format()`  \n",
    "`format_map()` 和 `vars()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T08:31:08.677042Z",
     "start_time": "2019-06-30T08:31:08.442720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{name} has {n} messages.'\n",
    "s.format(name='Guido', n=37)\n",
    "\n",
    "\n",
    "# format_map() 和 vars() 在作用域中尋找\n",
    "name = 'Guido'\n",
    "n = 37\n",
    "s.format_map(vars())\n",
    "\n",
    "class Info:\n",
    "    def __init__(self, name, n):\n",
    "        self.name = name\n",
    "        self.n = n\n",
    "        \n",
    "a = Info('Guido',37)\n",
    "s.format_map(vars(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**变量缺失的情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T08:32:12.959133Z",
     "start_time": "2019-06-30T08:32:12.594588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has {n} messages.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class safesub(dict):\n",
    "    \"\"\"防止key找不到\"\"\"\n",
    "    # __missing__() 方法可以让你定义如何处理缺失的值\n",
    "    def __missing__(self, key):\n",
    "        return '{' + key + '}'\n",
    "    \n",
    "del n # Make sure n is undefined\n",
    "s.format_map(safesub(vars()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量替换步骤用一个工具函数封装起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T08:44:23.118620Z",
     "start_time": "2019-06-30T08:44:23.022932Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def sub(text):\n",
    "    return text.format_map(\n",
    "        # sys._getframe(1).f_locals \n",
    "        # 調用此函數的作用域變數\n",
    "        safesub(sys._getframe(1).f_locals)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T08:44:51.447554Z",
     "start_time": "2019-06-30T08:44:51.442686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Guido\n",
      "You have 37 messages.\n",
      "Your favorite color is {color}\n"
     ]
    }
   ],
   "source": [
    "name = 'Guido'\n",
    "n = 37\n",
    "print(sub('Hello {name}'))\n",
    "print(sub('You have {n} messages.'))\n",
    "print(sub('Your favorite color is {color}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [textwrap.fill()]以指定列宽格式化字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T09:04:38.290856Z",
     "start_time": "2019-06-30T09:04:38.285000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look into my eyes, look into my eyes, the eyes, the eyes, the eyes,\n",
      "not around the eyes, don't look around the eyes, look into my eyes,\n",
      "you're under.\n",
      "\n",
      "\n",
      "Look into my eyes, look into my eyes,\n",
      "the eyes, the eyes, the eyes, not around\n",
      "the eyes, don't look around the eyes,\n",
      "look into my eyes, you're under.\n",
      "\n",
      "\n",
      "    Look into my eyes, look into my\n",
      "eyes, the eyes, the eyes, the eyes, not\n",
      "around the eyes, don't look around the\n",
      "eyes, look into my eyes, you're under.\n",
      "\n",
      "\n",
      "Look into my eyes, look into my eyes,\n",
      "    the eyes, the eyes, the eyes, not\n",
      "    around the eyes, don't look around\n",
      "    the eyes, look into my eyes, you're\n",
      "    under.\n"
     ]
    }
   ],
   "source": [
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
    "the eyes, not around the eyes, don't look around the eyes, \\\n",
    "look into my eyes, you're under.\"\n",
    "\n",
    "import textwrap\n",
    "print(textwrap.fill(s, 70),)\n",
    "print('\\n')\n",
    "print(textwrap.fill(s, 40))\n",
    "print('\\n')\n",
    "print(textwrap.fill(s, 40, initial_indent='    '))\n",
    "print('\\n')\n",
    "print(textwrap.fill(s, 40, subsequent_indent='    '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [os.get_terminal_size()]讨论\n",
    "\n",
    "`textwrap` 模块对于字符串打印是非常有用的，特别是当你希望输出自动匹配终端大小的时候。 你可以使用 `os.get_terminal_size()` 方法来获取终端的大小尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T09:06:27.914214Z",
     "start_time": "2019-06-30T09:06:27.909363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.get_terminal_size().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [html.escape()]在字符串中处理html和xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想替换文本字符串中的 `‘<’` 或者 `‘>’` ，使用 `html.escape()` 函数可以很容易的完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T13:07:36.671196Z",
     "start_time": "2019-06-30T13:07:36.446722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements are written as \"<tag>text</tag>\".\n",
      "Elements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.\n",
      "Elements are written as \"&lt;tag&gt;text&lt;/tag&gt;\".\n"
     ]
    }
   ],
   "source": [
    "s = 'Elements are written as \"<tag>text</tag>\".'\n",
    "import html\n",
    "print(s)\n",
    "print(html.escape(s))\n",
    "\n",
    "# Disable escaping of quotes\n",
    "print(html.escape(s, quote=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T14:45:18.609014Z",
     "start_time": "2019-07-01T14:45:17.744591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\__main__.py:4: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spicy \"Jalapeño\".'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'The prompt is >>>'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Spicy &quot;Jalape&#241;o&quot.'\n",
    "from html.parser import HTMLParser\n",
    "p = HTMLParser()\n",
    "p.unescape(s) # 'Spicy \"Jalapeño\".'\n",
    "\n",
    "t = 'The prompt is &gt;&gt;&gt;'\n",
    "from xml.sax.saxutils import unescape\n",
    "unescape(t) # 'The prompt is >>>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [html.parse xml.etree.ElementTree]讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* `html.escape()`\n",
    "* `xml.sax.saxutils.unescapge()`\n",
    "\n",
    "**解析模块**\n",
    "\n",
    "* `html.parse` \n",
    "* `xml.etree.ElementTree`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符串令牌解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```py\n",
    "text = 'foo = 23 + 42 * 10'\n",
    "```\n",
    "\n",
    "为了**令牌化字符串**，你不仅需要**匹配模式**，还得**指定模式的类型**。 比如，你可能想将字符串像下面这样转换为序列对：\n",
    "\n",
    "```py\n",
    "tokens = [\n",
    "    ('NAME', 'foo'), ('EQ','='), \n",
    "    ('NUM', '23'), ('PLUS','+'),\n",
    "    ('NUM', '42'), ('TIMES', '*'), \n",
    "    ('NUM', '10')\n",
    "]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了执行这样的切分，第一步就是像下面这样利用**命名捕获组的正则表达式**来定义所有可能的令牌，包括空格：\n",
    "\n",
    "`?P<TOKENNAME>` 用于给一个模式命名，供后面使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T14:57:18.700492Z",
     "start_time": "2019-07-01T14:57:18.695606Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了令牌化，使用模式对象很少被人知道的 `scanner()` 方法。 这个方法会创建一个 `scanner` 对象， 在这个对象上不断的调用 `match()` 方法会一步步的扫描目标文本，每步一个匹配。 下面是演示一个 `scanner` 对象如何工作的交互式例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T15:01:54.894688Z",
     "start_time": "2019-07-01T15:01:54.872708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='foo'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('NAME', 'foo')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(3, 4), match=' '>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('WS', ' ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(4, 5), match='='>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('EQ', '=')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(5, 6), match=' '>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('WS', ' ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(6, 8), match='42'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('NUM', '42')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner = master_pat.scanner('foo = 42')\n",
    "scanner.match()\n",
    "_.lastgroup, _.group() # ('NAME', 'foo')\n",
    "scanner.match()\n",
    "_.lastgroup, _.group() # ('WS', ' ')\n",
    "scanner.match()\n",
    "_.lastgroup, _.group() # ('EQ', '=')\n",
    "scanner.match()\n",
    "_.lastgroup, _.group() # ('WS', ' ')\n",
    "scanner.match()\n",
    "_.lastgroup, _.group() # ('NUM', '42')\n",
    "scanner.match()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**打包到一个生成器中**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T15:05:23.197477Z",
     "start_time": "2019-07-01T15:05:23.192597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='NUM', value='42')\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "def generate_tokens(pat, text):\n",
    "    Token = namedtuple('Token', ['type', 'value'])\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        yield Token(m.lastgroup, m.group())\n",
    "\n",
    "# Example use\n",
    "for tok in generate_tokens(master_pat, 'foo = 42'):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**过滤所有的空白令牌**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T15:07:24.084151Z",
     "start_time": "2019-07-01T15:07:24.076343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='NUM', value='23')\n",
      "Token(type='PLUS', value='+')\n",
      "Token(type='NUM', value='42')\n",
      "Token(type='TIMES', value='*')\n",
      "Token(type='NUM', value='10')\n"
     ]
    }
   ],
   "source": [
    "text = 'foo = 23 + 42 * 10'\n",
    "\n",
    "tokens = (tok for tok in generate_tokens(master_pat, text)\n",
    "          if tok.type != 'WS')\n",
    "for tok in tokens:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "令牌的顺序也是有影响的。 `re` 模块会按照指定好的顺序去做匹配。 因此，如果一个模式恰好是另一个更长模式的子字符串，那么你需要确定**{ 长模式写在前面 }**。比如：\n",
    "\n",
    "```py\n",
    "LT = r'(?P<LT><)'\n",
    "LE = r'(?P<LE><=)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "\n",
    "master_pat = re.compile('|'.join([LE, LT, EQ])) # Correct\n",
    "# master_pat = re.compile('|'.join([LT, LE, EQ])) # Incorrect\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3 + 4 = 7 字符解析處理]实现一个简单的递归下降分析器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在`EBNF`中，被包含在 `{...}*` 中的规则是可选的。*代表0次或多次重复(跟正则表达式中意义是一样的)。\n",
    "\n",
    "    expr ::= term { (+|-) term }*\n",
    "\n",
    "    term ::= factor { (*|/) factor }*\n",
    "\n",
    "    factor ::= ( expr )\n",
    "        |   NUM\n",
    " \n",
    "假设你正在解析形如 `3 + 4 * 5` 的表达式。 这个表达式先要通过使用2.18节中介绍的技术分解为一组令牌流。 结果可能是像下列这样的令牌序列：\n",
    "\n",
    "    NUM + NUM * NUM\n",
    "\n",
    "在此基础上， 解析动作会试着去通过替换操作匹配语法到输入令牌：\n",
    "\n",
    "    expr\n",
    "    expr ::= term { (+|-) term }*\n",
    "    expr ::= factor { (*|/) factor }* { (+|-) term }*\n",
    "    expr ::= NUM { (*|/) factor }* { (+|-) term }*\n",
    "    expr ::= NUM { (+|-) term }*\n",
    "    expr ::= NUM + term { (+|-) term }*\n",
    "    expr ::= NUM + factor { (*|/) factor }* { (+|-) term }*\n",
    "    expr ::= NUM + NUM { (*|/) factor}* { (+|-) term }*\n",
    "    expr ::= NUM + NUM * factor { (*|/) factor }* { (+|-) term }*\n",
    "    expr ::= NUM + NUM * NUM { (*|/) factor }* { (+|-) term }*\n",
    "    expr ::= NUM + NUM * NUM { (+|-) term }*\n",
    "    expr ::= NUM + NUM * NUM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T14:48:55.689222Z",
     "start_time": "2019-07-02T14:48:55.563511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTopic: 下降解析器\\nDesc :\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n",
      "14\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Topic: 下降解析器\n",
    "Desc :\n",
    "\"\"\"\n",
    "import re\n",
    "import collections\n",
    "\n",
    "# Token specification\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "MINUS = r'(?P<MINUS>-)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "DIVIDE = r'(?P<DIVIDE>/)'\n",
    "LPAREN = r'(?P<LPAREN>\\()'\n",
    "RPAREN = r'(?P<RPAREN>\\))'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,\n",
    "                                  DIVIDE, LPAREN, RPAREN, WS]))\n",
    "# Tokenizer\n",
    "Token = collections.namedtuple('Token', ['type', 'value'])\n",
    "\n",
    "\n",
    "def generate_tokens(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        tok = Token(m.lastgroup, m.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok\n",
    "\n",
    "\n",
    "# Parser\n",
    "class ExpressionEvaluator:\n",
    "    '''\n",
    "    Implementation of a recursive descent parser. Each method\n",
    "    implements a single grammar rule. Use the ._accept() method\n",
    "    to test and accept the current lookahead token. Use the ._expect()\n",
    "    method to exactly match and discard the next token on on the input\n",
    "    (or raise a SyntaxError if it doesn't match).\n",
    "    '''\n",
    "\n",
    "    def parse(self, text):\n",
    "        self.tokens = generate_tokens(text)\n",
    "        self.tok = None  # Last symbol consumed\n",
    "        self.nexttok = None  # Next symbol tokenized\n",
    "        self._advance()  # Load first lookahead token\n",
    "        return self.expr()\n",
    "\n",
    "    def _advance(self):\n",
    "        'Advance one token ahead'\n",
    "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
    "\n",
    "    def _accept(self, toktype):\n",
    "        'Test and consume the next token if it matches toktype'\n",
    "        if self.nexttok and self.nexttok.type == toktype:\n",
    "            self._advance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def _expect(self, toktype):\n",
    "        'Consume next token if it matches toktype or raise SyntaxError'\n",
    "        if not self._accept(toktype):\n",
    "            raise SyntaxError('Expected ' + toktype)\n",
    "\n",
    "    # Grammar rules follow\n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+'|'-') term }*\"\n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval += right\n",
    "            elif op == 'MINUS':\n",
    "                exprval -= right\n",
    "        return exprval\n",
    "\n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*'|'/') factor }*\"\n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval *= right\n",
    "            elif op == 'DIVIDE':\n",
    "                termval /= right\n",
    "        return termval\n",
    "\n",
    "    def factor(self):\n",
    "        \"factor ::= NUM | ( expr )\"\n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')\n",
    "\n",
    "\n",
    "def descent_parser():\n",
    "    e = ExpressionEvaluator()\n",
    "    print(e.parse('2'))\n",
    "    print(e.parse('2 + 3'))\n",
    "    print(e.parse('2 + 3 * 4'))\n",
    "    print(e.parse('2 + (3 + 4) * 5'))\n",
    "    \n",
    "    # print(e.parse('2 + (3 + * 4)'))\n",
    "    # Traceback (most recent call last):\n",
    "    #    File \"<stdin>\", line 1, in <module>\n",
    "    #    File \"exprparse.py\", line 40, in parse\n",
    "    #    return self.expr()\n",
    "    #    File \"exprparse.py\", line 67, in expr\n",
    "    #    right = self.term()\n",
    "    #    File \"exprparse.py\", line 77, in term\n",
    "    #    termval = self.factor()\n",
    "    #    File \"exprparse.py\", line 93, in factor\n",
    "    #    exprval = self.expr()\n",
    "    #    File \"exprparse.py\", line 67, in expr\n",
    "    #    right = self.term()\n",
    "    #    File \"exprparse.py\", line 77, in term\n",
    "    #    termval = self.factor()\n",
    "    #    File \"exprparse.py\", line 97, in factor\n",
    "    #    raise SyntaxError(\"Expected NUMBER or LPAREN\")\n",
    "    #    SyntaxError: Expected NUMBER or LPAREN\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    descent_parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLY 模塊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于复杂的语法，你最好是选择某个解析工具比如`PyParsing`或者是`PLY`。 下面是使用`PLY`来重写表达式求值程序的代码：\n",
    "\n",
    "./PLY_TEST.py\n",
    "\n",
    "```py\n",
    "from ply.lex import lex\n",
    "from ply.yacc import yacc\n",
    "\n",
    "# Token list\n",
    "tokens = [ 'NUM', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'LPAREN', 'RPAREN' ]\n",
    "# Ignored characters\n",
    "t_ignore = ' \\t\\n'\n",
    "# Token specifications (as regexs)\n",
    "t_PLUS = r'\\+'\n",
    "t_MINUS = r'-'\n",
    "t_TIMES = r'\\*'\n",
    "t_DIVIDE = r'/'\n",
    "t_LPAREN = r'\\('\n",
    "t_RPAREN = r'\\)'\n",
    "\n",
    "# Token processing functions\n",
    "def t_NUM(t):\n",
    "    r'\\d+'\n",
    "    t.value = int(t.value)\n",
    "    return t\n",
    "\n",
    "# Error handler\n",
    "def t_error(t):\n",
    "    print('Bad character: {!r}'.format(t.value[0]))\n",
    "    t.skip(1)\n",
    "\n",
    "# Build the lexer\n",
    "lexer = lex()\n",
    "\n",
    "# Grammar rules and handler functions\n",
    "def p_expr(p):\n",
    "    '''\n",
    "    expr : expr PLUS term\n",
    "        | expr MINUS term\n",
    "    '''\n",
    "    if p[2] == '+':\n",
    "        p[0] = p[1] + p[3]\n",
    "    elif p[2] == '-':\n",
    "        p[0] = p[1] - p[3]\n",
    "\n",
    "\n",
    "def p_expr_term(p):\n",
    "    '''\n",
    "    expr : term\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "\n",
    "def p_term(p):\n",
    "    '''\n",
    "    term : term TIMES factor\n",
    "    | term DIVIDE factor\n",
    "    '''\n",
    "    if p[2] == '*':\n",
    "        p[0] = p[1] * p[3]\n",
    "    elif p[2] == '/':\n",
    "        p[0] = p[1] / p[3]\n",
    "\n",
    "def p_term_factor(p):\n",
    "    '''\n",
    "    term : factor\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_factor(p):\n",
    "    '''\n",
    "    factor : NUM\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_factor_group(p):\n",
    "    '''\n",
    "    factor : LPAREN expr RPAREN\n",
    "    '''\n",
    "    p[0] = p[2]\n",
    "\n",
    "def p_error(p):\n",
    "    print('Syntax error')\n",
    "\n",
    "parser = yacc()\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T15:28:38.239574Z",
     "start_time": "2019-07-02T15:28:38.228628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ./PLY_TEST.py\n",
    "\n",
    "parser.parse('2')\n",
    "parser.parse('2+3')\n",
    "parser.parse('2+(3+4)*5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [b' ']字节字符串上的字符串操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在字节字符串上执行普通的文本操作(比如移除，搜索和替换)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T09:32:21.572269Z",
     "start_time": "2019-07-03T09:32:21.557630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[b'Hello', b'World']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "b'Hello Cruel World'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = b'Hello World'\n",
    "\n",
    "data[0:5] # b'Hello'\n",
    "\n",
    "data.startswith(b'Hello') # True\n",
    "\n",
    "data.split() # [b'Hello', b'World']\n",
    "\n",
    "data.replace(b'Hello', b'Hello Cruel') # b'Hello Cruel World'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**字节数组**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T09:33:37.208942Z",
     "start_time": "2019-07-03T09:33:37.103465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'Hello')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[bytearray(b'Hello'), bytearray(b'World')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "bytearray(b'Hello Cruel World')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bytearray(b'Hello World')\n",
    "\n",
    "data[0:5] # bytearray(b'Hello')\n",
    "\n",
    "data.startswith(b'Hello') # True\n",
    "\n",
    "data.split() # [bytearray(b'Hello'), bytearray(b'World')]\n",
    "\n",
    "data.replace(b'Hello', b'Hello Cruel') # bytearray(b'Hello Cruel World')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用正则表达式匹配字节字符串，但是 *正则表达式* 本身必须也是 *字节串*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T09:35:05.263595Z",
     "start_time": "2019-07-03T09:35:05.258689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'FOO', b'BAR', b'SPAM']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = b'FOO:BAR,SPAM'\n",
    "import re\n",
    "\n",
    "re.split(b'[:,]',data)\n",
    "\n",
    "# re.split('[:,]',data) \n",
    "# cannot use a string pattern on a bytes-like object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**字节字符串 返回整数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T09:36:04.281208Z",
     "start_time": "2019-07-03T09:36:04.271422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Hello World' # Text string\n",
    "a[0] # 'H'\n",
    "a[1] # 'e'\n",
    "\n",
    "b = b'Hello World' # Byte string\n",
    "b[0] # 72\n",
    "b[1] # 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**字节字符串 解码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T09:37:55.145657Z",
     "start_time": "2019-07-03T09:37:55.141769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World'\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "s = b'Hello World'\n",
    "print(s) # b'Hello World' # Observe b'...' \n",
    "\n",
    "print(s.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**格式化 不支持format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T09:41:45.914320Z",
     "start_time": "2019-07-03T09:41:45.905537Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2171e79111f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;34mb'{} {} {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'ACME'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m490.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'format'"
     ]
    }
   ],
   "source": [
    "\n",
    "b'{} {} {}'.format(b'ACME', 100, 490.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T09:41:47.201593Z",
     "start_time": "2019-07-03T09:41:47.196727Z"
    }
   },
   "source": [
    "先使用标准的文本字符串，然后将其编码为字节字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T09:41:51.689095Z",
     "start_time": "2019-07-03T09:41:51.684216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ACME              100     490.10'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'{:10s} {:10d} {:10.2f}'.format('ACME', 100, 490.1).encode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "192px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
